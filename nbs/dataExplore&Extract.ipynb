{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39767842-4079-4313-b092-ac3ce4661d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, sys\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9da2c8df-d3bf-4c95-9470-494245448d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = [\"danish\", \"english\", \"french\", \"persian\", \"spanish\", \"vietnamese\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1244b020-55a7-4b87-8898-28b90cd6965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "danishDFTrain = pd.read_json(\"../data/\"+langs[0]+\"/train.json\")\n",
    "danishDFDev = pd.read_json(\"../data/\"+langs[0]+\"/dev.json\")\n",
    "\n",
    "englishDFTrainLegal = pd.read_json(\"../data/\"+langs[1]+\"/legal/train.json\")\n",
    "englishDFDevLegal = pd.read_json(\"../data/\"+langs[1]+\"/legal/dev.json\")\n",
    "englishDFTrainScientific = pd.read_json(\"../data/\"+langs[1]+\"/scientific/train.json\")\n",
    "englishDFDevScientific = pd.read_json(\"../data/\"+langs[1]+\"/scientific/dev.json\")\n",
    "\n",
    "frenchDFTrain = pd.read_json(\"../data/\"+langs[2]+\"/train.json\")\n",
    "frenchDFDev = pd.read_json(\"../data/\"+langs[2]+\"/dev.json\")\n",
    "\n",
    "persianDFTrain = pd.read_json(\"../data/\"+langs[3]+\"/train.json\")\n",
    "persianDFDev = pd.read_json(\"../data/\"+langs[3]+\"/dev.json\")\n",
    "\n",
    "spanishDFTrain = pd.read_json(\"../data/\"+langs[4]+\"/train.json\")\n",
    "spanishDFDev = pd.read_json(\"../data/\"+langs[4]+\"/dev.json\")\n",
    "\n",
    "vietnameseDFTrain = pd.read_json(\"../data/\"+langs[5]+\"/train.json\")\n",
    "vietnameseDFDev = pd.read_json(\"../data/\"+langs[5]+\"/dev.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "965edf08-330e-4033-9ebc-fbaba067e24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' An arguably better approach to representation learning is Canonical Correlation Analysis (CCA) that induces representations that are maximally cor-',\n",
       " [[91, 94]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "englishDFTrainScientific.text[2], englishDFTrainScientific.acronyms[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "624ea8ad-3a9e-49de-907f-b2d5ba4723ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with io.open(\"data/\"+langs[1]+\"/legal/train.json\") as file:\n",
    "#     data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7371d1a8-32d1-4df1-988b-afb0b567bc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c417723f-e65f-4f42-91b2-d28bd8128c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>acronyms</th>\n",
       "      <th>long-forms</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92\\]. This selective approach led to significa...</td>\n",
       "      <td>[[91, 98]]</td>\n",
       "      <td>[[77, 89]]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We conduct a case study of dialectal language ...</td>\n",
       "      <td>[[119, 122]]</td>\n",
       "      <td>[[93, 117]]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An arguably better approach to representation...</td>\n",
       "      <td>[[91, 94]]</td>\n",
       "      <td>[[59, 89]]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23-28, 1992   Proceedings of NAACL-HLT 2015 St...</td>\n",
       "      <td>[[71, 74], [29, 38]]</td>\n",
       "      <td>[[44, 69]]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>itly mark objects of prepositions (POBJ), poss...</td>\n",
       "      <td>[[119, 121], [35, 39], [76, 81], [95, 99], [16...</td>\n",
       "      <td>[[105, 117], [10, 33], [56, 74], [84, 93], [15...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3975</th>\n",
       "      <td>take et al (2005)) for the representation of m...</td>\n",
       "      <td>[[112, 115], [55, 61]]</td>\n",
       "      <td>[[82, 110]]</td>\n",
       "      <td>3976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3976</th>\n",
       "      <td>clickthrough data. In ACM SIGKDD Conference on...</td>\n",
       "      <td>[[84, 87], [22, 25], [26, 32]]</td>\n",
       "      <td>[[47, 75]]</td>\n",
       "      <td>3977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>S2LS. The best parameters were then used on th...</td>\n",
       "      <td>[[88, 92], [0, 4]]</td>\n",
       "      <td>[[48, 86]]</td>\n",
       "      <td>3978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>C-NOUN: Nouns with POS NN that are not marked ...</td>\n",
       "      <td>[[89, 92], [0, 6], [19, 22], [23, 25], [46, 52...</td>\n",
       "      <td>[[67, 81]]</td>\n",
       "      <td>3979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>text corpus, to be made available without roya...</td>\n",
       "      <td>[[111, 115]]</td>\n",
       "      <td>[[121, 157]]</td>\n",
       "      <td>3980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3980 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     92\\]. This selective approach led to significa...   \n",
       "1     We conduct a case study of dialectal language ...   \n",
       "2      An arguably better approach to representation...   \n",
       "3     23-28, 1992   Proceedings of NAACL-HLT 2015 St...   \n",
       "4     itly mark objects of prepositions (POBJ), poss...   \n",
       "...                                                 ...   \n",
       "3975  take et al (2005)) for the representation of m...   \n",
       "3976  clickthrough data. In ACM SIGKDD Conference on...   \n",
       "3977  S2LS. The best parameters were then used on th...   \n",
       "3978  C-NOUN: Nouns with POS NN that are not marked ...   \n",
       "3979  text corpus, to be made available without roya...   \n",
       "\n",
       "                                               acronyms  \\\n",
       "0                                            [[91, 98]]   \n",
       "1                                          [[119, 122]]   \n",
       "2                                            [[91, 94]]   \n",
       "3                                  [[71, 74], [29, 38]]   \n",
       "4     [[119, 121], [35, 39], [76, 81], [95, 99], [16...   \n",
       "...                                                 ...   \n",
       "3975                             [[112, 115], [55, 61]]   \n",
       "3976                     [[84, 87], [22, 25], [26, 32]]   \n",
       "3977                                 [[88, 92], [0, 4]]   \n",
       "3978  [[89, 92], [0, 6], [19, 22], [23, 25], [46, 52...   \n",
       "3979                                       [[111, 115]]   \n",
       "\n",
       "                                             long-forms    ID  \n",
       "0                                            [[77, 89]]     1  \n",
       "1                                           [[93, 117]]     2  \n",
       "2                                            [[59, 89]]     3  \n",
       "3                                            [[44, 69]]     4  \n",
       "4     [[105, 117], [10, 33], [56, 74], [84, 93], [15...     5  \n",
       "...                                                 ...   ...  \n",
       "3975                                        [[82, 110]]  3976  \n",
       "3976                                         [[47, 75]]  3977  \n",
       "3977                                         [[48, 86]]  3978  \n",
       "3978                                         [[67, 81]]  3979  \n",
       "3979                                       [[121, 157]]  3980  \n",
       "\n",
       "[3980 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "englishDFTrainScientific"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486d501e-40df-4a67-a635-a9758cd73102",
   "metadata": {},
   "source": [
    "### Extracting text from the numerical indexes (Hadeel's Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dcb2a6b-b1ab-4fd9-b6a6-bd2174fa1b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTHOR: Hadeel S\n",
    "\n",
    "def create_acronyms(data):\n",
    "    acs2 = []\n",
    "    longf = []\n",
    "\n",
    "    acros = data.acronyms.values\n",
    "    txt = data.text.values\n",
    "    zipped = list(zip(txt,acros))\n",
    "    for z in zipped:\n",
    "        acs = []\n",
    "        for i in range(len(z[1])):\n",
    "            acs.append(z[0][z[1][i][0]:z[1][i][1]])\n",
    "        acs2.append(acs)\n",
    "    data['acronyms-text'] =acs2\n",
    "    \n",
    "# Creating long forms from here\n",
    "\n",
    "    longform = data[\"long-forms\"].values\n",
    "    zipped2 = list(zip(txt,longform))\n",
    "    for z2 in zipped2:\n",
    "        longform_temp = []\n",
    "        for i in range(len(z2[1])):\n",
    "            longform_temp.append(z2[0][z2[1][i][0]:z2[1][i][1]])\n",
    "        longf.append(longform_temp)\n",
    "    data[\"long-forms-text\"]= longf\n",
    "    \n",
    "    return data\n",
    "#     return data.to_csv(\"datatsvs/\" + name +\".tsv\", index = False, encoding='utf8', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fcc82de-0528-42fe-a53f-acde6b9b7ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "englishDFTrainScientific = create_acronyms(englishDFTrainScientific)\n",
    "englishDFDevScientific = create_acronyms(englishDFDevScientific)\n",
    "englishDFTrainLegal = create_acronyms(englishDFTrainLegal)\n",
    "englishDFDevLegal = create_acronyms(englishDFDevLegal)\n",
    "danishDFTrain = create_acronyms(danishDFTrain)\n",
    "danishDFDev = create_acronyms(danishDFDev)\n",
    "frenchDFTrain = create_acronyms(frenchDFTrain)\n",
    "frenchDFDev = create_acronyms(frenchDFDev)\n",
    "persianDFTrain = create_acronyms(persianDFTrain)\n",
    "persianDFDev = create_acronyms(persianDFDev)\n",
    "spanishDFTrain = create_acronyms(spanishDFTrain)\n",
    "spanishDFDev = create_acronyms(spanishDFDev)\n",
    "vietnameseDFTrain = create_acronyms(vietnameseDFTrain)\n",
    "vietnameseDFDev = create_acronyms(vietnameseDFDev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a359366c-d3ad-42fc-8cde-f64162898582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>acronyms</th>\n",
       "      <th>long-forms</th>\n",
       "      <th>ID</th>\n",
       "      <th>acronyms-text</th>\n",
       "      <th>long-forms-text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92\\]. This selective approach led to significa...</td>\n",
       "      <td>[[91, 98]]</td>\n",
       "      <td>[[77, 89]]</td>\n",
       "      <td>1</td>\n",
       "      <td>[ATIS...]</td>\n",
       "      <td>[applications]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We conduct a case study of dialectal language ...</td>\n",
       "      <td>[[119, 122]]</td>\n",
       "      <td>[[93, 117]]</td>\n",
       "      <td>2</td>\n",
       "      <td>[AAE]</td>\n",
       "      <td>[African-American English]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An arguably better approach to representation...</td>\n",
       "      <td>[[91, 94]]</td>\n",
       "      <td>[[59, 89]]</td>\n",
       "      <td>3</td>\n",
       "      <td>[CCA]</td>\n",
       "      <td>[Canonical Correlation Analysis]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23-28, 1992   Proceedings of NAACL-HLT 2015 St...</td>\n",
       "      <td>[[71, 74], [29, 38]]</td>\n",
       "      <td>[[44, 69]]</td>\n",
       "      <td>4</td>\n",
       "      <td>[SRW, NAACL-HLT]</td>\n",
       "      <td>[Student Research Workshop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>itly mark objects of prepositions (POBJ), poss...</td>\n",
       "      <td>[[119, 121], [35, 39], [76, 81], [95, 99], [16...</td>\n",
       "      <td>[[105, 117], [10, 33], [56, 74], [84, 93], [15...</td>\n",
       "      <td>5</td>\n",
       "      <td>[CC, POBJ, IDAFA, CONJ, TMZ]</td>\n",
       "      <td>[conjunctions, objects of prepositions, idafa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3975</th>\n",
       "      <td>take et al (2005)) for the representation of m...</td>\n",
       "      <td>[[112, 115], [55, 61]]</td>\n",
       "      <td>[[82, 110]]</td>\n",
       "      <td>3976</td>\n",
       "      <td>[LKB, LXGram]</td>\n",
       "      <td>[Linguistic Knowledge Builder]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3976</th>\n",
       "      <td>clickthrough data. In ACM SIGKDD Conference on...</td>\n",
       "      <td>[[84, 87], [22, 25], [26, 32]]</td>\n",
       "      <td>[[47, 75]]</td>\n",
       "      <td>3977</td>\n",
       "      <td>[KDD, ACM, SIGKDD]</td>\n",
       "      <td>[Knowledge Discovery and Data]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>S2LS. The best parameters were then used on th...</td>\n",
       "      <td>[[88, 92], [0, 4]]</td>\n",
       "      <td>[[48, 86]]</td>\n",
       "      <td>3978</td>\n",
       "      <td>[S3LS, S2LS]</td>\n",
       "      <td>[Senseval-3 English Lexical Sample task]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>C-NOUN: Nouns with POS NN that are not marked ...</td>\n",
       "      <td>[[89, 92], [0, 6], [19, 22], [23, 25], [46, 52...</td>\n",
       "      <td>[[67, 81]]</td>\n",
       "      <td>3979</td>\n",
       "      <td>[VBG, C-NOUN, POS, NN, O-NOUN, PER-NOUN, ED-VE...</td>\n",
       "      <td>[Verbs Only ING]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>text corpus, to be made available without roya...</td>\n",
       "      <td>[[111, 115]]</td>\n",
       "      <td>[[121, 157]]</td>\n",
       "      <td>3980</td>\n",
       "      <td>[SGML]</td>\n",
       "      <td>[Standard Generalized Markup Language]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3980 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     92\\]. This selective approach led to significa...   \n",
       "1     We conduct a case study of dialectal language ...   \n",
       "2      An arguably better approach to representation...   \n",
       "3     23-28, 1992   Proceedings of NAACL-HLT 2015 St...   \n",
       "4     itly mark objects of prepositions (POBJ), poss...   \n",
       "...                                                 ...   \n",
       "3975  take et al (2005)) for the representation of m...   \n",
       "3976  clickthrough data. In ACM SIGKDD Conference on...   \n",
       "3977  S2LS. The best parameters were then used on th...   \n",
       "3978  C-NOUN: Nouns with POS NN that are not marked ...   \n",
       "3979  text corpus, to be made available without roya...   \n",
       "\n",
       "                                               acronyms  \\\n",
       "0                                            [[91, 98]]   \n",
       "1                                          [[119, 122]]   \n",
       "2                                            [[91, 94]]   \n",
       "3                                  [[71, 74], [29, 38]]   \n",
       "4     [[119, 121], [35, 39], [76, 81], [95, 99], [16...   \n",
       "...                                                 ...   \n",
       "3975                             [[112, 115], [55, 61]]   \n",
       "3976                     [[84, 87], [22, 25], [26, 32]]   \n",
       "3977                                 [[88, 92], [0, 4]]   \n",
       "3978  [[89, 92], [0, 6], [19, 22], [23, 25], [46, 52...   \n",
       "3979                                       [[111, 115]]   \n",
       "\n",
       "                                             long-forms    ID  \\\n",
       "0                                            [[77, 89]]     1   \n",
       "1                                           [[93, 117]]     2   \n",
       "2                                            [[59, 89]]     3   \n",
       "3                                            [[44, 69]]     4   \n",
       "4     [[105, 117], [10, 33], [56, 74], [84, 93], [15...     5   \n",
       "...                                                 ...   ...   \n",
       "3975                                        [[82, 110]]  3976   \n",
       "3976                                         [[47, 75]]  3977   \n",
       "3977                                         [[48, 86]]  3978   \n",
       "3978                                         [[67, 81]]  3979   \n",
       "3979                                       [[121, 157]]  3980   \n",
       "\n",
       "                                          acronyms-text  \\\n",
       "0                                             [ATIS...]   \n",
       "1                                                 [AAE]   \n",
       "2                                                 [CCA]   \n",
       "3                                      [SRW, NAACL-HLT]   \n",
       "4                          [CC, POBJ, IDAFA, CONJ, TMZ]   \n",
       "...                                                 ...   \n",
       "3975                                      [LKB, LXGram]   \n",
       "3976                                 [KDD, ACM, SIGKDD]   \n",
       "3977                                       [S3LS, S2LS]   \n",
       "3978  [VBG, C-NOUN, POS, NN, O-NOUN, PER-NOUN, ED-VE...   \n",
       "3979                                             [SGML]   \n",
       "\n",
       "                                        long-forms-text  \n",
       "0                                        [applications]  \n",
       "1                            [African-American English]  \n",
       "2                      [Canonical Correlation Analysis]  \n",
       "3                           [Student Research Workshop]  \n",
       "4     [conjunctions, objects of prepositions, idafa ...  \n",
       "...                                                 ...  \n",
       "3975                     [Linguistic Knowledge Builder]  \n",
       "3976                     [Knowledge Discovery and Data]  \n",
       "3977           [Senseval-3 English Lexical Sample task]  \n",
       "3978                                   [Verbs Only ING]  \n",
       "3979             [Standard Generalized Markup Language]  \n",
       "\n",
       "[3980 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "englishDFTrainScientific"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab795d28-2157-47d5-ada3-041ac78f77b9",
   "metadata": {},
   "source": [
    "### Manipulating columns for proper TSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a03e206-8dde-4540-94ab-f6db2ce033ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "englishDFTrainScientific = englishDFTrainScientific[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "englishDFDevScientific = englishDFDevScientific[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "englishDFTrainLegal = englishDFTrainLegal[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "englishDFDevLegal = englishDFDevLegal[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "danishDFTrain = danishDFTrain[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "danishDFDev = danishDFDev[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "frenchDFTrain = frenchDFTrain[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "frenchDFDev = frenchDFDev[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "persianDFTrain = persianDFTrain[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "persianDFDev = persianDFDev[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "spanishDFTrain = spanishDFTrain[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "spanishDFDev = spanishDFDev[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "vietnameseDFTrain = vietnameseDFTrain[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "vietnameseDFDev = vietnameseDFDev[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7d4086-16d0-48e2-af45-86a658b4a1c0",
   "metadata": {},
   "source": [
    "### Writing TSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90ab187d-d095-435b-a388-b5bfbddcab11",
   "metadata": {},
   "outputs": [],
   "source": [
    "englishDFTrainScientific.to_csv(\"../data_tsvs/englishDFTrainScientific.tsv\", sep='\\t', index=False)\n",
    "englishDFDevScientific.to_csv(\"../data_tsvs/englishDFDevScientific.tsv\", sep='\\t', index=False)\n",
    "englishDFTrainLegal.to_csv(\"../data_tsvs/englishDFTrainLegal.tsv\", sep='\\t', index=False)\n",
    "englishDFDevLegal.to_csv(\"../data_tsvs/englishDFDevLegal.tsv\", sep='\\t', index=False)\n",
    "danishDFTrain.to_csv(\"../data_tsvs/danishDFTrain.tsv\", sep='\\t', index=False)\n",
    "danishDFDev.to_csv(\"../data_tsvs/danishDFDev.tsv\", sep='\\t', index=False)\n",
    "frenchDFTrain.to_csv(\"../data_tsvs/frenchDFTrain.tsv\", sep='\\t', index=False)\n",
    "frenchDFDev.to_csv(\"../data_tsvs/frenchDFDev.tsv\", sep='\\t', index=False)\n",
    "persianDFTrain.to_csv(\"../data_tsvs/persianDFTrain.tsv\", sep='\\t', index=False)\n",
    "persianDFDev.to_csv(\"../data_tsvs/persianDFDev.tsv\", sep='\\t', index=False)\n",
    "spanishDFTrain.to_csv(\"../data_tsvs/spanishDFTrain.tsv\", sep='\\t', index=False)\n",
    "spanishDFDev.to_csv(\"../data_tsvs/spanishDFDev.tsv\", sep='\\t', index=False)\n",
    "vietnameseDFTrain.to_csv(\"../data_tsvs/vietnameseDFTrain.tsv\", sep='\\t', index=False)\n",
    "vietnameseDFDev.to_csv(\"../data_tsvs/vietnameseDFDev.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fbd98ce-1b2f-49a2-8ff7-da60054042fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>acronyms</th>\n",
       "      <th>long-forms</th>\n",
       "      <th>acronyms-text</th>\n",
       "      <th>long-forms-text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Depuis le début 2000, les organismes des Natio...</td>\n",
       "      <td>[[323, 328]]</td>\n",
       "      <td>[[258, 321]]</td>\n",
       "      <td>[ONUDI]</td>\n",
       "      <td>[Organisation des Nations Unies pour le dévelo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>VI. Lutte contre les stupéfiants En janvier 20...</td>\n",
       "      <td>[[107, 112]]</td>\n",
       "      <td>[[52, 105]]</td>\n",
       "      <td>[UNODC]</td>\n",
       "      <td>[Office des Nations Unies contre la drogue et ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>À moins qu'il ne soit réglé à l'amiable par vo...</td>\n",
       "      <td>[[396, 399], [544, 547], [308, 314]]</td>\n",
       "      <td>[[360, 394], [508, 542]]</td>\n",
       "      <td>[CCI, AAA, CNUDCI]</td>\n",
       "      <td>[Chambre de commerce internationale, Associati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Rapports financiers des Fonds d'affectation sp...</td>\n",
       "      <td>[[358, 362]]</td>\n",
       "      <td>[[332, 356]]</td>\n",
       "      <td>[HCFC]</td>\n",
       "      <td>[hydrochlorofluorocabones]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Le GRE a examiné le document ECE/TRANS/WP.29/G...</td>\n",
       "      <td>[[454, 458], [400, 405], [390, 392], [214, 219...</td>\n",
       "      <td>[[412, 452]]</td>\n",
       "      <td>[AC.1, WP.29, no, WP.29, WP.29, GRE, no, ECE, ...</td>\n",
       "      <td>[Comité administratif de l'Accord de 1958]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7778</th>\n",
       "      <td>7779</td>\n",
       "      <td>Le Bureau du recensement des États-Unis a pris...</td>\n",
       "      <td>[[293, 298]]</td>\n",
       "      <td>[[256, 291]]</td>\n",
       "      <td>[CSPro]</td>\n",
       "      <td>[Census and Survey Processing System]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7779</th>\n",
       "      <td>7780</td>\n",
       "      <td>2.12 Par &lt;&lt;masse en ordre de marche*&gt;&gt;, on ent...</td>\n",
       "      <td>[[166, 169]]</td>\n",
       "      <td>[[133, 164]]</td>\n",
       "      <td>[CFM]</td>\n",
       "      <td>[coefficient maximal de freinage]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7780</th>\n",
       "      <td>7781</td>\n",
       "      <td>Le PNUD reconnaît l'avantage d'UNIFEM en tant ...</td>\n",
       "      <td>[[489, 494], [673, 676], [725, 728], [783, 787...</td>\n",
       "      <td>[[445, 487], [628, 671], [681, 723], [736, 781...</td>\n",
       "      <td>[FNUAP, UIT, OIM, FIDA, UNIFEM, HCR, ONUSIDA, ...</td>\n",
       "      <td>[Fonds des Nations Unies pour la population, U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7781</th>\n",
       "      <td>7782</td>\n",
       "      <td>1. Historique À la vingt-quatrième session du ...</td>\n",
       "      <td>[[101, 106], [167, 172], [164, 166], [161, 163]]</td>\n",
       "      <td>[[46, 99]]</td>\n",
       "      <td>[SCTDG, AC.10, SG, ST]</td>\n",
       "      <td>[Sous-Comité du transport des marchandises dan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7782</th>\n",
       "      <td>7783</td>\n",
       "      <td>4.2.1.13.8 Dans le texte sous la formule, supp...</td>\n",
       "      <td>[[185, 188], [119, 122]]</td>\n",
       "      <td>[[191, 246], [125, 178]]</td>\n",
       "      <td>[TPO, TPO]</td>\n",
       "      <td>[température de la matière au moment de la déc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7783 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                               text  \\\n",
       "0        1  Depuis le début 2000, les organismes des Natio...   \n",
       "1        2  VI. Lutte contre les stupéfiants En janvier 20...   \n",
       "2        3  À moins qu'il ne soit réglé à l'amiable par vo...   \n",
       "3        4  Rapports financiers des Fonds d'affectation sp...   \n",
       "4        5  Le GRE a examiné le document ECE/TRANS/WP.29/G...   \n",
       "...    ...                                                ...   \n",
       "7778  7779  Le Bureau du recensement des États-Unis a pris...   \n",
       "7779  7780  2.12 Par <<masse en ordre de marche*>>, on ent...   \n",
       "7780  7781  Le PNUD reconnaît l'avantage d'UNIFEM en tant ...   \n",
       "7781  7782  1. Historique À la vingt-quatrième session du ...   \n",
       "7782  7783  4.2.1.13.8 Dans le texte sous la formule, supp...   \n",
       "\n",
       "                                               acronyms  \\\n",
       "0                                          [[323, 328]]   \n",
       "1                                          [[107, 112]]   \n",
       "2                  [[396, 399], [544, 547], [308, 314]]   \n",
       "3                                          [[358, 362]]   \n",
       "4     [[454, 458], [400, 405], [390, 392], [214, 219...   \n",
       "...                                                 ...   \n",
       "7778                                       [[293, 298]]   \n",
       "7779                                       [[166, 169]]   \n",
       "7780  [[489, 494], [673, 676], [725, 728], [783, 787...   \n",
       "7781   [[101, 106], [167, 172], [164, 166], [161, 163]]   \n",
       "7782                           [[185, 188], [119, 122]]   \n",
       "\n",
       "                                             long-forms  \\\n",
       "0                                          [[258, 321]]   \n",
       "1                                           [[52, 105]]   \n",
       "2                              [[360, 394], [508, 542]]   \n",
       "3                                          [[332, 356]]   \n",
       "4                                          [[412, 452]]   \n",
       "...                                                 ...   \n",
       "7778                                       [[256, 291]]   \n",
       "7779                                       [[133, 164]]   \n",
       "7780  [[445, 487], [628, 671], [681, 723], [736, 781...   \n",
       "7781                                         [[46, 99]]   \n",
       "7782                           [[191, 246], [125, 178]]   \n",
       "\n",
       "                                          acronyms-text  \\\n",
       "0                                               [ONUDI]   \n",
       "1                                               [UNODC]   \n",
       "2                                    [CCI, AAA, CNUDCI]   \n",
       "3                                                [HCFC]   \n",
       "4     [AC.1, WP.29, no, WP.29, WP.29, GRE, no, ECE, ...   \n",
       "...                                                 ...   \n",
       "7778                                            [CSPro]   \n",
       "7779                                              [CFM]   \n",
       "7780  [FNUAP, UIT, OIM, FIDA, UNIFEM, HCR, ONUSIDA, ...   \n",
       "7781                             [SCTDG, AC.10, SG, ST]   \n",
       "7782                                         [TPO, TPO]   \n",
       "\n",
       "                                        long-forms-text  \n",
       "0     [Organisation des Nations Unies pour le dévelo...  \n",
       "1     [Office des Nations Unies contre la drogue et ...  \n",
       "2     [Chambre de commerce internationale, Associati...  \n",
       "3                            [hydrochlorofluorocabones]  \n",
       "4            [Comité administratif de l'Accord de 1958]  \n",
       "...                                                 ...  \n",
       "7778              [Census and Survey Processing System]  \n",
       "7779                  [coefficient maximal de freinage]  \n",
       "7780  [Fonds des Nations Unies pour la population, U...  \n",
       "7781  [Sous-Comité du transport des marchandises dan...  \n",
       "7782  [température de la matière au moment de la déc...  \n",
       "\n",
       "[7783 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frenchDFTrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f56420f-5de4-416a-a75e-307fa1acaf09",
   "metadata": {},
   "source": [
    "### Writing XLSX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a24c147a-6adb-4386-b586-def5b77988f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-9c8a3c741821>:2: FutureWarning: Use of **kwargs is deprecated, use engine_kwargs instead.\n",
      "  writer = pd.ExcelWriter(\"../data_xlsx/englishDFTrainScientific.xlsx\", engine='xlsxwriter', options={'strings_to_urls': False})\n",
      "<ipython-input-14-9c8a3c741821>:7: FutureWarning: Use of **kwargs is deprecated, use engine_kwargs instead.\n",
      "  writer = pd.ExcelWriter(\"../data_xlsx/englishDFDevScientific.xlsx\", engine='xlsxwriter', options={'strings_to_urls': False})\n",
      "<ipython-input-14-9c8a3c741821>:12: FutureWarning: Use of **kwargs is deprecated, use engine_kwargs instead.\n",
      "  writer = pd.ExcelWriter(\"../data_xlsx/englishDFTrainLegal.xlsx\", engine='xlsxwriter', options={'strings_to_urls': False})\n",
      "<ipython-input-14-9c8a3c741821>:16: FutureWarning: Use of **kwargs is deprecated, use engine_kwargs instead.\n",
      "  writer = pd.ExcelWriter(\"../data_xlsx/englishDFDevLegal.xlsx\", engine='xlsxwriter', options={'strings_to_urls': False})\n",
      "<ipython-input-14-9c8a3c741821>:20: FutureWarning: Use of **kwargs is deprecated, use engine_kwargs instead.\n",
      "  writer = pd.ExcelWriter(\"../data_xlsx/danishDFTrain.xlsx\", engine='xlsxwriter', options={'strings_to_urls': False})\n",
      "<ipython-input-14-9c8a3c741821>:24: FutureWarning: Use of **kwargs is deprecated, use engine_kwargs instead.\n",
      "  writer = pd.ExcelWriter(\"../data_xlsx/danishDFDev.xlsx\", engine='xlsxwriter', options={'strings_to_urls': False})\n",
      "<ipython-input-14-9c8a3c741821>:28: FutureWarning: Use of **kwargs is deprecated, use engine_kwargs instead.\n",
      "  writer = pd.ExcelWriter(\"../data_xlsx/frenchDFTrain.xlsx\", engine='xlsxwriter', options={'strings_to_urls': False})\n",
      "<ipython-input-14-9c8a3c741821>:32: FutureWarning: Use of **kwargs is deprecated, use engine_kwargs instead.\n",
      "  writer = pd.ExcelWriter(\"../data_xlsx/frenchDFDev.xlsx\", engine='xlsxwriter', options={'strings_to_urls': False})\n",
      "<ipython-input-14-9c8a3c741821>:36: FutureWarning: Use of **kwargs is deprecated, use engine_kwargs instead.\n",
      "  writer = pd.ExcelWriter(\"../data_xlsx/persianDFTrain.xlsx\", engine='xlsxwriter', options={'strings_to_urls': False})\n",
      "<ipython-input-14-9c8a3c741821>:40: FutureWarning: Use of **kwargs is deprecated, use engine_kwargs instead.\n",
      "  writer = pd.ExcelWriter(\"../data_xlsx/persianDFDev.xlsx\", engine='xlsxwriter', options={'strings_to_urls': False})\n",
      "<ipython-input-14-9c8a3c741821>:44: FutureWarning: Use of **kwargs is deprecated, use engine_kwargs instead.\n",
      "  writer = pd.ExcelWriter(\"../data_xlsx/spanishDFTrain.xlsx\", engine='xlsxwriter', options={'strings_to_urls': False})\n",
      "<ipython-input-14-9c8a3c741821>:48: FutureWarning: Use of **kwargs is deprecated, use engine_kwargs instead.\n",
      "  writer = pd.ExcelWriter(\"../data_xlsx/spanishDFDev.xlsx\", engine='xlsxwriter', options={'strings_to_urls': False})\n",
      "<ipython-input-14-9c8a3c741821>:53: FutureWarning: Use of **kwargs is deprecated, use engine_kwargs instead.\n",
      "  writer = pd.ExcelWriter(\"../data_xlsx/vietnameseDFTrain.xlsx\", engine='xlsxwriter', options={'strings_to_urls': False})\n",
      "<ipython-input-14-9c8a3c741821>:58: FutureWarning: Use of **kwargs is deprecated, use engine_kwargs instead.\n",
      "  writer = pd.ExcelWriter(\"../data_xlsx/vietnameseDFDev.xlsx\", engine='xlsxwriter', options={'strings_to_urls': False})\n"
     ]
    }
   ],
   "source": [
    "englishDFTrainScientific = englishDFTrainScientific.applymap(lambda x: x.encode('unicode_escape').decode('utf-8') if isinstance(x, str) else x)\n",
    "writer = pd.ExcelWriter(\"../data_xlsx/englishDFTrainScientific.xlsx\", engine='xlsxwriter', options={'strings_to_urls': False})\n",
    "englishDFTrainScientific.to_excel(writer, index = False, encoding='utf8')\n",
    "writer.save()\n",
    "\n",
    "englishDFDevScientific = englishDFDevScientific.applymap(lambda x: x.encode('unicode_escape').decode('utf-8') if isinstance(x, str) else x)\n",
    "writer = pd.ExcelWriter(\"../data_xlsx/englishDFDevScientific.xlsx\", engine='xlsxwriter', options={'strings_to_urls': False})\n",
    "englishDFDevScientific.to_excel(writer, index = False, encoding='utf8')\n",
    "writer.save()\n",
    "\n",
    "englishDFTrainLegal = englishDFTrainLegal.applymap(lambda x: x.encode('unicode_escape').decode('utf-8') if isinstance(x, str) else x)\n",
    "writer = pd.ExcelWriter(\"../data_xlsx/englishDFTrainLegal.xlsx\", engine='xlsxwriter', options={'strings_to_urls': False})\n",
    "englishDFTrainLegal.to_excel(writer, index = False, encoding='utf8')\n",
    "writer.save()\n",
    "\n",
    "writer = pd.ExcelWriter(\"../data_xlsx/englishDFDevLegal.xlsx\", engine='xlsxwriter', options={'strings_to_urls': False})\n",
    "englishDFDevLegal.to_excel(writer, index = False, encoding='utf8')\n",
    "writer.save()\n",
    "\n",
    "writer = pd.ExcelWriter(\"../data_xlsx/danishDFTrain.xlsx\", engine='xlsxwriter', options={'strings_to_urls': False})\n",
    "danishDFTrain.to_excel(writer, index = False, encoding='utf8')\n",
    "writer.save()\n",
    "\n",
    "writer = pd.ExcelWriter(\"../data_xlsx/danishDFDev.xlsx\", engine='xlsxwriter', options={'strings_to_urls': False})\n",
    "danishDFDev.to_excel(writer, index = False, encoding='utf8')\n",
    "writer.save()\n",
    "\n",
    "writer = pd.ExcelWriter(\"../data_xlsx/frenchDFTrain.xlsx\", engine='xlsxwriter', options={'strings_to_urls': False})\n",
    "frenchDFTrain.to_excel(writer, index = False, encoding='utf8')\n",
    "writer.save()\n",
    "\n",
    "writer = pd.ExcelWriter(\"../data_xlsx/frenchDFDev.xlsx\", engine='xlsxwriter', options={'strings_to_urls': False})\n",
    "frenchDFDev.to_excel(writer, index = False, encoding='utf8')\n",
    "writer.save()\n",
    "\n",
    "writer = pd.ExcelWriter(\"../data_xlsx/persianDFTrain.xlsx\", engine='xlsxwriter', options={'strings_to_urls': False})\n",
    "persianDFTrain.to_excel(writer, index = False, encoding='utf8')\n",
    "writer.save()\n",
    "\n",
    "writer = pd.ExcelWriter(\"../data_xlsx/persianDFDev.xlsx\", engine='xlsxwriter', options={'strings_to_urls': False})\n",
    "persianDFDev.to_excel(writer, index = False, encoding='utf8')\n",
    "writer.save()\n",
    "\n",
    "writer = pd.ExcelWriter(\"../data_xlsx/spanishDFTrain.xlsx\", engine='xlsxwriter', options={'strings_to_urls': False})\n",
    "spanishDFTrain.to_excel(writer, index = False, encoding='utf8')\n",
    "writer.save()\n",
    "\n",
    "writer = pd.ExcelWriter(\"../data_xlsx/spanishDFDev.xlsx\", engine='xlsxwriter', options={'strings_to_urls': False})\n",
    "spanishDFDev.to_excel(writer, index = False, encoding='utf8')\n",
    "writer.save()\n",
    "\n",
    "vietnameseDFTrain = vietnameseDFTrain.applymap(lambda x: x.encode('unicode_escape').decode('utf-8') if isinstance(x, str) else x)\n",
    "writer = pd.ExcelWriter(\"../data_xlsx/vietnameseDFTrain.xlsx\", engine='xlsxwriter', options={'strings_to_urls': False})\n",
    "vietnameseDFTrain.to_excel(writer, index = False, encoding='utf8')\n",
    "writer.save()\n",
    "\n",
    "vietnameseDFDev = vietnameseDFDev.applymap(lambda x: x.encode('unicode_escape').decode('utf-8') if isinstance(x, str) else x)\n",
    "writer = pd.ExcelWriter(\"../data_xlsx/vietnameseDFDev.xlsx\", engine='xlsxwriter', options={'strings_to_urls': False})\n",
    "vietnameseDFDev.to_excel(writer, index = False, encoding='utf8')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ce56af-b69b-48d0-bad1-ac7bc7789854",
   "metadata": {},
   "source": [
    "# DEFUNCT CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d5e50c-41f5-4f96-95cc-d0ebc5928df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# danishDFTrainList = []\n",
    "# for row in zip(danishDFTrain['ID'], danishDFTrain['text'], danishDFTrain['acronyms'], danishDFTrain['long-forms']):\n",
    "#     danishDFTrainList.append(row)\n",
    "    \n",
    "# danishDFDevList = []\n",
    "# for row in zip(danishDFDev['ID'], danishDFDev['text'], danishDFDev['acronyms'], danishDFDev['long-forms']):\n",
    "#     danishDFDevList.append(row)\n",
    "# englishDFTrainScientificList = []\n",
    "# for row in zip(englishDFTrainScientific['ID'], englishDFTrainScientific['text'], englishDFTrainScientific['acronyms'], englishDFTrainScientific['long-forms']):\n",
    "#     englishDFTrainScientificList.append(row)\n",
    "    \n",
    "# englishDFDevScientificList = []\n",
    "# for row in zip(englishDFDevScientific['ID'], englishDFDevScientific['text'], englishDFDevScientific['acronyms'], englishDFDevScientific['long-forms']):\n",
    "#     englishDFDevScientificList.append(row)\n",
    "\n",
    "# englishDFTrainLegalList = []\n",
    "# for row in zip(englishDFTrainLegal['ID'], englishDFTrainLegal['text'], englishDFTrainLegal['acronyms'], englishDFTrainLegal['long-forms']):\n",
    "#     englishDFTrainLegalList.append(row)\n",
    "    \n",
    "# englishDFDevLegalList = []\n",
    "# for row in zip(englishDFDevLegal['ID'], englishDFDevLegal['text'], englishDFDevLegal['acronyms'], englishDFDevLegal['long-forms']):\n",
    "#     englishDFDevLegalList.append(row)\n",
    "# frenchDFTrainList = []\n",
    "# for row in zip(frenchDFTrain['ID'], frenchDFTrain['text'], frenchDFTrain['acronyms'], frenchDFTrain['long-forms']):\n",
    "#     frenchDFTrainList.append(row)\n",
    "    \n",
    "# frenchDFDevList = []\n",
    "# for row in zip(frenchDFDev['ID'], frenchDFDev['text'], frenchDFDev['acronyms'], frenchDFDev['long-forms']):\n",
    "#     frenchDFDevList.append(row)\n",
    "# persianDFTrainList = []\n",
    "# for row in zip(persianDFTrain['ID'], persianDFTrain['text'], persianDFTrain['acronyms'], persianDFTrain['long-forms']):\n",
    "#     persianDFTrainList.append(row)\n",
    "\n",
    "# persianDFDevList = []\n",
    "# for row in zip(persianDFDev['ID'], persianDFDev['text'], persianDFDev['acronyms'], persianDFDev['long-forms']):\n",
    "#     persianDFDevList.append(row)\n",
    "# spanishDFTrainList = []\n",
    "# for row in zip(spanishDFTrain['ID'], spanishDFTrain['text'], spanishDFTrain['acronyms'], spanishDFTrain['long-forms']):\n",
    "#     spanishDFTrainList.append(row)\n",
    "    \n",
    "# spanishDFDevList = []\n",
    "# for row in zip(spanishDFDev['ID'], spanishDFDev['text'], spanishDFDev['acronyms'], spanishDFDev['long-forms']):\n",
    "#     spanishDFDevList.append(row)\n",
    "# vietnameseDFTrainList = []\n",
    "# for row in zip(vietnameseDFTrain['ID'], vietnameseDFTrain['text'], vietnameseDFTrain['acronyms'], vietnameseDFTrain['long-forms']):\n",
    "#     vietnameseDFTrainList.append(row)\n",
    "    \n",
    "# vietnameseDFDevList = []\n",
    "# for row in zip(vietnameseDFDev['ID'], vietnameseDFDev['text'], vietnameseDFDev['acronyms'], vietnameseDFDev['long-forms']):\n",
    "#     vietnameseDFDevList.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e895b888-433c-4993-bd3e-ab888a8bf3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# englishDFTrainScientific['acronyms-text'] = englishDFTrainScientificAcronyms\n",
    "# englishDFTrainScientific['long-forms-text'] = englishDFTrainScientificLFs\n",
    "# englishDFDevScientific['acronyms-text'] = englishDFDevScientificAcronyms\n",
    "# englishDFDevScientific['long-forms-text'] = englishDFDevScientificLFs\n",
    "# englishDFTrainLegal['acronyms-text'] = englishDFTrainLegalAcronyms\n",
    "# englishDFTrainLegal['long-forms-text'] = englishDFTrainLegalLFs\n",
    "# englishDFDevLegal['acronyms-text'] = englishDFDevLegalAcronyms\n",
    "# englishDFDevLegal['long-forms-text'] = englishDFDevLegalLFs\n",
    "# danishDFTrain['acronyms-text'] = danishDFTrainAcronyms\n",
    "# danishDFTrain['long-forms-text'] = danishDFTrainLFs\n",
    "# danishDFDev['acronyms-text'] = danishDFDevAcronyms\n",
    "# danishDFDev['long-forms-text'] = danishDFDevLFs\n",
    "# frenchDFTrain['acronyms-text'] = frenchDFTrainAcronyms\n",
    "# frenchDFTrain['long-forms-text'] = frenchDFTrainLFs\n",
    "# frenchDFDev['acronyms-text'] = frenchDFDevAcronyms\n",
    "# frenchDFDev['long-forms-text'] = frenchDFDevLFs\n",
    "# persianDFTrain['acronyms-text'] = persianDFTrainAcronyms\n",
    "# persianDFTrain['long-forms-text'] = persianDFTrainLFs\n",
    "# persianDFDev['acronyms-text'] = persianDFDevAcronyms\n",
    "# persianDFDev['long-forms-text'] = persianDFDevLFs\n",
    "# spanishDFTrain['acronyms-text'] = spanishDFTrainAcronyms\n",
    "# spanishDFTrain['long-forms-text'] = spanishDFTrainLFs\n",
    "# spanishDFDev['acronyms-text'] = spanishDFDevAcronyms\n",
    "# spanishDFDev['long-forms-text'] = spanishDFDevLFs\n",
    "# vietnameseDFTrain['acronyms-text'] = vietnameseDFTrainAcronyms\n",
    "# vietnameseDFTrain['long-forms-text'] = vietnameseDFTrainLFs\n",
    "# vietnameseDFDev['acronyms-text'] = vietnameseDFDevAcronyms\n",
    "# vietnameseDFDev['long-forms-text'] = vietnameseDFDevLFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1798dae-40d0-434c-8412-d2887578f965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# englishDFTrainScientificAcronyms = []\n",
    "# englishDFTrainScientificLFs = []\n",
    "# count = 0\n",
    "\n",
    "# for row in englishDFTrainScientificList:\n",
    "#     tempACRList = []\n",
    "#     tempLFList = []\n",
    "#     for acr, lf in zip(row[2], row[3]):\n",
    "# #         count1 = len(acr)\n",
    "# #         count2 = len(lf)\n",
    "#         acronym = []\n",
    "#         longform = []\n",
    "        \n",
    "#         textChars = list(row[1])\n",
    "#         for i in range(acr[0], acr[1]):\n",
    "#             acronym.append(textChars[i])\n",
    "#         for i in range(lf[0], lf[1]):\n",
    "#             longform.append(textChars[i])\n",
    "        \n",
    "#         tempACRList.append(str(''.join(acronym)))\n",
    "#         tempLFList.append(str(''.join(longform)))\n",
    "        \n",
    "#     englishDFTrainScientificAcronyms.append(tempACRList)\n",
    "#     englishDFTrainScientificLFs.append(tempLFList)\n",
    "#     count+=1\n",
    "# englishDFDevScientificAcronyms = []\n",
    "# englishDFDevScientificLFs = []\n",
    "# count = 0\n",
    "\n",
    "# for row in englishDFDevScientificList:\n",
    "#     tempACRList = []\n",
    "#     tempLFList = []\n",
    "#     for acr, lf in zip(row[2], row[3]):\n",
    "# #         count1 = len(acr)\n",
    "# #         count2 = len(lf)\n",
    "#         acronym = []\n",
    "#         longform = []\n",
    "        \n",
    "#         textChars = list(row[1])\n",
    "#         for i in range(acr[0], acr[1]):\n",
    "#             acronym.append(textChars[i])\n",
    "#         for i in range(lf[0], lf[1]):\n",
    "#             longform.append(textChars[i])\n",
    "        \n",
    "#         tempACRList.append(''.join(acronym))\n",
    "#         tempLFList.append(''.join(longform))\n",
    "        \n",
    "#     englishDFDevScientificAcronyms.append(tempACRList)\n",
    "#     englishDFDevScientificLFs.append(tempLFList)\n",
    "#     count+=1\n",
    "# englishDFTrainLegalAcronyms = []\n",
    "# englishDFTrainLegalLFs = []\n",
    "# count = 0\n",
    "\n",
    "# for row in englishDFTrainLegalList:\n",
    "#     tempACRList = []\n",
    "#     tempLFList = []\n",
    "#     for acr, lf in zip(row[2], row[3]):\n",
    "# #         count1 = len(acr)\n",
    "# #         count2 = len(lf)\n",
    "#         acronym = []\n",
    "#         longform = []\n",
    "        \n",
    "#         textChars = list(row[1])\n",
    "#         for i in range(acr[0], acr[1]):\n",
    "#             acronym.append(textChars[i])\n",
    "#         for i in range(lf[0], lf[1]):\n",
    "#             longform.append(textChars[i])\n",
    "        \n",
    "#         tempACRList.append(''.join(acronym))\n",
    "#         tempLFList.append(''.join(longform))\n",
    "        \n",
    "#     englishDFTrainLegalAcronyms.append(tempACRList)\n",
    "#     englishDFTrainLegalLFs.append(tempLFList)\n",
    "#     count+=1\n",
    "# englishDFDevLegalAcronyms = []\n",
    "# englishDFDevLegalLFs = []\n",
    "# count = 0\n",
    "\n",
    "# for row in englishDFDevLegalList:\n",
    "#     tempACRList = []\n",
    "#     tempLFList = []\n",
    "#     for acr, lf in zip(row[2], row[3]):\n",
    "# #         count1 = len(acr)\n",
    "# #         count2 = len(lf)\n",
    "#         acronym = []\n",
    "#         longform = []\n",
    "        \n",
    "#         textChars = list(row[1])\n",
    "#         for i in range(acr[0], acr[1]):\n",
    "#             acronym.append(textChars[i])\n",
    "#         for i in range(lf[0], lf[1]):\n",
    "#             longform.append(textChars[i])\n",
    "        \n",
    "#         tempACRList.append(''.join(acronym))\n",
    "#         tempLFList.append(''.join(longform))\n",
    "        \n",
    "#     englishDFDevLegalAcronyms.append(tempACRList)\n",
    "#     englishDFDevLegalLFs.append(tempLFList)\n",
    "#     count+=1\n",
    "# danishDFTrainAcronyms = []\n",
    "# danishDFTrainLFs = []\n",
    "# count = 0\n",
    "\n",
    "# for row in danishDFTrainList:\n",
    "#     tempACRList = []\n",
    "#     tempLFList = []\n",
    "#     for acr, lf in zip(row[2], row[3]):\n",
    "# #         count1 = len(acr)\n",
    "# #         count2 = len(lf)\n",
    "#         acronym = []\n",
    "#         longform = []\n",
    "        \n",
    "#         textChars = list(row[1])\n",
    "#         for i in range(acr[0], acr[1]):\n",
    "#             acronym.append(textChars[i])\n",
    "#         for i in range(lf[0], lf[1]):\n",
    "#             longform.append(textChars[i])\n",
    "        \n",
    "#         tempACRList.append(''.join(acronym))\n",
    "#         tempLFList.append(''.join(longform))\n",
    "        \n",
    "#     danishDFTrainAcronyms.append(tempACRList)\n",
    "#     danishDFTrainLFs.append(tempLFList)\n",
    "#     count+=1\n",
    "# danishDFDevAcronyms = []\n",
    "# danishDFDevLFs = []\n",
    "# count = 0\n",
    "\n",
    "# for row in danishDFDevList:\n",
    "#     tempACRList = []\n",
    "#     tempLFList = []\n",
    "#     for acr, lf in zip(row[2], row[3]):\n",
    "# #         count1 = len(acr)\n",
    "# #         count2 = len(lf)\n",
    "#         acronym = []\n",
    "#         longform = []\n",
    "        \n",
    "#         textChars = list(row[1])\n",
    "#         for i in range(acr[0], acr[1]):\n",
    "#             acronym.append(textChars[i])\n",
    "#         for i in range(lf[0], lf[1]):\n",
    "#             longform.append(textChars[i])\n",
    "        \n",
    "#         tempACRList.append(''.join(acronym))\n",
    "#         tempLFList.append(''.join(longform))\n",
    "        \n",
    "#     danishDFDevAcronyms.append(tempACRList)\n",
    "#     danishDFDevLFs.append(tempLFList)\n",
    "#     count+=1\n",
    "# frenchDFTrainAcronyms = []\n",
    "# frenchDFTrainLFs = []\n",
    "# count = 0\n",
    "\n",
    "# for row in frenchDFTrainList:\n",
    "#     tempACRList = []\n",
    "#     tempLFList = []\n",
    "#     for acr, lf in zip(row[2], row[3]):\n",
    "# #         count1 = len(acr)\n",
    "# #         count2 = len(lf)\n",
    "#         acronym = []\n",
    "#         longform = []\n",
    "        \n",
    "#         textChars = list(row[1])\n",
    "#         for i in range(acr[0], acr[1]):\n",
    "#             acronym.append(textChars[i])\n",
    "#         for i in range(lf[0], lf[1]):\n",
    "#             longform.append(textChars[i])\n",
    "        \n",
    "#         tempACRList.append(''.join(acronym))\n",
    "#         tempLFList.append(''.join(longform))\n",
    "        \n",
    "#     frenchDFTrainAcronyms.append(tempACRList)\n",
    "#     frenchDFTrainLFs.append(tempLFList)\n",
    "#     count+=1\n",
    "# frenchDFDevAcronyms = []\n",
    "# frenchDFDevLFs = []\n",
    "# count = 0\n",
    "\n",
    "# for row in frenchDFDevList:\n",
    "#     tempACRList = []\n",
    "#     tempLFList = []\n",
    "#     for acr, lf in zip(row[2], row[3]):\n",
    "# #         count1 = len(acr)\n",
    "# #         count2 = len(lf)\n",
    "#         acronym = []\n",
    "#         longform = []\n",
    "        \n",
    "#         textChars = list(row[1])\n",
    "#         for i in range(acr[0], acr[1]):\n",
    "#             acronym.append(textChars[i])\n",
    "#         for i in range(lf[0], lf[1]):\n",
    "#             longform.append(textChars[i])\n",
    "        \n",
    "#         tempACRList.append(''.join(acronym))\n",
    "#         tempLFList.append(''.join(longform))\n",
    "        \n",
    "#     frenchDFDevAcronyms.append(tempACRList)\n",
    "#     frenchDFDevLFs.append(tempLFList)\n",
    "#     count+=1\n",
    "# persianDFTrainAcronyms = []\n",
    "# persianDFTrainLFs = []\n",
    "# count = 0\n",
    "\n",
    "# for row in persianDFTrainList:\n",
    "#     tempACRList = []\n",
    "#     tempLFList = []\n",
    "#     for acr, lf in zip(row[2], row[3]):\n",
    "# #         count1 = len(acr)\n",
    "# #         count2 = len(lf)\n",
    "#         acronym = []\n",
    "#         longform = []\n",
    "        \n",
    "#         textChars = list(row[1])\n",
    "#         for i in range(acr[0], acr[1]):\n",
    "#             acronym.append(textChars[i])\n",
    "#         for i in range(lf[0], lf[1]):\n",
    "#             longform.append(textChars[i])\n",
    "        \n",
    "#         tempACRList.append(''.join(acronym))\n",
    "#         tempLFList.append(''.join(longform))\n",
    "        \n",
    "#     persianDFTrainAcronyms.append(tempACRList)\n",
    "#     persianDFTrainLFs.append(tempLFList)\n",
    "#     count+=1\n",
    "# persianDFDevAcronyms = []\n",
    "# persianDFDevLFs = []\n",
    "# count = 0\n",
    "\n",
    "# for row in persianDFDevList:\n",
    "#     tempACRList = []\n",
    "#     tempLFList = []\n",
    "#     for acr, lf in zip(row[2], row[3]):\n",
    "# #         count1 = len(acr)\n",
    "# #         count2 = len(lf)\n",
    "#         acronym = []\n",
    "#         longform = []\n",
    "        \n",
    "#         textChars = list(row[1])\n",
    "#         for i in range(acr[0], acr[1]):\n",
    "#             acronym.append(textChars[i])\n",
    "#         for i in range(lf[0], lf[1]):\n",
    "#             longform.append(textChars[i])\n",
    "        \n",
    "#         tempACRList.append(''.join(acronym))\n",
    "#         tempLFList.append(''.join(longform))\n",
    "        \n",
    "#     persianDFDevAcronyms.append(tempACRList)\n",
    "#     persianDFDevLFs.append(tempLFList)\n",
    "#     count+=1\n",
    "# spanishDFTrainAcronyms = []\n",
    "# spanishDFTrainLFs = []\n",
    "# count = 0\n",
    "\n",
    "# for row in spanishDFTrainList:\n",
    "#     tempACRList = []\n",
    "#     tempLFList = []\n",
    "#     for acr, lf in zip(row[2], row[3]):\n",
    "# #         count1 = len(acr)\n",
    "# #         count2 = len(lf)\n",
    "#         acronym = []\n",
    "#         longform = []\n",
    "        \n",
    "#         textChars = list(row[1])\n",
    "#         for i in range(acr[0], acr[1]):\n",
    "#             acronym.append(textChars[i])\n",
    "#         for i in range(lf[0], lf[1]):\n",
    "#             longform.append(textChars[i])\n",
    "        \n",
    "#         tempACRList.append(''.join(acronym))\n",
    "#         tempLFList.append(''.join(longform))\n",
    "        \n",
    "#     spanishDFTrainAcronyms.append(tempACRList)\n",
    "#     spanishDFTrainLFs.append(tempLFList)\n",
    "#     count+=1\n",
    "# spanishDFDevAcronyms = []\n",
    "# spanishDFDevLFs = []\n",
    "# count = 0\n",
    "\n",
    "# for row in spanishDFDevList:\n",
    "#     tempACRList = []\n",
    "#     tempLFList = []\n",
    "#     for acr, lf in zip(row[2], row[3]):\n",
    "# #         count1 = len(acr)\n",
    "# #         count2 = len(lf)\n",
    "#         acronym = []\n",
    "#         longform = []\n",
    "        \n",
    "#         textChars = list(row[1])\n",
    "#         for i in range(acr[0], acr[1]):\n",
    "#             acronym.append(textChars[i])\n",
    "#         for i in range(lf[0], lf[1]):\n",
    "#             longform.append(textChars[i])\n",
    "        \n",
    "#         tempACRList.append(''.join(acronym))\n",
    "#         tempLFList.append(''.join(longform))\n",
    "        \n",
    "#     spanishDFDevAcronyms.append(tempACRList)\n",
    "#     spanishDFDevLFs.append(tempLFList)\n",
    "#     count+=1\n",
    "# vietnameseDFTrainAcronyms = []\n",
    "# vietnameseDFTrainLFs = []\n",
    "# count = 0\n",
    "\n",
    "# for row in vietnameseDFTrainList:\n",
    "#     tempACRList = []\n",
    "#     tempLFList = []\n",
    "#     for acr, lf in zip(row[2], row[3]):\n",
    "# #         count1 = len(acr)\n",
    "# #         count2 = len(lf)\n",
    "#         acronym = []\n",
    "#         longform = []\n",
    "        \n",
    "#         textChars = list(row[1])\n",
    "#         for i in range(acr[0], acr[1]):\n",
    "#             acronym.append(textChars[i])\n",
    "#         for i in range(lf[0], lf[1]):\n",
    "#             longform.append(textChars[i])\n",
    "        \n",
    "#         tempACRList.append(''.join(acronym))\n",
    "#         tempLFList.append(''.join(longform))\n",
    "        \n",
    "#     vietnameseDFTrainAcronyms.append(tempACRList)\n",
    "#     vietnameseDFTrainLFs.append(tempLFList)\n",
    "#     count+=1\n",
    "# vietnameseDFDevAcronyms = []\n",
    "# vietnameseDFDevLFs = []\n",
    "# count = 0\n",
    "\n",
    "# for row in vietnameseDFDevList:\n",
    "#     tempACRList = []\n",
    "#     tempLFList = []\n",
    "#     for acr, lf in zip(row[2], row[3]):\n",
    "# #         count1 = len(acr)\n",
    "# #         count2 = len(lf)\n",
    "#         acronym = []\n",
    "#         longform = []\n",
    "        \n",
    "#         textChars = list(row[1])\n",
    "#         for i in range(acr[0], acr[1]):\n",
    "#             acronym.append(textChars[i])\n",
    "#         for i in range(lf[0], lf[1]):\n",
    "#             longform.append(textChars[i])\n",
    "        \n",
    "#         tempACRList.append(''.join(acronym))\n",
    "#         tempLFList.append(''.join(longform))\n",
    "        \n",
    "#     vietnameseDFDevAcronyms.append(tempACRList)\n",
    "#     vietnameseDFDevLFs.append(tempLFList)\n",
    "#     count+=1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
