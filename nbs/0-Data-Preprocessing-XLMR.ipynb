{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Author: Prashant K. Sharma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io, sys\n",
    "import json\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import word_tokenize\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/diptesh/workspace/PR-AAAI22-SDU-ST1-AE/nbs\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = [\"danish\", \"english\", \"french\", \"persian\", \"spanish\", \"vietnamese\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON to TSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "danishDFTrain = pd.read_json(\"../data/\"+langs[0]+\"/train.json\")\n",
    "danishDFDev = pd.read_json(\"../data/\"+langs[0]+\"/dev.json\")\n",
    "\n",
    "englishDFTrainLegal = pd.read_json(\"../data/\"+langs[1]+\"/legal/train.json\")\n",
    "englishDFDevLegal = pd.read_json(\"../data/\"+langs[1]+\"/legal/dev.json\")\n",
    "englishDFTrainScientific = pd.read_json(\"../data/\"+langs[1]+\"/scientific/train.json\")\n",
    "englishDFDevScientific = pd.read_json(\"../data/\"+langs[1]+\"/scientific/dev.json\")\n",
    "\n",
    "frenchDFTrain = pd.read_json(\"../data/\"+langs[2]+\"/train.json\")\n",
    "frenchDFDev = pd.read_json(\"../data/\"+langs[2]+\"/dev.json\")\n",
    "\n",
    "persianDFTrain = pd.read_json(\"../data/\"+langs[3]+\"/train.json\")\n",
    "persianDFDev = pd.read_json(\"../data/\"+langs[3]+\"/dev.json\")\n",
    "\n",
    "spanishDFTrain = pd.read_json(\"../data/\"+langs[4]+\"/train.json\")\n",
    "spanishDFDev = pd.read_json(\"../data/\"+langs[4]+\"/dev.json\")\n",
    "\n",
    "vietnameseDFTrain = pd.read_json(\"../data/\"+langs[5]+\"/train.json\")\n",
    "vietnameseDFDev = pd.read_json(\"../data/\"+langs[5]+\"/dev.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' An arguably better approach to representation learning is Canonical Correlation Analysis (CCA) that induces representations that are maximally cor-',\n",
       " [[91, 94]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "englishDFTrainScientific.text[2], englishDFTrainScientific.acronyms[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extracting text from the numerical indexes (Hadeel's Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTHOR: Hadeel S\n",
    "\n",
    "def create_acronyms(data):\n",
    "    acs2 = []\n",
    "    longf = []\n",
    "\n",
    "    acros = data.acronyms.values\n",
    "    txt = data.text.values\n",
    "    zipped = list(zip(txt,acros))\n",
    "    for z in zipped:\n",
    "        acs = []\n",
    "        for i in range(len(z[1])):\n",
    "            acs.append(z[0][z[1][i][0]:z[1][i][1]])\n",
    "        acs2.append(acs)\n",
    "    data['acronyms-text'] =acs2\n",
    "    \n",
    "# Creating long forms from here\n",
    "\n",
    "    longform = data[\"long-forms\"].values\n",
    "    zipped2 = list(zip(txt,longform))\n",
    "    for z2 in zipped2:\n",
    "        longform_temp = []\n",
    "        for i in range(len(z2[1])):\n",
    "            longform_temp.append(z2[0][z2[1][i][0]:z2[1][i][1]])\n",
    "        longf.append(longform_temp)\n",
    "    data[\"long-forms-text\"]= longf\n",
    "    \n",
    "    return data\n",
    "#     return data.to_csv(\"datatsvs/\" + name +\".tsv\", index = False, encoding='utf8', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "englishDFTrainScientific = create_acronyms(englishDFTrainScientific)\n",
    "englishDFDevScientific = create_acronyms(englishDFDevScientific)\n",
    "englishDFTrainLegal = create_acronyms(englishDFTrainLegal)\n",
    "englishDFDevLegal = create_acronyms(englishDFDevLegal)\n",
    "danishDFTrain = create_acronyms(danishDFTrain)\n",
    "danishDFDev = create_acronyms(danishDFDev)\n",
    "frenchDFTrain = create_acronyms(frenchDFTrain)\n",
    "frenchDFDev = create_acronyms(frenchDFDev)\n",
    "persianDFTrain = create_acronyms(persianDFTrain)\n",
    "persianDFDev = create_acronyms(persianDFDev)\n",
    "spanishDFTrain = create_acronyms(spanishDFTrain)\n",
    "spanishDFDev = create_acronyms(spanishDFDev)\n",
    "vietnameseDFTrain = create_acronyms(vietnameseDFTrain)\n",
    "vietnameseDFDev = create_acronyms(vietnameseDFDev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating columns for proper TSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "englishDFTrainScientific = englishDFTrainScientific[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "englishDFDevScientific = englishDFDevScientific[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "englishDFTrainLegal = englishDFTrainLegal[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "englishDFDevLegal = englishDFDevLegal[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "danishDFTrain = danishDFTrain[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "danishDFDev = danishDFDev[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "frenchDFTrain = frenchDFTrain[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "frenchDFDev = frenchDFDev[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "persianDFTrain = persianDFTrain[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "persianDFDev = persianDFDev[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "spanishDFTrain = spanishDFTrain[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "spanishDFDev = spanishDFDev[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "vietnameseDFTrain = vietnameseDFTrain[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "vietnameseDFDev = vietnameseDFDev[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "allLangDFTrain = englishDFTrainScientific.append(englishDFTrainLegal, ignore_index=True).append(danishDFTrain, ignore_index=True).append(frenchDFTrain, ignore_index=True).append(persianDFTrain, ignore_index=True).append(spanishDFTrain, ignore_index=True).append(vietnameseDFTrain, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>acronyms</th>\n",
       "      <th>long-forms</th>\n",
       "      <th>acronyms-text</th>\n",
       "      <th>long-forms-text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23265</th>\n",
       "      <td>3521</td>\n",
       "      <td>La información que figura en la presente secci...</td>\n",
       "      <td>[[672, 675]]</td>\n",
       "      <td>[[641, 670]]</td>\n",
       "      <td>[FMI]</td>\n",
       "      <td>[Fondo Monetario Internacional]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>696</td>\n",
       "      <td>are contained in a XML file and each query  co...</td>\n",
       "      <td>[[90, 93], [19, 22], [107, 112], [130, 134], [...</td>\n",
       "      <td>[[83, 88], [101, 106], [142, 151]]</td>\n",
       "      <td>[NUM, XML, TITLE, DESC, NARR]</td>\n",
       "      <td>[Numbe, Title, Narrative]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21455</th>\n",
       "      <td>1711</td>\n",
       "      <td>Entre 2000 y 2003, se realizaron tres evaluaci...</td>\n",
       "      <td>[[225, 229], [270, 273], [135, 140]]</td>\n",
       "      <td>[[181, 223], [236, 268]]</td>\n",
       "      <td>[OIEA, OMS, PNUMA]</td>\n",
       "      <td>[Organismo Internacional de Energía Atómica, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15670</th>\n",
       "      <td>5045</td>\n",
       "      <td>Elle a rappelé que l'institution d'un barème d...</td>\n",
       "      <td>[[459, 462]]</td>\n",
       "      <td>[[421, 457]]</td>\n",
       "      <td>[CAC]</td>\n",
       "      <td>[Comité administratif de coordination]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17332</th>\n",
       "      <td>6707</td>\n",
       "      <td>Cette question occupe une place croissante dan...</td>\n",
       "      <td>[[124, 127]]</td>\n",
       "      <td>[[84, 122]]</td>\n",
       "      <td>[OIT]</td>\n",
       "      <td>[Organisation internationale du Travail]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>4066</td>\n",
       "      <td>Los organismos integrantes del Comité Ejecutiv...</td>\n",
       "      <td>[[357, 360], [900, 906], [568, 575], [639, 645]]</td>\n",
       "      <td>[[317, 355], [833, 898], [460, 566], [581, 637]]</td>\n",
       "      <td>[OIT, ACNUDH, ONUSIDA, UNIFEM]</td>\n",
       "      <td>[Organización Internacional del Trabajo, Alto ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17869</th>\n",
       "      <td>7244</td>\n",
       "      <td>Costa Rica a également proposé la création d'u...</td>\n",
       "      <td>[[422, 427]]</td>\n",
       "      <td>[[367, 420]]</td>\n",
       "      <td>[PNMPO]</td>\n",
       "      <td>[Programa Nacional de Microcrédito Produtivo O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2052</th>\n",
       "      <td>2053</td>\n",
       "      <td>constituents. For example, discussing the poss...</td>\n",
       "      <td>[[190, 192]]</td>\n",
       "      <td>[[170, 188]]</td>\n",
       "      <td>[CG]</td>\n",
       "      <td>[Categorial Grammar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24372</th>\n",
       "      <td>4628</td>\n",
       "      <td>Desde que accedió a la independencia en 1921 h...</td>\n",
       "      <td>[[334, 338]]</td>\n",
       "      <td>[[290, 332]]</td>\n",
       "      <td>[PRPM]</td>\n",
       "      <td>[Partido Revolucionario Popular de Mongolia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21148</th>\n",
       "      <td>1404</td>\n",
       "      <td>Asuntos políticos Oficina de las Naciones Unid...</td>\n",
       "      <td>[[121, 126]]</td>\n",
       "      <td>[[102, 119]]</td>\n",
       "      <td>[UNSOM]</td>\n",
       "      <td>[Unidas en Somalia]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26947 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                               text  \\\n",
       "23265  3521  La información que figura en la presente secci...   \n",
       "695     696  are contained in a XML file and each query  co...   \n",
       "21455  1711  Entre 2000 y 2003, se realizaron tres evaluaci...   \n",
       "15670  5045  Elle a rappelé que l'institution d'un barème d...   \n",
       "17332  6707  Cette question occupe une place croissante dan...   \n",
       "...     ...                                                ...   \n",
       "23810  4066  Los organismos integrantes del Comité Ejecutiv...   \n",
       "17869  7244  Costa Rica a également proposé la création d'u...   \n",
       "2052   2053  constituents. For example, discussing the poss...   \n",
       "24372  4628  Desde que accedió a la independencia en 1921 h...   \n",
       "21148  1404  Asuntos políticos Oficina de las Naciones Unid...   \n",
       "\n",
       "                                                acronyms  \\\n",
       "23265                                       [[672, 675]]   \n",
       "695    [[90, 93], [19, 22], [107, 112], [130, 134], [...   \n",
       "21455               [[225, 229], [270, 273], [135, 140]]   \n",
       "15670                                       [[459, 462]]   \n",
       "17332                                       [[124, 127]]   \n",
       "...                                                  ...   \n",
       "23810   [[357, 360], [900, 906], [568, 575], [639, 645]]   \n",
       "17869                                       [[422, 427]]   \n",
       "2052                                        [[190, 192]]   \n",
       "24372                                       [[334, 338]]   \n",
       "21148                                       [[121, 126]]   \n",
       "\n",
       "                                             long-forms  \\\n",
       "23265                                      [[641, 670]]   \n",
       "695                  [[83, 88], [101, 106], [142, 151]]   \n",
       "21455                          [[181, 223], [236, 268]]   \n",
       "15670                                      [[421, 457]]   \n",
       "17332                                       [[84, 122]]   \n",
       "...                                                 ...   \n",
       "23810  [[317, 355], [833, 898], [460, 566], [581, 637]]   \n",
       "17869                                      [[367, 420]]   \n",
       "2052                                       [[170, 188]]   \n",
       "24372                                      [[290, 332]]   \n",
       "21148                                      [[102, 119]]   \n",
       "\n",
       "                        acronyms-text  \\\n",
       "23265                           [FMI]   \n",
       "695     [NUM, XML, TITLE, DESC, NARR]   \n",
       "21455              [OIEA, OMS, PNUMA]   \n",
       "15670                           [CAC]   \n",
       "17332                           [OIT]   \n",
       "...                               ...   \n",
       "23810  [OIT, ACNUDH, ONUSIDA, UNIFEM]   \n",
       "17869                         [PNMPO]   \n",
       "2052                             [CG]   \n",
       "24372                          [PRPM]   \n",
       "21148                         [UNSOM]   \n",
       "\n",
       "                                         long-forms-text  \n",
       "23265                    [Fondo Monetario Internacional]  \n",
       "695                            [Numbe, Title, Narrative]  \n",
       "21455  [Organismo Internacional de Energía Atómica, O...  \n",
       "15670             [Comité administratif de coordination]  \n",
       "17332           [Organisation internationale du Travail]  \n",
       "...                                                  ...  \n",
       "23810  [Organización Internacional del Trabajo, Alto ...  \n",
       "17869  [Programa Nacional de Microcrédito Produtivo O...  \n",
       "2052                                [Categorial Grammar]  \n",
       "24372       [Partido Revolucionario Popular de Mongolia]  \n",
       "21148                                [Unidas en Somalia]  \n",
       "\n",
       "[26947 rows x 6 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allLangDFTrain.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing TSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "englishDFTrainScientific.to_csv(\"../data_tsvs/englishDFTrainScientific.tsv\", sep='\\t', index=False)\n",
    "englishDFDevScientific.to_csv(\"../data_tsvs/englishDFDevScientific.tsv\", sep='\\t', index=False)\n",
    "englishDFTrainLegal.to_csv(\"../data_tsvs/englishDFTrainLegal.tsv\", sep='\\t', index=False)\n",
    "englishDFDevLegal.to_csv(\"../data_tsvs/englishDFDevLegal.tsv\", sep='\\t', index=False)\n",
    "danishDFTrain.to_csv(\"../data_tsvs/danishDFTrain.tsv\", sep='\\t', index=False)\n",
    "danishDFDev.to_csv(\"../data_tsvs/danishDFDev.tsv\", sep='\\t', index=False)\n",
    "frenchDFTrain.to_csv(\"../data_tsvs/frenchDFTrain.tsv\", sep='\\t', index=False)\n",
    "frenchDFDev.to_csv(\"../data_tsvs/frenchDFDev.tsv\", sep='\\t', index=False)\n",
    "persianDFTrain.to_csv(\"../data_tsvs/persianDFTrain.tsv\", sep='\\t', index=False)\n",
    "persianDFDev.to_csv(\"../data_tsvs/persianDFDev.tsv\", sep='\\t', index=False)\n",
    "spanishDFTrain.to_csv(\"../data_tsvs/spanishDFTrain.tsv\", sep='\\t', index=False)\n",
    "spanishDFDev.to_csv(\"../data_tsvs/spanishDFDev.tsv\", sep='\\t', index=False)\n",
    "vietnameseDFTrain.to_csv(\"../data_tsvs/vietnameseDFTrain.tsv\", sep='\\t', index=False)\n",
    "vietnameseDFDev.to_csv(\"../data_tsvs/vietnameseDFDev.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "allLangDFTrain.to_csv(\"../data_tsvs/allLangDFTrain.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSVs to CoNLL format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BIO(txt, an_ids, lf_ids):\n",
    "    \"\"\"\n",
    "    input: text\n",
    "    ouput: tags , bio_tags\n",
    "        \n",
    "        tags :    list (AN, FL, OT)\n",
    "        bio_tags: list (O, B-AN, I-AN, B-LF, I-LF)\n",
    "    \"\"\"\n",
    "    \n",
    "    txt_l = word_tokenize(txt)\n",
    "    \n",
    "    tags = [\"OT\"]*len(txt_l)\n",
    "    bio_tags = [\"B-O\"]*len(txt_l)\n",
    "    \n",
    "    #txt[an_ids[0][0]:an_ids[0][1]]\n",
    "    \n",
    "    ANs = []\n",
    "    LFs = []\n",
    "    \n",
    "    for an_id in an_ids:\n",
    "        ANs.append(txt[an_id[0]:an_id[1]])\n",
    "        \n",
    "    for lf_id in lf_ids:\n",
    "        LFs.append(txt[lf_id[0]:lf_id[1]])\n",
    "    \n",
    "    AN_start = [False]*len(ANs)\n",
    "    LF_start = [False]*len(LFs)\n",
    "    \n",
    "    \n",
    "    for tok_id in range(0,len(txt_l)):\n",
    "        tok = txt_l[tok_id]\n",
    "        \n",
    "        for AN_idx in range(0,len(ANs)):\n",
    "           \n",
    "            AN = ANs[AN_idx]\n",
    "            \n",
    "            if(tok in AN):\n",
    "                tags[tok_id] = \"AN\"\n",
    "                \n",
    "                if(AN_start[AN_idx] == False):\n",
    "                    AN_start[AN_idx] = True\n",
    "                    bio_tags[tok_id] = \"B-AN\"\n",
    "                else:\n",
    "                    bio_tags[tok_id] = \"I-AN\"\n",
    "        \n",
    "        for LF_idx in range(0,len(LFs)):\n",
    "            \n",
    "            LF = LFs[LF_idx]\n",
    "            \n",
    "            if(tok in LF):\n",
    "                tags[tok_id] = \"LF\"\n",
    "                \n",
    "                if(LF_start[LF_idx] == False):\n",
    "                    LF_start[LF_idx] = True\n",
    "                    bio_tags[tok_id] = \"B-LF\"\n",
    "                else:\n",
    "                    bio_tags[tok_id] = \"I-LF\"\n",
    "                    \n",
    "    return txt_l, tags, bio_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(df, idx):\n",
    "    df_i = df.iloc[idx]\n",
    "    \n",
    "    txt = str(df_i[\"text\"]).strip()\n",
    "    acrnm_ids = ast.literal_eval(df_i[\"acronyms\"])\n",
    "    longform_ids = ast.literal_eval(df_i[\"long-forms\"])\n",
    "    \n",
    "    return txt, acrnm_ids, longform_ids\n",
    "\n",
    "def prepare(df, cnt, fname=\"output.txt\"):\n",
    "    \n",
    "    file = open(fname, \"w\")\n",
    "    file.write(\"-DOCSTART- -X- O\\n\\n\")\n",
    "    for idx in tqdm(range(cnt)):\n",
    "        txt, an_ids, lf_ids = extract(df, idx)\n",
    "        \n",
    "        txt_l, tags, bio_tags = BIO(txt, an_ids, lf_ids)\n",
    "        \n",
    "        for txt_id in range(0,len(txt_l)):\n",
    "            string = txt_l[txt_id]+ \" \" + tags[txt_id] + \" \" + bio_tags[txt_id]\n",
    "            \n",
    "            file.write(string + \" \\n\")\n",
    "        file.write(\"\\n\")\n",
    "    file.close()\n",
    "    \n",
    "def convert_to_BIO(fileTrain, fileDev, lang, domain):\n",
    "    df_train = pd.read_csv(fileTrain, sep=\"\\t\")\n",
    "    df_dev = pd.read_csv(fileDev, sep=\"\\t\")\n",
    "    df_combine = df_train.append(df_dev, ignore_index=True)\n",
    "    \n",
    "    cnt_train = df_train.shape[0]\n",
    "    cnt_dev = df_dev.shape[0]\n",
    "    \n",
    "    train_cnt = cnt_train - 500 ## Assuming 300 instances are enough to validate\n",
    "    valid_cnt = 500\n",
    "    test_cnt = cnt_dev\n",
    "    \n",
    "    df_train_ = df_combine.iloc[:train_cnt]\n",
    "    df_valid_ = df_combine.iloc[train_cnt: train_cnt + valid_cnt].reset_index()\n",
    "    df_test_ = df_combine.iloc[train_cnt + valid_cnt: train_cnt + valid_cnt + test_cnt].reset_index()\n",
    "    \n",
    "    # Prepare training file\n",
    "    if ( domain == \"\" ):\n",
    "        prepare(df_train_, train_cnt, \"../processed/\" + lang + \"/train.txt\") # Prepare train file\n",
    "        prepare(df_valid_, valid_cnt, \"../processed/\" + lang + \"/valid.txt\") # Prepare validation file\n",
    "        prepare(df_test_, test_cnt, \"../processed/\" + lang + \"/test.txt\") # Prepare test file\n",
    "    else:\n",
    "        prepare(df_train_, train_cnt, \"../processed/\" + lang + \"/\" + domain + \"/train.txt\") # Prepare train file\n",
    "        prepare(df_valid_, valid_cnt, \"../processed/\" + lang + \"/\" + domain +\"/valid.txt\") # Prepare validation file\n",
    "        prepare(df_test_, test_cnt, \"../processed/\" + lang+  \"/\" + domain + \"/test.txt\") # Prepare test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3064/3064 [00:01<00:00, 2113.66it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 2165.94it/s]\n",
      "100%|██████████| 445/445 [00:00<00:00, 2134.67it/s]\n",
      "100%|██████████| 3480/3480 [00:01<00:00, 3218.50it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 3206.01it/s]\n",
      "100%|██████████| 497/497 [00:00<00:00, 3187.42it/s]\n",
      "100%|██████████| 2582/2582 [00:01<00:00, 2150.71it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 2005.69it/s]\n",
      "100%|██████████| 385/385 [00:00<00:00, 2121.12it/s]\n",
      "100%|██████████| 7283/7283 [00:03<00:00, 1935.51it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 1925.87it/s]\n",
      "100%|██████████| 973/973 [00:00<00:00, 1938.69it/s]\n",
      "100%|██████████| 836/836 [00:00<00:00, 2214.61it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 1756.46it/s]\n",
      "100%|██████████| 167/167 [00:00<00:00, 1832.97it/s]\n",
      "100%|██████████| 5428/5428 [00:02<00:00, 1949.17it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 1956.23it/s]\n",
      "100%|██████████| 741/741 [00:00<00:00, 1782.18it/s]\n",
      "100%|██████████| 774/774 [00:00<00:00, 3278.07it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 3019.67it/s]\n",
      "100%|██████████| 159/159 [00:00<00:00, 3265.84it/s]\n"
     ]
    }
   ],
   "source": [
    "convert_to_BIO(\"../data_tsvs/englishDFTrainLegal.tsv\", \"../data_tsvs/englishDFDevLegal.tsv\", \"eng\", \"legal\")\n",
    "convert_to_BIO(\"../data_tsvs/englishDFTrainScientific.tsv\", \"../data_tsvs/englishDFDevScientific.tsv\", \"eng\", \"scientific\")\n",
    "convert_to_BIO(\"../data_tsvs/danishDFTrain.tsv\", \"../data_tsvs/danishDFDev.tsv\", \"dan\", \"\")\n",
    "convert_to_BIO(\"../data_tsvs/frenchDFTrain.tsv\", \"../data_tsvs/frenchDFDev.tsv\", \"fre\", \"\")\n",
    "convert_to_BIO(\"../data_tsvs/persianDFTrain.tsv\", \"../data_tsvs/persianDFDev.tsv\", \"per\", \"\")\n",
    "convert_to_BIO(\"../data_tsvs/spanishDFTrain.tsv\", \"../data_tsvs/spanishDFDev.tsv\", \"esp\", \"\")\n",
    "convert_to_BIO(\"../data_tsvs/vietnameseDFTrain.tsv\", \"../data_tsvs/vietnameseDFDev.tsv\", \"vie\", \"\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26447/26447 [00:12<00:00, 2121.08it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 2933.15it/s]\n",
      "100%|██████████| 445/445 [00:00<00:00, 2022.25it/s]\n",
      "100%|██████████| 26447/26447 [00:12<00:00, 2128.56it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 3126.89it/s]\n",
      "100%|██████████| 497/497 [00:00<00:00, 3165.90it/s]\n",
      "100%|██████████| 26447/26447 [00:12<00:00, 2141.74it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 3108.11it/s]\n",
      "100%|██████████| 385/385 [00:00<00:00, 2120.48it/s]\n",
      "100%|██████████| 26447/26447 [00:12<00:00, 2124.54it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 2531.53it/s]\n",
      "100%|██████████| 973/973 [00:00<00:00, 1862.57it/s]\n",
      "100%|██████████| 26447/26447 [00:12<00:00, 2105.10it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 2566.13it/s]\n",
      "100%|██████████| 167/167 [00:00<00:00, 1596.49it/s]\n",
      "100%|██████████| 26447/26447 [00:12<00:00, 2112.66it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 2595.93it/s]\n",
      "100%|██████████| 741/741 [00:00<00:00, 1870.59it/s]\n",
      "100%|██████████| 26447/26447 [00:12<00:00, 2135.17it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 3143.43it/s]\n",
      "100%|██████████| 159/159 [00:00<00:00, 3120.47it/s]\n"
     ]
    }
   ],
   "source": [
    "convert_to_BIO(\"../data_tsvs/allLangDFTrain.tsv\", \"../data_tsvs/englishDFDevLegal.tsv\", \"engAll\", \"legal\")\n",
    "convert_to_BIO(\"../data_tsvs/allLangDFTrain.tsv\", \"../data_tsvs/englishDFDevScientific.tsv\", \"engAll\", \"scientific\")\n",
    "convert_to_BIO(\"../data_tsvs/allLangDFTrain.tsv\", \"../data_tsvs/danishDFDev.tsv\", \"danAll\", \"\")\n",
    "convert_to_BIO(\"../data_tsvs/allLangDFTrain.tsv\", \"../data_tsvs/frenchDFDev.tsv\", \"freAll\", \"\")\n",
    "convert_to_BIO(\"../data_tsvs/allLangDFTrain.tsv\", \"../data_tsvs/persianDFDev.tsv\", \"perAll\", \"\")\n",
    "convert_to_BIO(\"../data_tsvs/allLangDFTrain.tsv\", \"../data_tsvs/spanishDFDev.tsv\", \"espAll\", \"\")\n",
    "convert_to_BIO(\"../data_tsvs/allLangDFTrain.tsv\", \"../data_tsvs/vietnameseDFDev.tsv\", \"vieAll\", \"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
