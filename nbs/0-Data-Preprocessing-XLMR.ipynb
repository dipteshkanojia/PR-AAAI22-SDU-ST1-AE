{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Author: Prashant K. Sharma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io, sys\n",
    "import json\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import word_tokenize\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/diptesh/workspace/PR-AAAI22-SDU-ST1-AE/nbs\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = [\"danish\", \"english\", \"french\", \"persian\", \"spanish\", \"vietnamese\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON to TSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "danishDFTrain = pd.read_json(\"../data/\"+langs[0]+\"/train.json\")\n",
    "danishDFDev = pd.read_json(\"../data/\"+langs[0]+\"/dev.json\")\n",
    "\n",
    "englishDFTrainLegal = pd.read_json(\"../data/\"+langs[1]+\"/legal/train.json\")\n",
    "englishDFDevLegal = pd.read_json(\"../data/\"+langs[1]+\"/legal/dev.json\")\n",
    "englishDFTrainScientific = pd.read_json(\"../data/\"+langs[1]+\"/scientific/train.json\")\n",
    "englishDFDevScientific = pd.read_json(\"../data/\"+langs[1]+\"/scientific/dev.json\")\n",
    "\n",
    "frenchDFTrain = pd.read_json(\"../data/\"+langs[2]+\"/train.json\")\n",
    "frenchDFDev = pd.read_json(\"../data/\"+langs[2]+\"/dev.json\")\n",
    "\n",
    "persianDFTrain = pd.read_json(\"../data/\"+langs[3]+\"/train.json\")\n",
    "persianDFDev = pd.read_json(\"../data/\"+langs[3]+\"/dev.json\")\n",
    "\n",
    "spanishDFTrain = pd.read_json(\"../data/\"+langs[4]+\"/train.json\")\n",
    "spanishDFDev = pd.read_json(\"../data/\"+langs[4]+\"/dev.json\")\n",
    "\n",
    "vietnameseDFTrain = pd.read_json(\"../data/\"+langs[5]+\"/train.json\")\n",
    "vietnameseDFDev = pd.read_json(\"../data/\"+langs[5]+\"/dev.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' An arguably better approach to representation learning is Canonical Correlation Analysis (CCA) that induces representations that are maximally cor-',\n",
       " [[91, 94]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "englishDFTrainScientific.text[2], englishDFTrainScientific.acronyms[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extracting text from the numerical indexes (Hadeel's Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTHOR: Hadeel S\n",
    "\n",
    "def create_acronyms(data):\n",
    "    acs2 = []\n",
    "    longf = []\n",
    "\n",
    "    acros = data.acronyms.values\n",
    "    txt = data.text.values\n",
    "    zipped = list(zip(txt,acros))\n",
    "    for z in zipped:\n",
    "        acs = []\n",
    "        for i in range(len(z[1])):\n",
    "            acs.append(z[0][z[1][i][0]:z[1][i][1]])\n",
    "        acs2.append(acs)\n",
    "    data['acronyms-text'] =acs2\n",
    "    \n",
    "# Creating long forms from here\n",
    "\n",
    "    longform = data[\"long-forms\"].values\n",
    "    zipped2 = list(zip(txt,longform))\n",
    "    for z2 in zipped2:\n",
    "        longform_temp = []\n",
    "        for i in range(len(z2[1])):\n",
    "            longform_temp.append(z2[0][z2[1][i][0]:z2[1][i][1]])\n",
    "        longf.append(longform_temp)\n",
    "    data[\"long-forms-text\"]= longf\n",
    "    \n",
    "    return data\n",
    "#     return data.to_csv(\"datatsvs/\" + name +\".tsv\", index = False, encoding='utf8', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "englishDFTrainScientific = create_acronyms(englishDFTrainScientific)\n",
    "englishDFDevScientific = create_acronyms(englishDFDevScientific)\n",
    "englishDFTrainLegal = create_acronyms(englishDFTrainLegal)\n",
    "englishDFDevLegal = create_acronyms(englishDFDevLegal)\n",
    "danishDFTrain = create_acronyms(danishDFTrain)\n",
    "danishDFDev = create_acronyms(danishDFDev)\n",
    "frenchDFTrain = create_acronyms(frenchDFTrain)\n",
    "frenchDFDev = create_acronyms(frenchDFDev)\n",
    "persianDFTrain = create_acronyms(persianDFTrain)\n",
    "persianDFDev = create_acronyms(persianDFDev)\n",
    "spanishDFTrain = create_acronyms(spanishDFTrain)\n",
    "spanishDFDev = create_acronyms(spanishDFDev)\n",
    "vietnameseDFTrain = create_acronyms(vietnameseDFTrain)\n",
    "vietnameseDFDev = create_acronyms(vietnameseDFDev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating columns for proper TSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "englishDFTrainScientific = englishDFTrainScientific[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "englishDFDevScientific = englishDFDevScientific[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "englishDFTrainLegal = englishDFTrainLegal[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "englishDFDevLegal = englishDFDevLegal[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "danishDFTrain = danishDFTrain[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "danishDFDev = danishDFDev[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "frenchDFTrain = frenchDFTrain[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "frenchDFDev = frenchDFDev[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "persianDFTrain = persianDFTrain[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "persianDFDev = persianDFDev[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "spanishDFTrain = spanishDFTrain[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "spanishDFDev = spanishDFDev[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "vietnameseDFTrain = vietnameseDFTrain[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]\n",
    "vietnameseDFDev = vietnameseDFDev[['ID', 'text', 'acronyms', 'long-forms', 'acronyms-text', 'long-forms-text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "allLangDFTrain = englishDFTrainScientific.append(englishDFTrainLegal, ignore_index=True).append(danishDFTrain, ignore_index=True).append(frenchDFTrain, ignore_index=True).append(persianDFTrain, ignore_index=True).append(spanishDFTrain, ignore_index=True).append(vietnameseDFTrain, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>acronyms</th>\n",
       "      <th>long-forms</th>\n",
       "      <th>acronyms-text</th>\n",
       "      <th>long-forms-text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15009</th>\n",
       "      <td>4384</td>\n",
       "      <td>Je sais que nous pouvons y arriver ensemble, c...</td>\n",
       "      <td>[[292, 295]]</td>\n",
       "      <td>[[245, 290]]</td>\n",
       "      <td>[OMD]</td>\n",
       "      <td>[objectifs du Millénaire pour le développement]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23474</th>\n",
       "      <td>3730</td>\n",
       "      <td>45. Los donantes deben: Entablar relaciones a ...</td>\n",
       "      <td>[[530, 535], [686, 691], [595, 601]]</td>\n",
       "      <td>[[450, 528], [632, 684], [541, 592]]</td>\n",
       "      <td>[ROPPA, PELUM, ESAFF)]</td>\n",
       "      <td>[Red de Organizaciones Campesinas y Productore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13651</th>\n",
       "      <td>3026</td>\n",
       "      <td>Le Groupe de travail a noté que l'Association ...</td>\n",
       "      <td>[[418, 421], [304, 308], [309, 313], [451, 455...</td>\n",
       "      <td>[[380, 416], [34, 83]]</td>\n",
       "      <td>[ICC, SC.3, WP.3, SC.3, no, EBA, EBA, EBA]</td>\n",
       "      <td>[certificat international de capacité, Associa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22969</th>\n",
       "      <td>3225</td>\n",
       "      <td>Sin embargo, la creación de un sistema para ta...</td>\n",
       "      <td>[[191, 194]]</td>\n",
       "      <td>[[142, 189]]</td>\n",
       "      <td>[OIM]</td>\n",
       "      <td>[Organización Internacional para las Migraciones]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4536</th>\n",
       "      <td>557</td>\n",
       "      <td>Invites Parties, Signatories and other stakeho...</td>\n",
       "      <td>[[575, 586]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(IUCN)-UNEP]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3600</th>\n",
       "      <td>3601</td>\n",
       "      <td>is different from the annotation scheme (Abbas...</td>\n",
       "      <td>[[128, 131], [88, 90], [140, 151]]</td>\n",
       "      <td>[[100, 126], [70, 86]]</td>\n",
       "      <td>[HDS, PS, URDU.KON-TB]</td>\n",
       "      <td>[hyper dependency structure, phrase structure]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20739</th>\n",
       "      <td>995</td>\n",
       "      <td>Tipos de formulaciones El endosulfán se produ...</td>\n",
       "      <td>[[146, 148], [176, 178], [233, 235]]</td>\n",
       "      <td>[[117, 144], [151, 174], [217, 231]]</td>\n",
       "      <td>[CE, SC, UL]</td>\n",
       "      <td>[concentrados emulsificables, suspensiones en ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20827</th>\n",
       "      <td>1083</td>\n",
       "      <td>El Gobierno de Nicaragua ha establecido como o...</td>\n",
       "      <td>[[557, 563], [413, 417]]</td>\n",
       "      <td>[[484, 555], [383, 411]]</td>\n",
       "      <td>[ERCERP, HIPC]</td>\n",
       "      <td>[Estrategia Reforzada de Crecimiento Económico...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4222</th>\n",
       "      <td>243</td>\n",
       "      <td>Grand total 8 262a Abbreviations: AOS = admini...</td>\n",
       "      <td>[[34, 37], [81, 84], [116, 120], [169, 172], [...</td>\n",
       "      <td>[[40, 79], [87, 114], [175, 205], [214, 258], ...</td>\n",
       "      <td>[AOS, GEF, SPPD, STS, TRAC, UNV, UNSO]</td>\n",
       "      <td>[administrative and operational services, Glob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21344</th>\n",
       "      <td>1600</td>\n",
       "      <td>89. El Centro Internacional de Protección del...</td>\n",
       "      <td>[[61, 67]]</td>\n",
       "      <td>[[8, 59]]</td>\n",
       "      <td>[ICALPE]</td>\n",
       "      <td>[Centro Internacional de Protección del Medio ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26947 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                               text  \\\n",
       "15009  4384  Je sais que nous pouvons y arriver ensemble, c...   \n",
       "23474  3730  45. Los donantes deben: Entablar relaciones a ...   \n",
       "13651  3026  Le Groupe de travail a noté que l'Association ...   \n",
       "22969  3225  Sin embargo, la creación de un sistema para ta...   \n",
       "4536    557  Invites Parties, Signatories and other stakeho...   \n",
       "...     ...                                                ...   \n",
       "3600   3601  is different from the annotation scheme (Abbas...   \n",
       "20739   995   Tipos de formulaciones El endosulfán se produ...   \n",
       "20827  1083  El Gobierno de Nicaragua ha establecido como o...   \n",
       "4222    243  Grand total 8 262a Abbreviations: AOS = admini...   \n",
       "21344  1600   89. El Centro Internacional de Protección del...   \n",
       "\n",
       "                                                acronyms  \\\n",
       "15009                                       [[292, 295]]   \n",
       "23474               [[530, 535], [686, 691], [595, 601]]   \n",
       "13651  [[418, 421], [304, 308], [309, 313], [451, 455...   \n",
       "22969                                       [[191, 194]]   \n",
       "4536                                        [[575, 586]]   \n",
       "...                                                  ...   \n",
       "3600                  [[128, 131], [88, 90], [140, 151]]   \n",
       "20739               [[146, 148], [176, 178], [233, 235]]   \n",
       "20827                           [[557, 563], [413, 417]]   \n",
       "4222   [[34, 37], [81, 84], [116, 120], [169, 172], [...   \n",
       "21344                                         [[61, 67]]   \n",
       "\n",
       "                                              long-forms  \\\n",
       "15009                                       [[245, 290]]   \n",
       "23474               [[450, 528], [632, 684], [541, 592]]   \n",
       "13651                             [[380, 416], [34, 83]]   \n",
       "22969                                       [[142, 189]]   \n",
       "4536                                                  []   \n",
       "...                                                  ...   \n",
       "3600                              [[100, 126], [70, 86]]   \n",
       "20739               [[117, 144], [151, 174], [217, 231]]   \n",
       "20827                           [[484, 555], [383, 411]]   \n",
       "4222   [[40, 79], [87, 114], [175, 205], [214, 258], ...   \n",
       "21344                                          [[8, 59]]   \n",
       "\n",
       "                                    acronyms-text  \\\n",
       "15009                                       [OMD]   \n",
       "23474                      [ROPPA, PELUM, ESAFF)]   \n",
       "13651  [ICC, SC.3, WP.3, SC.3, no, EBA, EBA, EBA]   \n",
       "22969                                       [OIM]   \n",
       "4536                                [(IUCN)-UNEP]   \n",
       "...                                           ...   \n",
       "3600                       [HDS, PS, URDU.KON-TB]   \n",
       "20739                                [CE, SC, UL]   \n",
       "20827                              [ERCERP, HIPC]   \n",
       "4222       [AOS, GEF, SPPD, STS, TRAC, UNV, UNSO]   \n",
       "21344                                    [ICALPE]   \n",
       "\n",
       "                                         long-forms-text  \n",
       "15009    [objectifs du Millénaire pour le développement]  \n",
       "23474  [Red de Organizaciones Campesinas y Productore...  \n",
       "13651  [certificat international de capacité, Associa...  \n",
       "22969  [Organización Internacional para las Migraciones]  \n",
       "4536                                                  []  \n",
       "...                                                  ...  \n",
       "3600      [hyper dependency structure, phrase structure]  \n",
       "20739  [concentrados emulsificables, suspensiones en ...  \n",
       "20827  [Estrategia Reforzada de Crecimiento Económico...  \n",
       "4222   [administrative and operational services, Glob...  \n",
       "21344  [Centro Internacional de Protección del Medio ...  \n",
       "\n",
       "[26947 rows x 6 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allLangDFTrain.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing TSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "englishDFTrainScientific.to_csv(\"../data_tsvs/englishDFTrainScientific.tsv\", sep='\\t', index=False)\n",
    "englishDFDevScientific.to_csv(\"../data_tsvs/englishDFDevScientific.tsv\", sep='\\t', index=False)\n",
    "englishDFTrainLegal.to_csv(\"../data_tsvs/englishDFTrainLegal.tsv\", sep='\\t', index=False)\n",
    "englishDFDevLegal.to_csv(\"../data_tsvs/englishDFDevLegal.tsv\", sep='\\t', index=False)\n",
    "danishDFTrain.to_csv(\"../data_tsvs/danishDFTrain.tsv\", sep='\\t', index=False)\n",
    "danishDFDev.to_csv(\"../data_tsvs/danishDFDev.tsv\", sep='\\t', index=False)\n",
    "frenchDFTrain.to_csv(\"../data_tsvs/frenchDFTrain.tsv\", sep='\\t', index=False)\n",
    "frenchDFDev.to_csv(\"../data_tsvs/frenchDFDev.tsv\", sep='\\t', index=False)\n",
    "persianDFTrain.to_csv(\"../data_tsvs/persianDFTrain.tsv\", sep='\\t', index=False)\n",
    "persianDFDev.to_csv(\"../data_tsvs/persianDFDev.tsv\", sep='\\t', index=False)\n",
    "spanishDFTrain.to_csv(\"../data_tsvs/spanishDFTrain.tsv\", sep='\\t', index=False)\n",
    "spanishDFDev.to_csv(\"../data_tsvs/spanishDFDev.tsv\", sep='\\t', index=False)\n",
    "vietnameseDFTrain.to_csv(\"../data_tsvs/vietnameseDFTrain.tsv\", sep='\\t', index=False)\n",
    "vietnameseDFDev.to_csv(\"../data_tsvs/vietnameseDFDev.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "allLangDFTrain.to_csv(\"../data_tsvs/allLangDFTrain.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSVs to CoNLL format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BIO(txt, an_ids, lf_ids):\n",
    "    \"\"\"\n",
    "    input: text\n",
    "    ouput: tags , bio_tags\n",
    "        \n",
    "        tags :    list (AN, FL, OT)\n",
    "        bio_tags: list (O, B-AN, I-AN, B-LF, I-LF)\n",
    "    \"\"\"\n",
    "    \n",
    "    txt_l = word_tokenize(txt)\n",
    "    \n",
    "    tags = [\"OT\"]*len(txt_l)\n",
    "    bio_tags = [\"B-O\"]*len(txt_l)\n",
    "    \n",
    "    #txt[an_ids[0][0]:an_ids[0][1]]\n",
    "    \n",
    "    ANs = []\n",
    "    LFs = []\n",
    "    \n",
    "    for an_id in an_ids:\n",
    "        ANs.append(txt[an_id[0]:an_id[1]])\n",
    "        \n",
    "    for lf_id in lf_ids:\n",
    "        LFs.append(txt[lf_id[0]:lf_id[1]])\n",
    "    \n",
    "    AN_start = [False]*len(ANs)\n",
    "    LF_start = [False]*len(LFs)\n",
    "    \n",
    "    \n",
    "    for tok_id in range(0,len(txt_l)):\n",
    "        tok = txt_l[tok_id]\n",
    "        \n",
    "        for AN_idx in range(0,len(ANs)):\n",
    "           \n",
    "            AN = ANs[AN_idx]\n",
    "            \n",
    "            if(tok in AN):\n",
    "                tags[tok_id] = \"AN\"\n",
    "                \n",
    "                if(AN_start[AN_idx] == False):\n",
    "                    AN_start[AN_idx] = True\n",
    "                    bio_tags[tok_id] = \"B-AN\"\n",
    "                else:\n",
    "                    bio_tags[tok_id] = \"I-AN\"\n",
    "        \n",
    "        for LF_idx in range(0,len(LFs)):\n",
    "            \n",
    "            LF = LFs[LF_idx]\n",
    "            \n",
    "            if(tok in LF):\n",
    "                tags[tok_id] = \"LF\"\n",
    "                \n",
    "                if(LF_start[LF_idx] == False):\n",
    "                    LF_start[LF_idx] = True\n",
    "                    bio_tags[tok_id] = \"B-LF\"\n",
    "                else:\n",
    "                    bio_tags[tok_id] = \"I-LF\"\n",
    "                    \n",
    "    return txt_l, tags, bio_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(df, idx):\n",
    "    df_i = df.iloc[idx]\n",
    "    \n",
    "    txt = str(df_i[\"text\"]).strip()\n",
    "    acrnm_ids = ast.literal_eval(df_i[\"acronyms\"])\n",
    "    longform_ids = ast.literal_eval(df_i[\"long-forms\"])\n",
    "    \n",
    "    return txt, acrnm_ids, longform_ids\n",
    "\n",
    "def prepare(df, cnt, fname=\"output.txt\"):\n",
    "    \n",
    "    file = open(fname, \"w\")\n",
    "    file.write(\"-DOCSTART- -X- O\\n\\n\")\n",
    "    for idx in tqdm(range(cnt)):\n",
    "        txt, an_ids, lf_ids = extract(df, idx)\n",
    "        \n",
    "        txt_l, tags, bio_tags = BIO(txt, an_ids, lf_ids)\n",
    "        \n",
    "        for txt_id in range(0,len(txt_l)):\n",
    "            string = txt_l[txt_id]+ \" \" + tags[txt_id] + \" \" + bio_tags[txt_id]\n",
    "            \n",
    "            file.write(string + \" \\n\")\n",
    "        file.write(\"\\n\")\n",
    "    file.close()\n",
    "    \n",
    "def convert_to_BIO(fileTrain, fileDev, lang, domain):\n",
    "    df_train = pd.read_csv(fileTrain, sep=\"\\t\")\n",
    "    df_dev = pd.read_csv(fileDev, sep=\"\\t\")\n",
    "    df_combine = df_train.append(df_dev, ignore_index=True)\n",
    "    \n",
    "    cnt_train = df_train.shape[0]\n",
    "    cnt_dev = df_dev.shape[0]\n",
    "    \n",
    "    train_cnt = cnt_train - 500 ## Assuming 300 instances are enough to validate\n",
    "    valid_cnt = 500\n",
    "    test_cnt = cnt_dev\n",
    "    \n",
    "    df_train_ = df_combine.iloc[:train_cnt]\n",
    "    df_valid_ = df_combine.iloc[train_cnt: train_cnt + valid_cnt].reset_index()\n",
    "    df_test_ = df_combine.iloc[train_cnt + valid_cnt: train_cnt + valid_cnt + test_cnt].reset_index()\n",
    "    \n",
    "    # Prepare training file\n",
    "    if ( domain == \"\" ):\n",
    "        prepare(df_train_, train_cnt, \"../processed/\" + lang + \"/train.txt\") # Prepare train file\n",
    "        prepare(df_valid_, valid_cnt, \"../processed/\" + lang + \"/valid.txt\") # Prepare validation file\n",
    "        prepare(df_test_, test_cnt, \"../processed/\" + lang + \"/test.txt\") # Prepare test file\n",
    "    else:\n",
    "        prepare(df_train_, train_cnt, \"../processed/\" + lang + \"/\" + domain + \"/train.txt\") # Prepare train file\n",
    "        prepare(df_valid_, valid_cnt, \"../processed/\" + lang + \"/\" + domain +\"/valid.txt\") # Prepare validation file\n",
    "        prepare(df_test_, test_cnt, \"../processed/\" + lang+  \"/\" + domain + \"/test.txt\") # Prepare test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3064/3064 [00:01<00:00, 2113.66it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 2165.94it/s]\n",
      "100%|██████████| 445/445 [00:00<00:00, 2134.67it/s]\n",
      "100%|██████████| 3480/3480 [00:01<00:00, 3218.50it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 3206.01it/s]\n",
      "100%|██████████| 497/497 [00:00<00:00, 3187.42it/s]\n",
      "100%|██████████| 2582/2582 [00:01<00:00, 2150.71it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 2005.69it/s]\n",
      "100%|██████████| 385/385 [00:00<00:00, 2121.12it/s]\n",
      "100%|██████████| 7283/7283 [00:03<00:00, 1935.51it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 1925.87it/s]\n",
      "100%|██████████| 973/973 [00:00<00:00, 1938.69it/s]\n",
      "100%|██████████| 836/836 [00:00<00:00, 2214.61it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 1756.46it/s]\n",
      "100%|██████████| 167/167 [00:00<00:00, 1832.97it/s]\n",
      "100%|██████████| 5428/5428 [00:02<00:00, 1949.17it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 1956.23it/s]\n",
      "100%|██████████| 741/741 [00:00<00:00, 1782.18it/s]\n",
      "100%|██████████| 774/774 [00:00<00:00, 3278.07it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 3019.67it/s]\n",
      "100%|██████████| 159/159 [00:00<00:00, 3265.84it/s]\n"
     ]
    }
   ],
   "source": [
    "convert_to_BIO(\"../data_tsvs/englishDFTrainLegal.tsv\", \"../data_tsvs/englishDFDevLegal.tsv\", \"eng\", \"legal\")\n",
    "convert_to_BIO(\"../data_tsvs/englishDFTrainScientific.tsv\", \"../data_tsvs/englishDFDevScientific.tsv\", \"eng\", \"scientific\")\n",
    "convert_to_BIO(\"../data_tsvs/danishDFTrain.tsv\", \"../data_tsvs/danishDFDev.tsv\", \"dan\", \"\")\n",
    "convert_to_BIO(\"../data_tsvs/frenchDFTrain.tsv\", \"../data_tsvs/frenchDFDev.tsv\", \"fre\", \"\")\n",
    "convert_to_BIO(\"../data_tsvs/persianDFTrain.tsv\", \"../data_tsvs/persianDFDev.tsv\", \"per\", \"\")\n",
    "convert_to_BIO(\"../data_tsvs/spanishDFTrain.tsv\", \"../data_tsvs/spanishDFDev.tsv\", \"esp\", \"\")\n",
    "convert_to_BIO(\"../data_tsvs/vietnameseDFTrain.tsv\", \"../data_tsvs/vietnameseDFDev.tsv\", \"vie\", \"\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26447/26447 [00:12<00:00, 2200.11it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 3282.84it/s]\n",
      "100%|██████████| 445/445 [00:00<00:00, 2243.83it/s]\n",
      "100%|██████████| 26447/26447 [00:12<00:00, 2182.38it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 3021.38it/s]\n",
      "100%|██████████| 497/497 [00:00<00:00, 3054.90it/s]\n",
      "100%|██████████| 26447/26447 [00:12<00:00, 2167.70it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 3289.45it/s]\n",
      "100%|██████████| 385/385 [00:00<00:00, 1981.28it/s]\n",
      "100%|██████████| 26447/26447 [00:12<00:00, 2101.06it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 1543.01it/s]\n",
      "100%|██████████| 973/973 [00:00<00:00, 1549.90it/s]\n",
      "100%|██████████| 26447/26447 [00:12<00:00, 2181.53it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 3223.82it/s]\n",
      "100%|██████████| 167/167 [00:00<00:00, 1849.71it/s]\n",
      "100%|██████████| 26447/26447 [00:12<00:00, 2184.80it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 3121.30it/s]\n",
      "100%|██████████| 741/741 [00:00<00:00, 1959.25it/s]\n",
      "100%|██████████| 26447/26447 [00:12<00:00, 2201.89it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 2604.81it/s]\n",
      "100%|██████████| 159/159 [00:00<00:00, 3251.16it/s]\n"
     ]
    }
   ],
   "source": [
    "convert_to_BIO(\"../data_tsvs/allLangDFTrain.tsv\", \"../data_tsvs/englishDFDevLegal.tsv\", \"engAll\", \"legal\")\n",
    "convert_to_BIO(\"../data_tsvs/allLangDFTrain.tsv\", \"../data_tsvs/englishDFDevScientific.tsv\", \"engAll\", \"scientific\")\n",
    "convert_to_BIO(\"../data_tsvs/allLangDFTrain.tsv\", \"../data_tsvs/danishDFDev.tsv\", \"danAll\", \"\")\n",
    "convert_to_BIO(\"../data_tsvs/allLangDFTrain.tsv\", \"../data_tsvs/frenchDFDev.tsv\", \"freAll\", \"\")\n",
    "convert_to_BIO(\"../data_tsvs/allLangDFTrain.tsv\", \"../data_tsvs/persianDFDev.tsv\", \"perAll\", \"\")\n",
    "convert_to_BIO(\"../data_tsvs/allLangDFTrain.tsv\", \"../data_tsvs/spanishDFDev.tsv\", \"espAll\", \"\")\n",
    "convert_to_BIO(\"../data_tsvs/allLangDFTrain.tsv\", \"../data_tsvs/vietnameseDFDev.tsv\", \"vieAll\", \"\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
