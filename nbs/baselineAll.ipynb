{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1c98c43-c986-4620-bad5-51353ef9f720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import copy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "547a09cf-3358-4756-b5fa-42dcd85c2197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data):\n",
    "    predictions = []\n",
    "    for d in data:\n",
    "        pred = {\n",
    "            'ID': d['ID'],\n",
    "            'acronyms': [],\n",
    "            'long-forms': []\n",
    "        }\n",
    "        tokens = d['text'].split()\n",
    "        for i, t in enumerate(tokens):            \n",
    "#             t2 = copy.deepcopy(t) ## DOES NOT WORK; Thanks to Python referencing!\n",
    "#             t2 = copy.copy(t) ## DOES NOT WORK; Thanks to Python referencing!\n",
    "#             t2 = t\n",
    "\n",
    "            t2 = (t + '.')[:-1] ## Works! \n",
    "    \n",
    "#             t2 = '%s' % t ## DOES NOT WORK; Thanks to Python referencing!\n",
    "#             t2 = t2.replace(r\"\\(.*\\)\",\"\")\n",
    "#             re.sub(r'\\([^()]*\\)', '', t2)\n",
    "            t2 = t2.replace('(',' ').replace(')',' ')\n",
    "#             t2 = t2.replace('(',' ').replace(')',' ').replace(',',' ').strip()\n",
    "#             print(t2)\n",
    "            if len(t2) > 0:\n",
    "                if t2[0].isupper() and len([c for c in t2 if c.isupper()])/len(t2) > 0.5 and 2 <= len(t2) <= 10:\n",
    "#                     print(d['ID'], d['text'])\n",
    "#                     print(id(t2),id(t))\n",
    "#                     print(i, t2, t)\n",
    "                    pred['acronyms'].append([sum([len(w)+1 for w in tokens[:i]]),sum([len(w)+1 for w in tokens[:i]])+len(t)])\n",
    "                    if t.startswith('(') and t.endswith(')'): ## TRY TO REPAIR THIS!\n",
    "#                         print(\"found\")\n",
    "                        uppers = []\n",
    "                        for c in t:\n",
    "                            if c.isupper():\n",
    "                                uppers.append(c)\n",
    "                        candids = tokens[i-len(uppers):i]\n",
    "    #                     print(\"candids\", i, candids)\n",
    "                        match = True\n",
    "                        for j, candid in enumerate(candids):\n",
    "                            if candid[0].lower() != uppers[j].lower():\n",
    "                                match = False\n",
    "                        if match:\n",
    "                            pred['long-forms'].append([sum([len(w)+1 for w in tokens[:i-len(uppers)]]),sum([len(w)+1 for w in tokens[:i-1]])+len(tokens[i-1])])\n",
    "        predictions.append(pred)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e1ac836-e1ab-4735-a519-fa3f645f7110",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 14 files\n",
    "\n",
    "files = [\"../data/english/legal/train.json\", \"../data/english/legal/dev.json\", \"../data/english/scientific/train.json\", \n",
    "         \"../data/english/scientific/dev.json\", \"../data/danish/train.json\", \"../data/danish/dev.json\", \"../data/french/train.json\",\n",
    "         \"../data/french/dev.json\", \"../data/persian/train.json\", \"../data/persian/dev.json\", \n",
    "         \"../data/spanish/train.json\", \"../data/spanish/dev.json\", \"../data/vietnamese/train.json\", \"../data/vietnamese/dev.json\"]\n",
    "\n",
    "for f in files:\n",
    "    head, tail = os.path.split(f)\n",
    "    dd = head.replace('..','')\n",
    "    dd = head.replace('/','')\n",
    "    dd = dd.replace('data','')\n",
    "#     print(dd+tail[:-5]+\"results.json\")\n",
    "    with open(f) as file:\n",
    "        data = json.load(file)\n",
    "    predictions = predict(data) ## Use the function above to predict based on the \"Word capitalized over 60% and above is an acronym rule\"\n",
    "    with open(\"../results/baseline/\"+dd+tail[:-5]+\".json\", 'w') as file:\n",
    "        json.dump(predictions, file) ## Dump the prediction in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "258ac735-0049-48d2-b27d-46e067305a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [\"../results/baseline/englishlegaltrain.json\", \"../results/baseline/englishlegaldev.json\", \"../results/baseline/englishscientifictrain.json\",\n",
    "           \"../results/baseline/englishscientificdev.json\", \"../results/baseline/danishtrain.json\", \"../results/baseline/danishdev.json\", \"../results/baseline/frenchtrain.json\", \"../results/baseline/frenchdev.json\", \"../results/baseline/persiantrain.json\", \"../results/baseline/persiandev.json\",\n",
    "           \"../results/baseline/spanishtrain.json\", \"../results/baseline/spanishdev.json\", \"../results/baseline/vietnamesetrain.json\", \"../results/baseline/vietnamesedev.json\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a379c07-25ff-4819-9658-b7869ffc9ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation(file1g, file2p, verbose=False):\n",
    "    with open(file1g) as file:\n",
    "        gold = dict([(d['ID'], {'acronyms':d['acronyms'],'long-forms':d['long-forms']}) for d in json.load(file)])\n",
    "    with open(file2p) as file:\n",
    "        pred = dict([(d['ID'], {'acronyms':d['acronyms'],'long-forms':d['long-forms']}) for d in json.load(file)])\n",
    "        print(file2p)\n",
    "        pred = [pred[k] for k,v in gold.items()]\n",
    "        gold = [gold[k] for k,v in gold.items()]\n",
    "    p, r, f1 = score_phrase_level(gold, pred, verbos=verbose)\n",
    "    return p, r, f1\n",
    "\n",
    "def score_phrase_level(key, predictions, verbos=False):\n",
    "    gold_shorts = set()\n",
    "    gold_longs = set()\n",
    "    pred_shorts = set()\n",
    "    pred_longs = set()\n",
    "\n",
    "    def find_phrase(seq, shorts, longs):\n",
    "        for i, data in enumerate(seq):\n",
    "            for sh in data['acronyms']:\n",
    "                shorts.add(str(i)+'#'+str(sh[0])+'-'+str(sh[1]))\n",
    "            for lf in data['long-forms']:\n",
    "                longs.add(str(i)+'#'+str(lf[0])+'-'+str(lf[1]))\n",
    "\n",
    "    find_phrase(key, gold_shorts, gold_longs)\n",
    "    find_phrase(predictions, pred_shorts, pred_longs)\n",
    "\n",
    "    def find_prec_recall_f1(pred, gold):\n",
    "        correct = 0\n",
    "        for phrase in pred:\n",
    "            if phrase in gold:\n",
    "                correct += 1\n",
    "        # print(correct)\n",
    "        prec = correct / len(pred) if len(pred) > 0 else 1\n",
    "        recall = correct / len(gold) if len(gold) > 0 else 1\n",
    "        f1 = 2 * prec * recall / (prec + recall) if prec+recall > 0 else 0\n",
    "        return prec, recall, f1\n",
    "\n",
    "    prec_short, recall_short, f1_short = find_prec_recall_f1(pred_shorts, gold_shorts)\n",
    "    prec_long, recall_long, f1_long = find_prec_recall_f1(pred_longs, gold_longs)\n",
    "    precision_micro, recall_micro, f1_micro = find_prec_recall_f1(pred_shorts.union(pred_longs), gold_shorts.union(gold_longs))\n",
    "\n",
    "    precision_macro = (prec_short + prec_long) / 2\n",
    "    recall_macro = (recall_short + recall_long) / 2\n",
    "    f1_macro = 2*precision_macro*recall_macro/(precision_macro+recall_macro) if precision_macro+recall_macro > 0 else 0\n",
    "\n",
    "    if verbos:\n",
    "        print('Shorts: P: {:.2%}, R: {:.2%}, F1: {:.2%}'.format(prec_short, recall_short, f1_short))\n",
    "        print('Longs: P: {:.2%}, R: {:.2%}, F1: {:.2%}'.format(prec_long, recall_long, f1_long))\n",
    "        print('micro scores: P: {:.2%}, R: {:.2%}, F1: {:.2%}'.format(precision_micro, recall_micro, f1_micro))\n",
    "        print('macro scores: P: {:.2%}, R: {:.2%}, F1: {:.2%}'.format(precision_macro, recall_macro, f1_macro))\n",
    "\n",
    "    return precision_macro, recall_macro, f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "957d7eba-558e-4974-b477-f70737bac0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../results/baseline/englishlegaltrain.json\n",
      "../results/baseline/englishlegaldev.json\n",
      "../results/baseline/englishscientifictrain.json\n",
      "../results/baseline/englishscientificdev.json\n",
      "../results/baseline/danishtrain.json\n",
      "../results/baseline/danishdev.json\n",
      "../results/baseline/frenchtrain.json\n",
      "../results/baseline/frenchdev.json\n",
      "../results/baseline/persiantrain.json\n",
      "../results/baseline/persiandev.json\n",
      "../results/baseline/spanishtrain.json\n",
      "../results/baseline/spanishdev.json\n",
      "../results/baseline/vietnamesetrain.json\n",
      "../results/baseline/vietnamesedev.json\n"
     ]
    }
   ],
   "source": [
    "!rm ../results/baseline/allresults.tsv ## Delete old file\n",
    "with open(\"../results/baseline/allresults.tsv\", 'a') as outfile:\n",
    "    outfile.write(\"SET\\tPrecision\\tRecall\\tF1-Score\\n\")\n",
    "for gold,pred in zip(files,results):\n",
    "    p, r, f1 = run_evaluation(gold, pred)\n",
    "    new = \"{:.2}\".format(p)\n",
    "    head, tail = os.path.split(pred)\n",
    "    with open(\"../results/baseline/allresults.tsv\", 'a') as outfile:\n",
    "        outfile.write(tail[:-5]+\"\\t{:.2%}\\t{:.2%}\\t{:.2%}\\n\".format(p,r,f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
