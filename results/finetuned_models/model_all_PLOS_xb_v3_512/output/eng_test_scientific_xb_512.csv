	text	ID	AN_Pred	LF_Pred	AN_Pred_idxs	LF_Pred_idxs
0	The label restricted means the model is restricted to recovering rules that have been seen in training data. LR = labeled recall. LP = labeled	1	['LR', 'LP']	['label', 'labeled recall']	[[109, 111], [130, 132]]	[[4, 9], [114, 128]]
1	We have followed their methodology as best as we could, using the same WordNet (WN) categories and the same corpora.	2	['WN']	['WordNet']	[[80, 82]]	[[71, 78]]
2	adaptation scenario. Duan et al (2009) proposed a Domain Adaptation Machine (DAM) method to learn a Least-Squares SVM classifier for target do-	3	['DAM', 'SVM']	['a Domain Adaptation Machine', 'a']	[[77, 80], [114, 117]]	[[48, 75], [0, 1]]
3	 Actes de la 13e Confe?rence sur le Traitement Automatique des Langues Naturelles (TALN), pages 20?42.	4	['TALN']	['de la', 'le Traitement Automatique des Langues Naturelles']	[[82, 86]]	[[6, 11], [32, 80]]
4	TGTM P=p,pk ,b   TGTM PR=pr ,  pkr ,  b r   TGTM PL =p l ,  ph l ,  b l   TGTM PW=pw, pkw, bw 	5	['TGTM', 'PL']	[',', ',', ',', ',', 'r', 'l , ph l ,', 'l', ',', ',']	[[0, 4], [49, 51]]	[[8, 9], [8, 9], [8, 9], [8, 9], [26, 27], [-1, 9], [55, 56], [8, 9], [8, 9]]
5	MIRA/AROW requires selecting the loss function `(w) so that wt can be solved in closed-form, by a quadratic program (QP), or in some other way that is better than linearizing.	6	['wt', 'QP']	['a quadratic program']	[[60, 62], [117, 119]]	[[96, 115]]
6	 1 Introduction Information extraction (IE) systems generally consist of multiple interdependent components, e.g., en-	7	[')']	['extraction']	[[41, 42]]	[[27, 37]]
7	117 d?eriv?es) (AP (ADJ thiazidiques) (COORD (PONCT ,) (NP (DET les) (ADV plus) (ADJ accessibles)) (PONCT ,) (AP (ADJ disponibles)))) (PP (P sous forme de) (NP (NC m?edicaments) (AP (ADJ g?en?eriques)))))))))	8	['AP', 'ADJ', 'COORD', 'PONCT', 'NP', 'DET', 'ADV', 'PP']	['d ? eriv ? es', 'thiazidiques', 'ADJ accessibles', 'P sous forme de', 'm ? edicaments', 'ADJ g ? en ? eriques']	[[16, 18], [20, 23], [39, 44], [46, 51], [56, 58], [60, 63], [70, 73], [135, 137]]	[[-1, 12], [24, 36], [81, 96], [139, 154], [-1, 13], [-1, 19]]
8	2002. The concaveconvex procedure (CCCP). In Proc.	9	[')']	['procedure']	[[39, 40]]	[[24, 33]]
9	most related words pop-up. Then the documents are re-ranked about their term frequency (TF) values (G. Salton and C. Buckley, 1988) and contextual infor-	10	['TF']	['term frequency']	[[88, 90]]	[[72, 86]]
10	in part by ONR grant number N00014-95-1-1164,  and has been done in collaboration with the US  Navy's NCCOSC RDT&E Division (NRaD), Ascent  Technologies, Mitre Corp., MRJ Corp., and SRI In- 	11	['ONR', 'NCCOSC', 'SRI']	['RDT & E']	[[11, 14], [102, 108], [182, 185]]	[[-1, 6]]
11	approach.  The Minimum Token Margin (MTM) strategy is a variant of the margin sampling strategy introduced	12	['MTM']	['Minimum Token Margin', 'a']	[[37, 40]]	[[15, 35], [0, 1]]
12	food(FOOD) artifact(AFT) article(ART)  location(LOC) psych_feature(PSY)  cognition(COG) feeling(FEEL)  motivation(MOT) abstraction(ABS) 	13	['FOOD', 'AFT', 'ART', 'LOC', 'PSY', 'COG', 'FEEL', 'MOT', 'ABS']	['food', 'artifact', 'article', 'location', 'psych_feature', 'cognition', 'feeling', 'motivation', 'abstraction']	[[5, 9], [20, 23], [33, 36], [48, 51], [67, 70], [83, 86], [96, 100], [114, 117], [131, 134]]	[[0, 4], [11, 19], [25, 32], [39, 47], [53, 66], [73, 82], [88, 95], [103, 113], [119, 130]]
13	m } using standard support vector machine (SVM) training (holding A fixed), and then make a simple	14	[')']	['m', 'vector machine', 'a']	[[46, 47]]	[[0, 1], [27, 41], [12, 13]]
14	son. One is based on chi-square value and the other is based on Pointwise Mutual Information (PMI). 	15	['PMI']	['is', 'on', 'is', 'on Pointwise Mutual Information']	[[94, 97]]	[[9, 11], [1, 3], [9, 11], [61, 92]]
15	concerned with video lecture viewing only) before 11 Figure 4: Variation of Average Information Processing Indices(IPI) for Video 4-6 Figure 5: Variation of Average Information Processing Indices(IPI) for the full course	16	['IPI']	['Information Processing Indices', 'for', 'Information Processing Indices', 'for']	[[115, 118]]	[[84, 114], [45, 48], [84, 114], [45, 48]]
16	Figure 1. Annotated Syntax Tree  (AST) and Phrase Levels (PL). 	17	['AST', 'PL']	['Annotated Syntax Tree', 'Phrase Levels']	[[34, 37], [58, 60]]	[[10, 31], [43, 56]]
17	Num. of Friendships 265 Average Clustering Coefficient (ACC) 0.42 Diameter 12 Table 1: Statistical information of our Foursquare dataset.	18	['ACC']	['Average Clustering Coefficient']	[[56, 59]]	[[24, 54]]
18	number of phrase pairs that can be extracted. We observe that it (OEF) is able to find more than 14% more phrase pairs than heuristic methods and	19	['OEF']	[]	[[66, 69]]	[]
19	? Frequency-based: LUHN (Luhn, 1958) score(S) = maxci?{clusters(S)}{csi}, where	20	['LUHN']	['?', 'Luhn ,', '=', '? {', '{', ',']	[[19, 23]]	[[0, 1], [-1, 5], [46, 47], [-1, 2], [54, 55], [29, 30]]
20	resource presented here implements formal semantic descriptions of verbs in the Web Ontology Language (OWL) and exploits its reasoning potential based on Description Logics (DL) for the disambiguation of verbs in context, since before the correct sense of a verb can be reliably	21	['OWL', 'DL']	['Web Ontology Language', 'on', 'Description Logics', 'a']	[[103, 106], [174, 176]]	[[80, 101], [60, 62], [154, 172], [39, 40]]
21	the noun phrase (NP) rule, a top-down parser is delaying making any commitments about the category following the determiner (DT). This delay in predic-	22	['NP', 'DT']	['noun phrase', 'a', 'in']	[[17, 19], [125, 127]]	[[4, 15], [12, 13], [53, 55]]
22	for test year 2010 (train on 2009), polarity task.  SemTree combined with FWD (SemTreeFWD) generally gives the best performance in both	23	[]	['SemTree combined', 'FWD']	[]	[[52, 68], [74, 77]]
23	Marcu (2007) note that none of the tens of papers published over the last five years has shown that significant decreases in alignment error rate (AER) result in significant increases in translation perfor-	24	['AER']	['alignment error rate']	[[147, 150]]	[[125, 145]]
24	"""bridge"" between this bilingual word pair. This  leads us to use the term frequency(TF) mea-  sure."	25	['TF']	['term frequency']	[[84, 86]]	[[69, 83]]
25	 4 Evaluation and Experiments We use the General Inquirer (GI)8 data for evaluation.	26	[')']	['Inquirer']	[[60, 61]]	[[48, 56]]
26	We ran our experiments with three corpora in different languages and representing different textual typologies: the British National Corpus (BNC), a ? bal-	27	['BNC']	['British National Corpus', 'a']	[[141, 144]]	[[116, 139], [4, 5]]
27	the same discourse relation annotation style over different domain corpora: PDTB is annotated on top of Wall Street Journal (WSJ) corpus (financial news-wire domain); and it is aligned with Penn	28	['PDTB', 'WSJ']	['Wall Street Journal']	[[76, 80], [125, 128]]	[[104, 123]]
28	 6 Related Work  Boosting is a machine learning (ML) method that  has been well studied in the ML community 	29	[')']	['a', 'learning', 'in']	[[50, 51]]	[[5, 6], [38, 46], [21, 23]]
29	MOVE is a label for complex events that con-  sists o f  maximal ly  three sub-events,  namely  START, CHPOS (CHANGE OF POSITION), and STOP,  where the first and the last sub-event are optional 	30	[]	['OF POSITION']	[]	[[117, 128]]
30	>puncS Hertz equipment is a major supplier of rental equipment N/N N S\N (S\S)/N N/N N (N\N)/N N/N N > >	31	[]	['N S\\N', 'S\\S', '/N N/N N', 'N\\N', '/N N/N N']	[]	[[67, 72], [74, 77], [78, 86], [88, 91], [78, 86]]
31	 Several algorithms have been evaluated using 80 multiple-choice synonym questions taken from the Test of English as a Foreign Language (TOEFL). An example of	32	['TOEFL']	['Test of English as a Foreign Language']	[[136, 141]]	[[97, 134]]
32	halcea and Nataste (2012)). In our framework, we train a Neural Language Model (NLM) on yearly corpora to obtain word vectors for each year	33	['NLM']	['a Neural Language Model']	[[80, 83]]	[[55, 78]]
33	summarizing the work of the Corpora and Performance  Evaluation Committee (CPEC) of the DARPA Spoken Language  Systems (SLS) Program, with specific reports from several  working groups which have been dealing with various aspects 	34	['CPEC', 'DARPA', 'SLS']	['Corpora and Performance Evaluation Committee', 'Spoken Language Systems']	[[75, 79], [88, 93], [120, 123]]	[[-1, 43], [-1, 22]]
34	robust and the failure of matching produces no results.  On the other hand, statistical learning model (SLM) can  deal with unexpected cases during designing and 	35	['SLM']	['statistical learning model']	[[104, 107]]	[[76, 102]]
35	Statistical model (S) O O O O O O O O  Cooperative(CPR)  O   O O  O  Corrective(COR)   O  O  O O  Self-directing(SFD)    O  O O O 	36	['CPR']	['S', 'Corrective', 'O', 'O', 'Self-directing', 'O']	[[51, 54]]	[[0, 1], [69, 79], [22, 23], [22, 23], [98, 112], [22, 23]]
36	Among  three state-of-the-art systems we have, the best Fscores of single character location (SCL) and single character person (SCP) are 43.63% and 43.48% 	37	['SCL', 'SCP']	['single character location', 'single character person']	[[94, 97], [128, 131]]	[[67, 92], [103, 126]]
37	5. Introducing background knowledge via CCMs [30 min]   We will look at ways in which Constrained Conditional Models (CCMs)can be used to  augment probabilistic models with declarative constraints in order to support decisions 	38	['CCMs']	['at', 'in', 'Constrained Conditional Models', 'in']	[[40, 44]]	[[69, 71], [11, 13], [86, 116], [11, 13]]
38	bor.hodoscek@gmail.com Abstract Regarding the construction of an ontology of Japanese lexical properties (JLP-O) as fundamental in terms of establishing a conceptual framework to guide and facilitate the construction of a large-scale	39	['JLP-O']	['Japanese lexical properties', 'a', 'a']	[[106, 111]]	[[77, 104], [15, 16], [15, 16]]
39	Abstract  This paper presents a new approach  based on Equivalent Pseudowords (EPs)  to tackle Word Sense Disambiguation 	40	['EPs']	['a', 'Equivalent Pseudowords']	[[79, 82]]	[[5, 6], [55, 77]]
40	phrase-based decoder that has been augmented to translate ambiguous input given in the form of a confusion network (CN), a weighted finite state representation of a	41	['CN']	['a confusion network', 'a']	[[116, 118]]	[[95, 114], [3, 4]]
41	BACKGROUN D The LOLITA (Large-scale, Object-based, Linguistic Interactor, Translator, and Analyser) system is de signed as a general purpose Natural Language Processing (NLP) system and has been under development a t the University of Durham since 1986 .	42	['LOLITA', 'NLP']	['a', 'Natural Language Processing', 'a t']	[[16, 22], [170, 173]]	[[25, 26], [141, 168], [213, 216]]
42	al. ( 2008), on the other hand, include features from the grammar in a maximum entropy (ME) classifier to predict new lexical entries for the	43	['ME']	['a maximum entropy']	[[88, 90]]	[[69, 86]]
43	 select_id_schema(Sign,Sit,Phrase,NewSit) :-  id_schema(ID),  extend~sit (Sit,NewS\]l), 	44	['ID']	['id_schema']	[[55, 57]]	[[7, 16]]
44	different tags: B-L (Beginning of a literal chunk), I-L (Inside of a literal chunk), B-I (Beginning an Idiomatic chunk), I-I (Inside an Idiomatic chunk), O (Outside a chunk).	45	['B-L', 'I-L', 'B-I']	['Beginning of a literal', 'Inside of a literal', 'Beginning an Idiomatic', 'Inside an Idiomatic', 'Outside a']	[[16, 19], [52, 55], [85, 88]]	[[21, 43], [57, 76], [90, 112], [126, 145], [157, 166]]
45	Besides, other tools such as ELAN2 or Anvil3 are available as well, as are tool kits such as the Annotation Graph Toolkit (AGTK)4 or the NITE XML Toolkit.5 While multimodal annotation	46	['ELAN2', 'AGTK', 'NITE']	['Annotation Graph Toolkit']	[[29, 34], [123, 127], [137, 141]]	[[97, 121]]
46	Eparl+NC no 29.28 (0.11) 55.28 (0.13) Eparl+NC yes 29.26 (0.10) 55.44 (0.29) Table 1: Results of the study on number translation (NT) from English to French	47	['no', 'NT']	['on number translation']	[[9, 11], [130, 132]]	[[107, 128]]
47	Xue and Palmer, 2005). The present version  PCTB5 (PCTB Version 5), contains 18,782 sentences, 507,222 words, 824,983 Hanzi and 890 	48	['PCTB5', 'PCTB']	['5']	[[44, 49], [44, 48]]	[[19, 20]]
48	Proper noun (PropN): yes when the description has a capitalized initial.  Restrictive postmodification (RPostm): yes if the definite description is modified by relative or associative clauses.	49	['PropN', 'RPostm']	['Proper noun', 'a', 'Restrictive postmodification', 'or']	[[13, 18], [104, 110]]	[[0, 11], [47, 48], [74, 102], [169, 171]]
49	ply it on substrings of names. In the English to Russian task, we report ACC (Accuracy in top-1) of 0.545,  Mean F-score of 0.917, and MRR (Mean Reciprocal  	50	['ACC', 'MRR']	['Accuracy', 'Mean']	[[73, 76], [135, 138]]	[[78, 86], [108, 112]]
50	Lexico-syntactic properties of English Non-Deverbal Event Nouns (NDV E N),  Process Nouns (PR-N) and Result Nouns (RESN) and Non Event Nouns (NEN).	51	['NDV', 'PR-N', 'RESN']	['Non-Deverbal', 'Event Nouns', 'E N', 'Process Nouns', 'Result Nouns', 'Non Event Nouns']	[[65, 68], [91, 95], [115, 119]]	[[39, 51], [52, 63], [69, 72], [76, 89], [101, 113], [125, 140]]
51	dimensionality reduction. NG = ngrams, E = emoticon replacement, IR = informal register replacement, TL = tweet length, RT = retweet count, SVO = subject-verb-	52	['NG', 'IR', 'TL', 'RT', 'SVO']	['ngrams', 'emoticon', 'informal register replacement', 'tweet length', 'retweet count']	[[26, 28], [65, 67], [101, 103], [120, 122], [140, 143]]	[[31, 37], [43, 51], [70, 99], [106, 118], [125, 138]]
52	levels of the discourse tree. Segmented Discourse  Structure Theory (SDRT) is introduced (Asher,  1993) and the predictions of this theory are dis- 	53	['SDRT']	['Segmented Discourse Structure Theory', 'is']	[[69, 73]]	[[-1, 35], [15, 17]]
53	We describe two classifiers we have built for relevance. A Naive Bayes classifier (NB) was used as the baseline.	54	['NB']	['Naive Bayes classifier']	[[83, 85]]	[[59, 81]]
54	On all test sets, and for both the evaluation metrics used, the results achieved by the classifier built from the automatically annotated training set (AA) produces lower error rates (Weighted FPR-FDR)	55	['AA']	['annotated training set']	[[152, 154]]	[[128, 150]]
55	Figure 1: The system combination architecture.  system prior weights and a language model (LM). 	56	['LM']	['a language model']	[[91, 93]]	[[73, 89]]
56	and its too slowly paced to be a thriller.  Question Classification (QC)What is the temperature at the center of the earth? numberWhat state did the Battle of Bighorn take place in?	57	['QC']	['a', 'Question Classification', 'at']	[[69, 71]]	[[0, 1], [44, 67], [62, 64]]
57	Table 3: AMT evaluation results. Numbers are percentages or counts. BL = baseline, SY = system, N-D = no decision, B=S = same sentence selected by baseline and system	58	['AMT', 'BL', 'SY', 'N-D']	['baseline', 'system', 'no decision', 'same sentence', 'baseline']	[[9, 12], [68, 70], [83, 85], [96, 99]]	[[73, 81], [88, 94], [102, 113], [121, 134], [73, 81]]
58	 From the annotation pipeline we extracted as features: the polar words (PolW) and their basic polarity (Pol); the sentiment annotations from LIWC	59	[')']	['words']	[[76, 77]]	[[65, 70]]
59	There-fore, the end for the tram was sealed in the 1970s.] As an application example, a small corpus consisting of 21 newspaper articles is analyzed. The corpus belongs to the interdisciplinary pro-ject Future Mobility (FuMob), which is funded by the Excellent Initiative of the German federal and state governments. The methodological ap-proach consists of three steps, which are per-formed iteratively: (1) manual discourse-linguistic argumentation analysis, (2) semi-automatic Text Mining (PoS-tagging and linguis-tic multi-level annotation), and (3) data merge.	60	['FuMob']	['in', 'a', 'Future Mobility', 'Text Mining']	[[220, 225]]	[[44, 46], [30, 31], [203, 218], [480, 491]]
60	~21   Proceedings of the Workshop on Discourse in Machine Translation (DiscoMT), pages 10?18, Sofia, Bulgaria, August 9, 2013.	61	['DiscoMT']	['on Discourse in Machine Translation']	[[71, 78]]	[[34, 69]]
61	For instance, in (def4) a polar interrogative clauses  (I'olS) is detined as a verb-first clause (V1S), which  in (def3) is deiined as a main clause (MainS), which  in turn is defined as a clause (S).	62	[')']	['in', 'a', 'a', 'clause', 'in', 'a', 'clause', 'in', 'a clause']	[[22, 23]]	[[4, 6], [8, 9], [8, 9], [46, 52], [4, 6], [8, 9], [46, 52], [4, 6], [187, 195]]
62	number of correct matched constituents in proposed parse  number of constituents in treebank parse  3) Crossing Brackets(CBs) ffinumber of constituents which violate constituent boundaries with a  constituent inthe treebank parse.	63	['CBs']	['in', 'in', 'Crossing Brackets', 'a']	[[121, 124]]	[[39, 41], [39, 41], [103, 120], [19, 20]]
63	 1 Introduction Word Sense Disambiguation (WSD) is the process of resolving the meaning of a word unambiguously	64	[')']	['Sense Disambiguation', 'is', 'a']	[[45, 46]]	[[20, 40], [27, 29], [29, 30]]
64	In order to represent gram-  mar rules distributively, we adopt categorial unifi-  cAtion grammar (CUG) Where eaclh category owns  its functional type.	65	[')']	['unifi- cAtion grammar']	[[102, 103]]	[[-1, 20]]
65	Translate has achieved very good results on the  Chinese-to-English translation tracks of NIST open  machine translation test (MT)5 and it ranks the first  on most tracks.	66	['NIST', 'MT']	['on', 'translation', 'machine translation test', 'it', 'on']	[[90, 94], [127, 129]]	[[41, 43], [68, 79], [101, 125], [136, 138], [41, 43]]
66	 In earlier topic modeling work such as latent Dirichlet alocation (LDA) (Blei et al, 2003; Griffiths and Steyvers, 2004), documents are treated as bags of	67	['LDA']	['latent Dirichlet alocation', 'et']	[[67, 70]]	[[39, 65], [53, 55]]
67	Apart from  other features, each modifier should be anno/atecl  with a pragmatic function feature (PRAGM), which  specifies why a modifier is used it: an NP.	68	[')']	['a', 'function feature', 'a']	[[104, 105]]	[[2, 3], [81, 97], [2, 3]]
68	way as the above feature.  The Acoustic Features (AF) were extracted directly from the wave files using SoX: Minimum,	69	['AF', 'SoX']	['Acoustic Features']	[[50, 52], [104, 107]]	[[31, 48]]
69	factfinding? technology, Information Extraction (IE), to determine exactly what happened in each article:	70	['IE']	['Information Extraction']	[[49, 51]]	[[25, 47]]
70	 Relations between function words and content words (e.g. specifier (SPR), marker complement (CMP), infinitival zu marker (PM)) are frequent and	71	['SPR', 'CMP', 'PM']	['specifier', 'marker complement', 'infinitival zu marker']	[[68, 71], [93, 96], [122, 124]]	[[57, 66], [74, 91], [99, 120]]
71	name along the path ? LCA (Lowest Common Ancestor) path that is from ORG name to its lowest common ancestor with PRO name	72	['LCA', 'ORG', 'PRO']	['Lowest Common Ancestor', 'to']	[[22, 25], [69, 72], [113, 116]]	[[27, 49], [46, 48]]
72	1 The following abbreviations are used POSS = possessive prefix/suffix; LOC = locative suffix; OBV = obviative suffix; DIM = diminutive suffix; NUM = number marking suffix; IN	73	[]	[]	[]	[]
73	the Brill tagger.  NNP = proper noun, CD = cardinal number,  CC = coordinating conjunction, JJ = adjective, VBG = verb,  gerund/present participle 	74	['NNP', 'CD', 'CC', 'JJ', 'VBG']	['cardinal', 'coordinating conjunction', 'adjective', 'verb']	[[19, 22], [38, 40], [61, 63], [92, 94], [108, 111]]	[[43, 51], [66, 90], [97, 106], [114, 118]]
74	natural_object(NOBJ) substance(SUB)  food(FOOD) artifact(AFT) article(ART)  location(LOC) psych_feature(PSY)  cognition(COG) feeling(FEEL) 	75	['NOBJ', 'SUB', 'FOOD', 'AFT', 'ART', 'LOC', 'PSY', 'COG', 'FEEL']	['natural_object', 'substance', 'food', 'artifact', 'article', 'location', 'psych_feature', 'cognition', 'feeling']	[[15, 19], [31, 34], [42, 46], [57, 60], [70, 73], [85, 88], [104, 107], [120, 123], [133, 137]]	[[0, 14], [21, 30], [37, 41], [48, 56], [62, 69], [76, 84], [90, 103], [110, 119], [125, 132]]
75	the increase is.  Table 2 shows the average solve time (ST) for sentences with respect to the number of tokens in	76	['ST']	['average solve time']	[[56, 58]]	[[36, 54]]
76	language processing. Specifically, stochastic finitestate transducers (SFSTs) have proved to be useful for machine translation tasks within restricted do-	77	['SFSTs']	['stochastic finitestate transducers', 'to']	[[71, 76]]	[[35, 69], [36, 38]]
77	Inspired by our experience of dealing with different text classification problems, we decide to  employ a linear support vector machine (SVM) in  our NLI2013 system.	78	['SVM']	['to', 'a', 'support vector machine', 'in']	[[137, 140]]	[[93, 95], [32, 33], [113, 135], [34, 36]]
78	 The transformation phase is done by applying singular value decomposition (SVD) to the initial term-by-sentence matrix defined as A = U?V T .	79	[')']	['value decomposition']	[[78, 79]]	[[54, 73]]
79	Abstract WordNet, a widely used sense inventory for Word Sense Disambiguation(WSD), is often too fine-grained for many Natural Language	80	['WSD']	['a', 'Word Sense Disambiguation', 'is']	[[78, 81]]	[[5, 6], [52, 77], [64, 66]]
80	Mihael Arcan and Paul Buitelaar Unit for Natural Language Processing, Digital Enterprise Research Institute (DERI) National University of Ireland Galway (NUIG)	81	['DERI', 'NUIG']	['Digital Enterprise Research Institute', 'National University of Ireland Galway']	[[109, 113], [154, 158]]	[[70, 107], [115, 152]]
81	 For French, the main problem was to retrieve MWEs (Multi Word Expression) in pred data mode.	82	[]	['Word Expression )']	[]	[[-1, 16]]
82	General-type: region Specific type: RCC Spatial value: PP (proper part) Dynamic	83	['RCC', 'PP']	['part']	[[36, 39], [55, 57]]	[[66, 70]]
83	system of Conceptual Dependency (Schank 1975). Some of the  Conceptual Dependency (CD) s t r u c t u r e s  are passed on to a program  which expresses them in E n g l i s h .	84	['CD']	['Conceptual Dependency', 'Conceptual Dependency', 't r', 't', 'e', 'a', 'n', 'l']	[[83, 85]]	[[10, 31], [10, 31], [89, 92], [3, 4], [4, 5], [18, 19], [12, 13], [19, 20]]
84	60  Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 118?125, Seoul, South Korea, 5-6 July 2012.	85	['SIGDIAL']	['Special Interest Group on Discourse and Dialogue']	[[100, 107]]	[[50, 98]]
85	 Chapter 1 has the lowest pi?S score in the table, and also the highest bias (BS). One of the reasons for	86	['S']	['highest bias']	[[28, 29]]	[[63, 75]]
86	order to adapt them to process dialects. This paper adopts this general framework: we propose a method to build a lexicon of deverbal nouns for Tunisian (TUN) using MSA tools and resources as starting material.	87	['TUN', 'MSA']	['a', 'a', 'Tunisian']	[[154, 157], [165, 168]]	[[9, 10], [9, 10], [144, 152]]
87	3 Approach Following this intuition, we fit a directed Gaussian graphical model (GGM) that simultaneously considers (i) each word?s embedding (obtained from	88	['GGM']	['a', 'Gaussian graphical model', 'i', 's']	[[81, 84]]	[[7, 8], [55, 79], [17, 18], [24, 25]]
88	In Proc. of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL). 	89	['ACL']	['Association for Computational Linguistics']	[[86, 89]]	[[43, 84]]
89	teacher for advice.  	90	[]	[]	[]	[]
90	models. Among stochastic models, bi-gram and  tri-gram Hidden Markov Model (HMM) are  quite popular.	91	['HMM']	['Hidden Markov Model']	[[76, 79]]	[[55, 74]]
91	els, which seamlessly incorporates graphbased and more general supervision by extending the posterior regularization (PR) framework.	92	['PR']	['posterior regularization']	[[118, 120]]	[[92, 116]]
92	{alexispalmer,ponvert,jbaldrid,carlotasmith}@mail.utexas.edu Abstract Situation entities (SEs) are the events, states, generic statements, and embedded facts and	93	['SEs']	['Situation entities']	[[90, 93]]	[[70, 88]]
93	 Conf. Computational Linguistics (COLING), pages 89?97.	94	['COLING']	['Computational Linguistics']	[[33, 39]]	[[6, 31]]
94	TO-DEATH).  VAg and related NPs/PPs (VAgRel) This is similar to VPa above, but for VAg.	95	['VAg', 'VPa']	[]	[[12, 15], [64, 67]]	[]
95	Reduced Sentences 0.121 0.055 4.89 0.027* 1.129 1.01 to 1.26 Constant 5.23 1.18 19.67 <0.000* 187.25 ADAG, n=242; HAG, n = 242; S.E = standard error; OR = Odds ratio or Exp(?); CI = confidence Interval.	96	['ADAG', 'HAG', 'S.E', 'OR', 'CI']	['n', 'standard error', 'Odds ratio', 'confidence Interval']	[[101, 105], [114, 117], [128, 131], [150, 152], [177, 179]]	[[10, 11], [134, 148], [155, 165], [182, 201]]
96	to learn coherent topics. To solve this problem, we build a Markov Random Field (MRF) regularized Latent Dirichlet Allocation (LDA)	97	['MRF', 'LDA']	['a Markov Random Field', 'Latent Dirichlet Allocation']	[[81, 84], [127, 130]]	[[58, 79], [98, 125]]
97	mensions. The counts were then transformed into Local Mutual Information (LMI) scores, an association measure that closely approximates the com-	98	['LMI']	['Local Mutual Information']	[[74, 77]]	[[48, 72]]
98	bringert@chalmers.se Abstract Grammatical Framework (GF) is a grammar formalism which supports interlingua-	99	['GF']	['Grammatical Framework', 'a']	[[53, 55]]	[[30, 51], [11, 12]]
99	 Conf. on Language Resources and Evaluation (LREC), pages 697?702, Genoa, Italy, May.	100	[')']	['Resources']	[[48, 49]]	[[18, 27]]
100	stantin, Evan Herbst, Moses: Open Source Toolkit for Statistical Machine Translation, Annual Meeting of the Association for Computational Linguistics (ACL), demonstration session, Prague, Czech Republic, June	101	['ACL']	['for', 'Association for Computational Linguistics']	[[151, 154]]	[[49, 52], [108, 149]]
101	 In an effort to apply such models to noisy optical character recognition (OCR) text output, we endeavor to understand the effect	102	['OCR']	['an', 'optical character recognition']	[[74, 77]]	[[3, 5], [43, 72]]
102	the fragment space that can describe all the trees in Ms. Fragment Mining and Indexing (FMI) In Equation 1 it is possible to isolate the gradient ~w =?	103	['FMI']	['in', 'Fragment Mining and Indexing', 'In']	[[88, 91]]	[[51, 53], [58, 86], [78, 80]]
103	Section 3 for exact criteria), reporting  approximately 40% precision and 45% recall for  transitional probability (TP) and 50% precision and  53% recall for mutual information (MI) on the first 	104	['TP', 'MI']	['for', 'for transitional probability', 'for mutual information', 'on']	[[116, 118], [178, 180]]	[[10, 13], [-1, 27], [154, 176], [5, 7]]
104	are at least four candidates: less studied (LS) languages, resource scarce (RS) languages, less computerized (LC) languages, and less privileged (LP) languages.	105	['LS', 'RS', 'LC', 'LP']	['are', 'less studied', 'resource scarce', 'less computerized', 'less privileged']	[[44, 46], [76, 78], [110, 112], [146, 148]]	[[0, 3], [30, 42], [59, 74], [91, 108], [129, 144]]
105	thesauri: Macquarie, Moby, Oxford and Roget?s.  The inverse rank (InvR) metric allows a comparison to be made between the extracted rank list	106	['InvR']	['inverse rank', 'a', 'rank']	[[66, 70]]	[[52, 64], [4, 5], [60, 64]]
106	  1 Introduction  Word Sense Disambiguation (WSD) is wellknown as one of the more difficult problems in 	107	[')']	['Sense Disambiguation', 'is']	[[46, 47]]	[[21, 41], [28, 30]]
107	FF-AUTO-NONE Fullform Auto None FF-DEFAULT-GRAM Fullform Default Auto (GRAM) FF-AUTO-GRAM Fullform Auto Auto (GRAM) FF-DEFAULT-SAO* Fullform Default Auto (SAO)	108	['FF-AUTO-NONE', 'SAO']	['Fullform', 'Auto', 'Fullform Default Auto', 'GRAM', 'Fullform Auto Auto', 'Fullform Default Auto']	[[0, 12], [127, 130]]	[[13, 21], [22, 26], [48, 69], [43, 47], [90, 108], [48, 69]]
108	The parameters are trained using the 764 Margin Infused Relaxed Algorithm (MIRA) (Crammer et al, 2006).	109	[')']	['Infused Relaxed Algorithm']	[[79, 80]]	[[48, 73]]
109	 ? Activity Tree (AT): a tree-structure representing the current, past, and planned activities that	110	[')']	['Tree']	[[19, 20]]	[[11, 15]]
110	ging from Merialdo (1994). The approach involved training a standard Hidden Markov Model (HMM) using the Expectation Maximization (EM) algo-	111	['HMM', 'EM']	['a', 'Hidden Markov Model', 'Expectation Maximization']	[[90, 93], [131, 133]]	[[14, 15], [69, 88], [105, 129]]
111	email: {firstname.lastname} @itri.bton.ac.uk  Introduction ~,  WYSIWYM (What You See Is What You Meant) is a user interface technique which allows anauthor to create  and edit in a natural and simple way the knowledge contained in a generated document.	112	['WYSIWYM']	['What You See Is What You Meant', 'a', 'a', 'a']	[[63, 70]]	[[72, 102], [2, 3], [2, 3], [2, 3]]
112	and beyond, in several AI applications. Neel and Garzon (2010) show that the quality of a knowledge resource like WN affects the performance in recognizing textual entailment (RTE) and word-sense disambiguation (WSD) tasks.	113	['AI', 'WN', 'RTE', 'WSD']	['a', 'textual entailment', 'word-sense disambiguation']	[[23, 25], [114, 116], [176, 179], [212, 215]]	[[0, 1], [156, 174], [185, 210]]
113	This measure combines two metrics. The first metric, predicted frequency (PF), estimates the degree to which a word appears to be used consis-	114	['PF']	['predicted frequency', 'a']	[[74, 76]]	[[53, 72], [7, 8]]
114	Table 5: Participating teams and references to system descriptions. Abbreviations: BI=Bioinformatician, NLP=Natural Language Processing researcher, CS=Computer Scientist, LI=Linguist, ML=Machine Learning researcher.	115	[]	['Language Processing', 'Scientist', 'Learning']	[]	[[116, 135], [160, 169], [195, 203]]
115	predictive ones among all our features. We used the Correlation based Feature Subset (CFS) selection method in WEKA for this purpose.	116	['CFS', 'WEKA']	['Correlation based Feature Subset']	[[86, 89], [111, 115]]	[[52, 84]]
116	In Ellen M. Voorhees and Donna K. Harman, editors, The Seventh Text Retrieval Conference (TREC-7), volume 7.	117	['TREC-7']	['Seventh Text Retrieval Conference']	[[90, 96]]	[[55, 88]]
117	currently concerns include Chinese personal  names( CN), transliterated foreign personal names( TFN)  and Chinese place names(CPN). They can not be 	118	['CN', 'TFN', 'CPN']	['Chinese personal names', 'foreign personal names', 'Chinese place names']	[[52, 54], [96, 99], [126, 129]]	[[-1, 21], [72, 94], [106, 125]]
118	The results are reported for Same Sentence (SS) and Previous Sentence (PS) models, and the joined results for each of the arguments (ALL) as average	119	[')']	['Sentence', 'Sentence']	[[46, 47]]	[[34, 42], [34, 42]]
119	some structural constraints which are mostly prag-  matic in natnre:  2based on PVM (parallel virtual madfine)  semRnb~ 	120	['PVM']	['in', 'parallel virtual madfine']	[[80, 83]]	[[23, 25], [85, 109]]
120	 and Iryna Gurevych Ubiquitous Knowledge Processing (UKP) Lab Computer Science Department	121	['UKP']	['Ubiquitous Knowledge Processing']	[[52, 55]]	[[19, 50]]
121	This paper describes the Universal Decompositional Semantics (Decomp) project, which aims to augments Universal Dependencies (UD) data sets with robust, scalable semantic annotations based in lin-	122	['Decomp', 'UD']	['Universal Decompositional Semantics', 'Universal Dependencies']	[[35, 41], [126, 128]]	[[25, 60], [102, 124]]
122	of National Intelligence (ODNI) and the Intelligence Advanced Research Projects Activity (IARPA) via the Air Force Research Laboratory (AFRL) contract number FA8750-16-C-0114.	123	['ODNI', 'IARPA', 'AFRL']	['National Intelligence', 'Intelligence Advanced Research Projects Activity', 'Air Force Research Laboratory']	[[26, 30], [90, 95], [136, 140]]	[[3, 24], [40, 88], [105, 134]]
123	nominal elements. For German, we see confusions with the object functions (accusative OA and dative objects DA), predicates (PD), and the EP function marking expletive pronouns in subject position.	124	['OA', 'DA', 'PD', 'EP']	['object', 'objects', 'predicates']	[[86, 88], [108, 110], [125, 127], [138, 140]]	[[57, 63], [100, 107], [113, 123]]
124	"trated in Figure 1. At the outset, the table (T1), the  pump (PU), the apprentice (you) and the compressor  (COMP) are in ""primary focus""."	125	['PU', 'COMP']	['pump', 'compressor']	[[62, 64], [109, 113]]	[[56, 60], [96, 106]]
125	 Thirdly, most PROLOG implementations include a  version of metamorphosis grammars (MGs), a logic-  based formalism useful in particular for describing NL 	126	[')']	['a', 'grammars', 'a']	[[86, 87]]	[[30, 31], [73, 81], [30, 31]]
126	  Machine Translation (prototype phase)  The machine translation (MT) sub-component  implements the hybrid MT paradigm, combining 	127	['MT']	['machine translation']	[[64, 66]]	[[43, 62]]
127	for 4 of the 9 classes, and was usually competitive on the remaining 5 classes. WordNet (W.Net) consistently produced high precision, but with compar-	128	['.']	['WordNet']	[[78, 79]]	[[80, 87]]
128	as dependants. Dependency structures are suit-  ably depicted as a directed acyclic graph(DAG),  where arrows direct from dependants to gover- 	129	['DAG']	['a directed acyclic graph', 'direct']	[[90, 93]]	[[65, 89], [67, 73]]
129	These derivations were induced using a collapsed Gibbs sampler, which sampled from the posterior of a Dirichlet process (DP) defined over the subtree rewrites of each nonterminal.	130	['DP']	['Dirichlet process']	[[121, 123]]	[[102, 119]]
130	 For both these models, we use cost sensitive LibSVM with radial basis kernel function (RBF) as the learning algorithm (Hsu et al.,	131	['LibSVM', 'RBF']	['radial basis kernel function', 'as']	[[45, 51], [87, 90]]	[[57, 85], [65, 67]]
131	is also significant that this model?s paraphraser can be employed not only for MT but also for most natural language processing (NLP) applications.	132	['MT', 'NLP']	['s', 'natural language processing']	[[79, 81], [129, 132]]	[[1, 2], [100, 127]]
132	6.2 Methodology We conducted experiments on MUC-6, ACE-2004, and ACE Phrase-2 (ACE-2). We evaluated our sys-	133	['MUC-6']	['ACE Phrase-2']	[[44, 49]]	[[65, 77]]
133	ALCOGRAM. ? P2E5N5S1, C T W D A I Common Logic Controlled English (CLCE) (Sowa 2004) is a language that can be translated into first-order logic with equality in the form of the Conceptual Graph	134	['P2E5N5S1']	['C', 'Common Logic Controlled English']	[[12, 20]]	[[2, 3], [34, 65]]
134	text categorization tasks. The newer method of Latent Semantic Indexing (LSI) 3 (Deerwester et al.,	135	['LSI']	['Latent Semantic Indexing']	[[73, 76]]	[[47, 71]]
135	non-terminals is extended by means of conditional and additive categories according to Combinatory Categorical Grammar (CCG) (Steedman, 1999). 	136	['CCG']	['to Combinatory Categorical Grammar']	[[120, 123]]	[[84, 118]]
136	 These models are trained only using negative entities which we refer to as Negative Entity (NE) objective. 	137	[')']	['Entity']	[[94, 95]]	[[84, 90]]
137	main line of the narrative. This move is signaled  by the temporal focus (TF), and the entire deictic  center, returning to an established node in the 	138	['TF']	['temporal focus']	[[74, 76]]	[[58, 72]]
138	 4.1 Task  The Spontaneous Scheduling Task (SST) databases  are a collection of dialogues in which two speak- 	139	[')']	['Scheduling Task', 'a', 'in']	[[46, 47]]	[[26, 41], [5, 6], [33, 35]]
139	The Chinese text is segmented with a segmenter trained on CTB data using conditional random fields (CRF). Language models	140	['CTB', 'CRF']	['a', 'on', 'conditional random fields']	[[58, 61], [100, 103]]	[[35, 36], [55, 57], [73, 98]]
140	retrieval effectiveness. The following figure  shows the change of average precision (AvgP)  using CDQE (Model 2) along with the change of 	141	['AvgP', 'CDQE']	['average precision']	[[86, 90], [99, 103]]	[[67, 84]]
141	level-2 domains) yet still did not sufficiently cover relevant subject fields identified by our users, such as IT, medicine and mechanical engineering. The Internal Classification for Standards (ICS) scheme was considered next, as it covers technical subject fields, but it was lacking with respect to legal and	142	['IT', 'ICS']	['and', 'Internal Classification for Standards']	[[111, 113], [195, 198]]	[[124, 127], [156, 193]]
142	logical subject/object and its verb governor, General  Event (GE) on who did what when and where and  Predefined Event (PE) such as Management  Succession and Company Acquisition.	143	['GE', 'PE']	['General Event', 'Predefined Event']	[[62, 64], [120, 122]]	[[-1, 12], [102, 118]]
143	 We cover two main thrusts: (i) a black-box evaluation of several NE taggers (commercial and research systems); and (ii) an error analysis of system performance. 2.1 Evaluation data Our evaluation data set contains three distinct sec-tions.  The largest component consists of publicly-available financial reports filed with the Securities and Exchange Commission (SEC), in particular the 2003 forms 10-K filed by eight Fortune 500 com-panies.  These corporate annual reports share the same subject matter as much business news: sales, profits, acquisitions, business strategies and the like.	144	['NE', 'SEC']	['i', 'a', 'and', 'and', 'an', 'Securities and Exchange Commission', 'and']	[[65, 67], [363, 366]]	[[15, 16], [14, 15], [88, 91], [88, 91], [88, 90], [327, 361], [88, 91]]
144	@math.canterbury.ac.nz Abstract We introduce Peripheral Diversity (PD) as a knowledge-based approach to achieve multi-	145	['PD']	['Peripheral Diversity', 'a']	[[67, 69]]	[[45, 65], [2, 3]]
145	SS 0.47 5.1 100 times faster than that of Tree Kernel, and the retrieval speed of Subpath Set (SS) is about 1,000 times faster than that of Tree Kernel.	146	['SS']	['Subpath Set']	[[0, 2]]	[[82, 93]]
146	grammar (LTAG) (Bangalore and Joshi, 1999) and then extended to other lexicalized grammars, such as combinatory categorial grammar (CCG) (Clark, 2002) and Head-driven phrase structure grammar	147	['LTAG', 'CCG']	['grammar', 'to', 'combinatory categorial grammar']	[[9, 13], [132, 135]]	[[0, 7], [61, 63], [100, 130]]
147	embeddings from the Neural Language Model of Collobert and Weston [2008] and word representations from random indexing (RI)1. These, however, were	148	['RI']	['indexing']	[[120, 122]]	[[110, 118]]
148	Finally, some Wikipages are redirections to other pages, e.g. SODA (SODIUM CARBONATE) redirects to SODIUM CARBONATE.	149	['SODA']	['SODIUM CARBONATE', 'SODIUM CARBONATE']	[[62, 66]]	[[68, 84], [68, 84]]
149	 : : , .  :~..~. NAT =nat iona =ty .:~:~',,~,.~ . .:.-,~.~;~ SRC~.;ob I .~concrete-:,~ 	150	['NAT']	['iona']	[[16, 19]]	[[25, 29]]
150	+ BD 67.4 67.0 67.2 + NEG + BD 67.4 67.1 67.3 Table 1: Results on development corpus: LP = labeled precision, LR = labeled recall, F1 = balanced F-measure	151	['BD', 'NEG', 'LP', 'LR']	['on', 'labeled precision', 'labeled recall', 'balanced']	[[2, 4], [22, 25], [86, 88], [110, 112]]	[[63, 65], [91, 108], [115, 129], [136, 144]]
151	Machine Translation. In 41st Annual Meeting of the Association for Computational Linguistics (ACL), pages 192?202, Sapporo, Japan.	152	['ACL']	['Association for Computational Linguistics']	[[94, 97]]	[[51, 92]]
152	against three baselines. The first baseline was based on the minimum overlap (MinOv) of characters in consecutive scenes and corresponds closely to the	153	['MinOv']	['minimum overlap', 'in']	[[78, 83]]	[[61, 76], [3, 5]]
153	by a rhetorical relation R, Triple=verb pair associated with a relation R in V 2 R, BG = Background, cont.=continuation, elab.=elaboration.	154	['BG']	['a', 'a', 'Background']	[[84, 86]]	[[3, 4], [3, 4], [89, 99]]
154	contains two data sets, training and devtest, which were used for training and testing, respectively. Each of these sets is further divided into three domains: newswire (NWire), newspaper (NPaper), and broadcast news (BNews).	155	['BNews']	['broadcast news']	[[218, 223]]	[[202, 216]]
155	Allocation (LDA), but using linguistic dependency information in place of simple features from bag of words (BOW) representations.	156	['LDA', 'BOW']	['of', 'bag of words']	[[12, 15], [109, 112]]	[[71, 73], [95, 107]]
156	Pseudo-disambiguation results for inverse selectional preferences (BNC as primary and secondary corpus, DISCR weighting). ER = Error rate; Cov = Coverage. 	157	['BNC', 'DISCR', 'ER', 'Cov']	['Error rate', 'Coverage']	[[67, 70], [104, 109], [122, 124], [139, 142]]	[[127, 137], [145, 153]]
157	 Results and Analysis  A finite state machine (FSM) description of user be-  havior was used to analyze session data.	158	['FSM', ')']	['finite state machine']	[[46, 49], [49, 50]]	[[24, 44]]
158	is used to generate ground truth answers).  The Children?s Book Test (CBT) dataset, created by Hill et al (2016), contains 113,719 cloze-style	159	['CBT']	['Children ? s Book Test']	[[70, 73]]	[[-1, 21]]
159	ipants represent cognitive scenarios as schematic representations of events, objects, situations, or states of affairs. The participants are called frame elements (FEs) and are described in terms of semantic roles such as AGENT, LOCATION, or MANNER.	160	['FEs', 'AGENT', 'LOCATION', 'MANNER']	['frame elements']	[[164, 167], [222, 227], [229, 237], [242, 248]]	[[148, 162]]
160	do you have? for taskswitching (SWT) and poker-playing (PKR) respectively.	161	['SWT', 'PKR']	[]	[[32, 35], [56, 59]]	[]
161	Conjoined noun phrases are required to all  be members of the same semantic  class, which may be one of the set PERSON, PHYSOB (physical object), LOCNAME  (location name), ATTRNAME (attribute name), or MEASU (measurement unit). 	162	[]	['object', 'name', 'name )', 'unit']	[]	[[137, 143], [165, 169], [-1, 5], [221, 225]]
162	mation is likely to be found). This is similar to  tasks such as named entity recognition (NER) or  part-of-speech tagging, where sequence modeling 	163	['NER']	['named entity recognition']	[[91, 94]]	[[65, 89]]
163	this assumption.  In a synchronous TAG (STAG) the elementary structures are ordered pairs of TAG trees, with a	164	[]	['a synchronous TAG', 'TAG']	[]	[[21, 38], [35, 38]]
164	3.2 Graph-based Approaches Laparra et al(2010) utilize the SSI-Dijkstra+ algorithm to align FN lexical units (LUs) with WN synsets.	165	['FN', 'LUs', 'WN']	['al', 'lexical units']	[[92, 94], [110, 113], [120, 122]]	[[38, 40], [95, 108]]
165	 2.1 Multilingual Central Repository The Multilingual Central Repository (MCR)2 follows the model proposed by the EuroWordNet	166	[')']	['Central Repository', 'Central Repository']	[[76, 77]]	[[17, 35], [17, 35]]
166	POL (politics) Belgium elections 2003 16 15107 15.4 SPO (sports) Kim Clijsters 9 9713 11.1 HIS (history) History of Belgium 3 8396 17.9 BUS (business) Belgium Labour Federation 9 4440 11.0	167	['POL', 'SPO', 'HIS', 'BUS']	['politics', 'sports', 'history', 'business']	[[0, 3], [52, 55], [91, 94], [136, 139]]	[[5, 13], [57, 63], [96, 103], [141, 149]]
167	study (usually as an elective) or not at all. At the  City University of New York (CUNY)?s Graduate  Center (the primary Ph.	168	['CUNY']	['City University of New York']	[[83, 87]]	[[54, 81]]
168	1992. Proceedings of the Fourth  Message Understanding Conference (MUC-$). Mor- 	169	['MUC-$']	['Fourth Message Understanding Conference']	[[67, 72]]	[[-1, 38]]
169	lemma(L)? and ? nonlem(NL)? systems for ran-	170	['L']	['lemma']	[[6, 7]]	[[0, 5]]
170	to analyse the eects of applying pronominal anaphora resolution to Question Answering (QA) systems. 	171	['QA']	['Question Answering']	[[88, 90]]	[[68, 86]]
171	 To evaluate feature effectiveness, we group the features into seven groups: textual features (TX), utterance features (UT), pointing gesture fea-	172	['TX', 'UT']	['textual', 'utterance']	[[94, 96], [119, 121]]	[[76, 83], [99, 108]]
172	number of bilingual term pairs)  We compare our model with IBM Model 2  (IBM-2), and IBM Model 4 (IBM-4) implemented by GIZA++ (Och et al, 2003).	173	['GIZA++']	['IBM Model 2', 'IBM Model 4']	[[120, 126]]	[[59, 70], [85, 96]]
173	predicted this outcome correctly in 70.37% of the cases (upper left cell). However,  IBL also predicted the outcome penultimate stress (PEN) in 25.26% of the words and  440 	174	['IBL', 'PEN']	['penultimate stress']	[[85, 88], [136, 139]]	[[116, 134]]
174	It is not useful to exploit latent  semantic analysis directly on the user-topic matrix  UR = UQ * QR , where UR represents how many  times each user is diffused for existing topic R (R 	175	['UR']	['UQ']	[[89, 91]]	[[94, 96]]
175	 Thus the determination of lexical scopes of  Complex Predicates (CPs) from a long consecutive sequence is indeed a crucial task.	176	[]	[]	[]	[]
176	baseline adapted language model.  The Table 2 shows the word error rates (WERs) of experiments on the code switching lecture	177	['WERs']	['word error rates']	[[74, 78]]	[[56, 72]]
177	This section describes the two evaluation methods we employed ? average precision (AP) and correlation coefficient (CC).	178	['AP', 'CC']	['average precision', 'correlation coefficient']	[[83, 85], [116, 118]]	[[64, 81], [91, 114]]
178	A block ?[] invokes both the inner and outer generations simultaneously in Bracket Model A (BM-A). 	179	[]	['A', 'Model A']	[]	[[0, 1], [83, 90]]
179	"In a third stage, they are put in a Multilingual Polyphraz Memory (MPM). A ""polyphrase"" is a structure"	180	[')']	['a', 'in a', 'Polyphraz Memory', 'a']	[[70, 71]]	[[3, 4], [31, 35], [49, 65], [3, 4]]
180	Semantic Information Retrieval (SIR) AQUA Sentiment Analysis in User Generated Discourse (SentAL) Internet der Dienste (THESEUS) ?	181	['SIR', 'AQUA', 'SentAL', 'THESEUS']	['Semantic Information Retrieval', 'Sentiment Analysis in User Generated Discourse', 'Internet der Dienste']	[[32, 35], [37, 41], [90, 96], [120, 127]]	[[0, 30], [42, 88], [98, 118]]
181	6 Event Ordering TimeML defines three different types of links: subordinate (SLINK), temporal (TLINK), and aspectual (ALINK).	182	['SLINK', 'ALINK']	['subordinate', 'temporal', 'aspectual']	[[77, 82], [118, 123]]	[[64, 75], [85, 93], [107, 116]]
182	Lapata, 2006). All systems were controlled to produce similar compression ratios (CR) for fair comparison.	183	['CR']	['compression ratios']	[[82, 84]]	[[62, 80]]
183	idealistic) practice of balancing and purging quirks.  6.2 Lexicography and Exploratory Data Analysis (EDA)  Statistics can be used for many different purposes.	184	['EDA']	['and', 'Lexicography and Exploratory Data Analysis']	[[103, 106]]	[[34, 37], [59, 101]]
184	4 Experimental Setup 4.1 Corpus and Experimental Expressions We use the British National Corpus (BNC),4 automatically parsed using the Collins parser (Collins,	185	['BNC']	['Corpus', 'British National Corpus']	[[97, 100]]	[[25, 31], [72, 95]]
185	redefined  While politicians all over the world want to  make Information Society Technologies (IST)  available and accessible in the language and locale 	186	[')']	['Society Technologies']	[[99, 100]]	[[74, 94]]
186	method to train large neural networks. We use mini-batch version RPROP (RMSPROP) (Hinton, 2012) to minimize the loss function.	187	['RPROP']	[]	[[65, 70]]	[]
187	words not found in the dictionary, a Markov grammar that  computes the optimal ordering of the possible classes of all  words and a Wild Card Parser (WPC), i.e., a deterministic parser  based on a Context Free Grammar.	188	['WPC']	['a', 'a Wild Card Parser', 'a', 'a']	[[150, 153]]	[[30, 31], [130, 148], [30, 31], [30, 31]]
188	 ? Conditional Random Fields (CRF) is the state  of art for named entity extraction, in the 	189	[')']	['Random Fields']	[[32, 33]]	[[14, 27]]
189	Our Chinese  word segmentation system is based on three models: (a) word boundary token (WBT) model and (b)  triple context matching model for unknown word 	190	[')']	['a', 'boundary token']	[[66, 67]]	[[25, 26], [73, 87]]
190	 With the availability of Chinese Gigaword Corpus (CGC) and Word Sketch Engine (WSE) Tools (Kilgarriff, 2004).	191	[')']	['Gigaword Corpus', 'Sketch Engine']	[[53, 54]]	[[33, 48], [64, 77]]
191	features are chosen due to their effectiveness and availability for on-line detection.  They are independent word probability (IWP), anti-word pair (AWP), word formation analogy Table 8	192	['IWP', 'AWP']	['word probability', 'anti-word pair', 'word']	[[127, 130], [149, 152]]	[[109, 125], [133, 147], [109, 113]]
192	1 Introduction RWTH?s main approach to System Combination (SC) for Machine Translation (MT) is a refined version of the ROVER approach in Automatic	193	[')']	['s', 'Combination', 'Translation', 'a', 'in']	[[61, 62]]	[[20, 21], [46, 57], [75, 86], [23, 24], [24, 26]]
193	This is called empirical Bayesian estimation. Our approach differs from maximum a posteriori (MAP) estimation, since we re-estimate the parameters of	194	['MAP']	['maximum a posteriori']	[[94, 97]]	[[72, 92]]
194	1 Introduction Statistical machine translation (MT) uses large target language models (LMs) to improve the fluency of generated texts, and it is commonly	195	[')']	['translation', 'language models']	[[50, 51]]	[[35, 46], [70, 85]]
195	Our approach to this problem is influenced by the named entity annotation in the Automatic Content Extraction (ACE) project (Consortium, 2002), in which ?	196	['ACE']	['Automatic Content Extraction']	[[111, 114]]	[[81, 109]]
196	 It is used for many natural language tasks, such as part of speech (POS) and named entity tagging (Toutanova and others, 2003; Carreras et al.,	197	[]	['part of speech']	[]	[[52, 66]]
197	NC 91.0 99.1 89.5 92.1 99.7 90.7 Table 2: Attachment score for Java and the lexical feature set, where CO = convertible and NC = nonconvertible dependency trees.	198	['NC', 'CO']	['convertible', 'nonconvertible dependency']	[[0, 2], [103, 105]]	[[108, 119], [129, 154]]
198	precisely the issue we address in this article. We concentrate on the task of automatically classifying NSUs, which we approach using machine learning (ML) techniques. Our aim	199	['NSUs', 'ML']	['in', 'machine learning']	[[104, 108], [152, 154]]	[[31, 33], [134, 150]]
199	ABSTRACT  French auxilliaries and clitics have been analysed  in the flame of U.C.G. (Unification Categorial Grammar). 	200	['U.C.G.']	['Unification Categorial Grammar']	[[78, 84]]	[[86, 116]]
200	 ? Word translation features (WT): ?	201	[')']	['translation features']	[[31, 32]]	[[7, 27]]
201	(e.g. adjective bivs?i, which means former in both languages), (b) the term partial false friends (PFF) describes pairs that are polysemous and	202	['PFF']	['i', 'partial false friends']	[[99, 102]]	[[12, 13], [76, 97]]
202	2 VIP targeted technologies  Current products for VIP such as screen readers mainly depend on speech synthesis or Braille solutions, e.g. ChromeVox [3], Windows-Eyes [4], or JAWS (Job Access With Speech) [5]. Braille displays 	203	['VIP', 'JAWS']	['Job Access With Speech']	[[2, 5], [174, 178]]	[[180, 202]]
203	Peter Robinson; Philip Tuddenham; 3 Visualisation Scalable Vector Graphics (SVG)1 is a language for describing two-dimensional graphics and graphical	204	['SVG']	['Scalable Vector Graphics', 'a']	[[76, 79]]	[[50, 74], [30, 31]]
204	Subset of significant adjacency pairs CORRECTTASKACTION?CORRECTTASKACTION;??EXTRADOMAINS?EXTRADOMAINT;?GROUNDINGS?GROUNDINGT;?ASSESSINGQUESTIONT?POSITIVEFEEDBACKS;??ASSESSINGQUESTIONS?POSITIVEFEEDBACKT;?QUESTIONT?STATEMENTS;?ASSESSINGQUESTIONT?STATEMENTS;?EXTRADOMAINT?EXTRADOMAINS;?QUESTIONS?STATEMENTT;?NEGATIVEFEEDBACKS?GROUNDINGT;?INCOMPLETETASKACTION?INCOMPLETETASKACTION;?POSITIVEFEEDBACKS?GROUNDINGT;??BUGGYTASKACTION?BUGGYTASKACTION 4 Models We learned three types of models using cross-validation with systematic sampling of training and testing sets.  4.1 First-Order Markov Model The simplest model we discuss is the first-order Markov model (MM), or bigram model (Figure 2). A MM that generates observation (state) sequence o1o2?ot is defined in the following way.	205	['MM']	['Markov', 'model', 'Markov model', 'model']	[[654, 656]]	[[578, 584], [476, 481], [640, 652], [476, 481]]
205	We searched for four conditions: depression, bipolar disorder, post traumatic stress disorder (PTSD) and seasonal affective disorder (SAD).	206	['PTSD', 'SAD']	['disorder', 'post traumatic stress disorder', 'seasonal affective disorder']	[[95, 99], [134, 137]]	[[53, 61], [63, 93], [105, 132]]
206	 ? If the key and response do not match, the category is incorrect (INC) ; if interactively assigned, a tall y appears in both the INC and XIC (interactive incorrect) columns .	207	['INC', 'XIC']	['incorrect', 'a', 'in', 'interactive incorrect']	[[67, 70], [138, 141]]	[[56, 65], [13, 14], [56, 58], [143, 164]]
207	(ARG0) and ? Greenspan? as the object (ARG1) of the noun predicate ?	208	['ARG0', 'ARG1']	[]	[[1, 5], [39, 43]]	[]
208	(2014c): ? Italian - Romanian (IT-RO); ?	209	[]	['Italian - Romanian']	[]	[[11, 29]]
209	1 Introduction Despite the advances in natural language processing (NLP), Word Sense Disambiguation (WSD) is still considered one of the most challenging prob-	210	[')']	['in', 'language processing', 'Sense Disambiguation', 'is']	[[71, 72]]	[[36, 38], [47, 66], [79, 99], [86, 88]]
210	 ? Unstressed (US) average: Each feature is normalized by its mean value in the un-	211	[')']	['is']	[[16, 17]]	[[40, 42]]
211	and a search procedure. For example, we can build a n-gram word language model (LM)?itself a large weighted FSA.	212	['LM', 'FSA']	['a', 'a', 'language model', 'a']	[[80, 82], [108, 111]]	[[0, 1], [0, 1], [64, 78], [0, 1]]
212	The key reason to compute tsim under the equiprobability assumption is that we need not compute the MWBM, but may find just the maximum cardinality bipartite matching (MCBM), since all potential links have the same weight. An O(e	213	['MWBM', 'MCBM']	['maximum cardinality bipartite matching']	[[100, 104], [168, 172]]	[[128, 166]]
213	10http://rapid-i.com/ classification problems, we were unable to achieve results with a Support Vector Machine (SVM) learner (libSVMLearner) using the Radial Base	214	['SVM']	['to', 'a Support Vector Machine']	[[112, 115]]	[[62, 64], [86, 110]]
214	 First, the matching score of the matching two nodes, NMS (Node Match Score) is calculated with their node scores, NS1 and NS2,	215	['NMS']	['Node Match Score']	[[53, 56]]	[[58, 74]]
215	2007. CRFsuite: A fast implementation of Conditional Random Fields (CRFs), http://www.chokkan.org/software/crfsuite/.	216	['CRFsuite']	['Conditional Random Fields']	[[6, 14]]	[[41, 66]]
216	rithms can also be used in discriminative settings (Bellare et al, 2009; Ganchev et al, 2010) specifically for semi-supervised learning (SSL.) 	217	['SSL']	['in', 'semi-supervised learning']	[[137, 140]]	[[24, 26], [111, 135]]
217	It makes sense now that you explained it, but I never used an else if in any of my other programs .04 POSITIVE FEEDBACK (P) Second part complete. .11 QUESTION (Q) Why couldn?t I have said if (i<5) .11 STATEMENT (S) i is my only index .07  REQUEST FOR FEEDBACK (RF) So I need to create a new method that sees how many elements are in my array? .16 RESPONSE (RSP) You mean not the length but the contents .14 UNCERTAIN FEEDBACK WITH ELABORATION (UE) I?m trying to remember how to copy arrays .008 UNCERTAIN FEEDBACK (U) Not quite yet .008  3.2 Task action annotation The tutoring sessions were task-oriented, focusing on a computer programming exercise.	218	['RF', 'UE']	['POSITIVE', 'FEEDBACK', 'P', 'QUESTION', 'STATEMENT', 'S', 'REQUEST FOR FEEDBACK', 'RESPONSE', 'UNCERTAIN FEEDBACK WITH ELABORATION', 'I', 'UNCERTAIN FEEDBACK', 'U', 'on']	[[261, 263], [151, 153]]	[[102, 110], [111, 119], [102, 103], [150, 158], [201, 210], [104, 105], [239, 259], [347, 355], [407, 442], [0, 1], [407, 425], [151, 152], [127, 129]]
218	nodes in their MRs mij . Then, after setting the context ci as the MR of the root node (MR(T ) ? ci),	219	['MR', 'MR']	['root']	[[15, 17], [15, 17]]	[[77, 81]]
219	until the current sentence (PENT) and the word entropy for the conversation subsequent to the current sentence (SENT). We hypothesize that informative	220	['PENT', 'SENT']	['sentence', 'the word entropy for the', 'the', 'sentence']	[[28, 32], [112, 116]]	[[18, 26], [38, 62], [6, 9], [18, 26]]
220	  1. PARADISEC (Pacific and Regional Archive for Digital Sources in Endangered Cultures): audio, video,  text and image resources for Australian and Pacific Island languages (Thieberger, Barwick, Billington, & 	221	[]	['and Regional Archive for Digital Sources in Endangered Cultures )', 'and', 'for', 'and']	[]	[[-1, 64], [22, 25], [43, 46], [22, 25]]
221	c, include latent variable models that simultaneously capture the semantics of words and sentences, such as latent semantic analysis (LSA) or latent Dirichlet alocation (LDA).	222	['LSA', 'LDA']	['c', 'latent', 'latent semantic analysis', 'latent Dirichlet alocation']	[[134, 137], [170, 173]]	[[0, 1], [11, 17], [108, 132], [142, 168]]
222	 Abstract Minimum Error Rate Training (MERT) is a method for training the parameters of a log-	223	[')']	['Error Rate Training', 'a', 'a']	[[42, 43]]	[[17, 36], [5, 6], [5, 6]]
223	A phonetic system represents sound segments as 3Phonemic and phonetic representations are given in the International Phonetic Alphabet (IPA). 	224	[]	['A', 'Phonetic Alphabet']	[]	[[0, 1], [117, 134]]
224	word w is defined as the largest connected subgraph that contains w. For each content  9 Other thesauri have been used for WSD, e.g., the German Hallig-Wartburg (see Schmidt \[1988, 1991\])  and the Longman Lexicon of Contemporary English (LLOCE) (Chen and Chang, this volume). 	225	['WSD', 'LLOCE']	['Longman Lexicon of Contemporary English']	[[123, 126], [240, 245]]	[[199, 238]]
225	the Switchboard corpus.1 The standard measure of error used in ASR is word error rate (WER), computed as 100(I + D + S)/R, where I,D and S are the number of inser-	226	['ASR', 'WER']	['error', 'word error rate']	[[63, 66], [87, 90]]	[[49, 54], [70, 85]]
226	verbs, adject ives,  and others. Then a  separate  Keyword In Context  (KWIC) Index  was made for each part of speech.	227	['KWIC']	['Keyword In Context']	[[72, 76]]	[[51, 69]]
227	company was interested in knowledge discovery  approaches applicable to the data aggregated by its  Emergency Control System (ECS) in the form of  field service tickets.	228	['ECS']	['Emergency Control System']	[[126, 129]]	[[100, 124]]
228	Italian - Romanian (IT-RO); ? Portuguese - Romanian (PT-RO); ?	229	[]	['Italian - Romanian', 'Portuguese - Romanian']	[]	[[0, 18], [30, 51]]
229	V (verb) 6946 81.9 85.8 PR (preposition) 5302 60.0 79.0 CONJ (conjunction) 2998 76.1 80.7 ADV (adverb) 2855 72.3 83.3	230	['V', 'PR', 'CONJ']	['verb', 'preposition', 'conjunction', 'adverb']	[[0, 1], [24, 26], [56, 60]]	[[3, 7], [28, 39], [62, 73], [95, 101]]
230	lexicalized Baselines. In Proceedings of the ACL Workshop on Parsing German (PaGe), pages 40?46, Columbus, OH, USA.	231	['ACL', 'PaGe', 'OH', 'USA']	['Parsing German']	[[45, 48], [77, 81], [107, 109], [111, 114]]	[[61, 75]]
231	It consists mainly of four incremental (cas-  caded) processes that work on the blackboard-like  current conceptual structure (CCR). At first sight, 	232	['CCR']	['conceptual structure']	[[127, 130]]	[[105, 125]]
232	when reconcilable with Bias 1. Whenever the sentence or query has a verb phrase (VP) spanning roughly half of it, annotators seem to chunk be-	233	['VP']	['a verb phrase']	[[81, 83]]	[[66, 79]]
233	Abbreviations NE = Named Entity CE = Correlated Entity EP = Entity Profile	234	[]	['Entity', 'Entity']	[]	[[25, 31], [25, 31]]
234	which can handle the non-projective trees present in the Irish data. In each case we report Labelled Attachment Score (LAS) and Unlabelled Attachment Score (UAS). 	235	['LAS', 'UAS']	['Labelled Attachment Score', 'Unlabelled Attachment Score']	[[119, 122], [157, 160]]	[[92, 117], [128, 155]]
235	Table 1: A classification of grammar rules for the HPB model. PR = phrasal rule, HR = hierarchical rule, GR = glue rule.	236	['HPB', 'PR', 'HR', 'GR']	['phrasal', 'rule', 'hierarchical rule', 'glue rule']	[[51, 54], [62, 64], [81, 83], [105, 107]]	[[67, 74], [37, 41], [86, 103], [110, 119]]
236	senses. Semantic role labeling is achieved using maximum entropy (MaxEnt) model based semantic role classification and integer linear	237	['MaxEnt']	['maximum entropy']	[[66, 72]]	[[49, 64]]
237	FS = false start  E = echo  ADD = added information  SELF = talking to oneself 	238	['FS', 'ADD', 'SELF']	['false start', 'E', 'echo', 'added', 'information']	[[0, 2], [28, 31], [53, 57]]	[[5, 16], [18, 19], [22, 26], [34, 39], [40, 51]]
238	tasks or languages.  Amazon?s Mechanical Turk (MTurk) service facilitates inexpensive collection of large amounts of	239	[]	['Mechanical Turk']	[]	[[30, 45]]
239	 iii. Simple_Rank (S-Rank): It is computed  based on Rank(i)=tfi*Len(i), which aims 	240	['S-Rank']	['Simple_Rank', 'Rank']	[[18, 24]]	[[5, 16], [12, 16]]
240	The MRF provides the base frame to  combine various statistical information  with maximum entropy (ME) method. 	241	[')']	['entropy']	[[101, 102]]	[[90, 97]]
241	annotation ? the Penn Chinese Treebank (CTB)(Xia et al, 2000), and the People?s Daily News (PDN) corpus from Beijing University.	242	['CTB', 'PDN']	['?', 'Chinese Treebank', 'People ? s Daily News']	[[40, 43], [92, 95]]	[[11, 12], [22, 38], [-1, 20]]
242	Sangkeun Jung, Cheongjae Lee, Kyungduk Kim, Gary Geunbae Lee Department of Computer Science and Engineering Pohang University of Computer Science and Technology(POSTECH) San 31, Hyoja-Dong, Pohang, 790-784, Korea	243	['POSTECH']	['of Computer Science and', 'Pohang University of Computer Science and Technology', 'Pohang']	[[161, 168]]	[[72, 95], [108, 160], [108, 114]]
243	6. A rule to convert the Hindi word into its  base form (BF). 	244	[')']	[]	[[59, 60]]	[]
244	for acquiring high quality non-expert knowledge from on-demand workforce using Amazon Mechanical Turk (MTurk). We show how 	245	[]	['Mechanical Turk']	[]	[[86, 101]]
245	integral to membrane  membrane  The protein encoded by this gene is a receptor for interleukin 20 (IL20), a cytokine that may be involved in epidermal function.	246	[]	['interleukin 20', 'in']	[]	[[83, 97], [0, 2]]
246	We evaluate the lexicons proposed in Section 3 both intrinsically (by comparing their lexicon entries against General Inquirer (GI) lexicon) and extrinsically (by using them in a phrase polarity anno-	247	['GI']	['in', 'General Inquirer', 'a']	[[128, 130]]	[[34, 36], [110, 126], [5, 6]]
247	out of this phrase. The word with the parent out of  the phrase is called Head of Phrase (HP). The 	248	['HP']	['of', 'of', 'Head of Phrase']	[[90, 92]]	[[4, 6], [4, 6], [74, 88]]
248	 1 Introduction Noun phrase (NP) coreference resolution, the task of determining which NPs in a text or dialogue re-	249	[')']	['phrase', 'a']	[[30, 31]]	[[20, 26], [23, 24]]
249	Generation of Crisp Descriptions Arguably the most fundamental task in the generation of referring expressions (GRE), content determination (CD) requires finding a set of properties that jointly identify the intended referent.	250	['GRE', 'CD']	['of', 'in', 'generation of referring expressions', 'content determination', 'a', 'of']	[[112, 115], [141, 143]]	[[11, 13], [68, 70], [75, 110], [118, 139], [5, 6], [11, 13]]
250	entities presence feature (DIC), numerical entities presence feature (NUM), question specific feature (SPE), and dependency validity feature (DEP). 	251	['DIC', 'NUM', 'SPE', 'DEP']	['entities presence feature', 'numerical entities presence feature', 'question specific feature', 'dependency validity feature']	[[27, 30], [70, 73], [103, 106], [142, 145]]	[[0, 25], [33, 68], [76, 101], [113, 140]]
251	3.1 Semantic Types In the present task, we use a subset of semantic types from the Brandeis Shallow Ontology (BSO), which is a shallow hierarchy of types developed as a part	252	['BSO']	['the', 'a', 'the Brandeis Shallow Ontology', 'is a', 'a']	[[110, 113]]	[[22, 25], [7, 8], [79, 108], [122, 126], [7, 8]]
252	applied to the sentiment analysis problem. Models such as Na??ve Bayes (NB), Maximum Entropy (ME) and Support Vector Machines (SVM) can determine	253	['NB', 'ME', 'SVM']	['to', 'Na ? ? ve Bayes', 'Maximum Entropy', 'Support Vector Machines']	[[72, 74], [94, 96], [127, 130]]	[[8, 10], [-1, 14], [77, 92], [102, 125]]
253	 Rank Group Lexical Features 1 HM HM1 (head of M1) HM2 (head of M2)	254	['1']	['head', 'head']	[[28, 29]]	[[38, 42], [38, 42]]
254	Cross-lingual textual entailment (CLTE) (Mehdad et al., 2010) is an extension of textual entailment (TE) (Dagan and Glickman, 2004).	255	['CLTE', 'TE']	['Cross-lingual textual entailment', 'textual entailment']	[[34, 38], [36, 38]]	[[0, 32], [14, 32]]
255	1977).  The parameters of the IDCLM model are computed using the variational Bayes EM (VB-EM) procedure by maximizing the marginal distribution of the training data that contains a set of n-gram events	256	['IDCLM']	['variational Bayes EM', 'a']	[[30, 35]]	[[65, 85], [13, 14]]
256	 2 Related Work Reference resolution (RR), which is the task of resolving referring expressions (REs) to what they are	257	[')']	['resolution', 'referring expressions']	[[39, 40]]	[[25, 35], [73, 94]]
257	or fictional) world. These discourse ntities,  called reference objects (RefOs), are stored  and processed ina net-like structure, called a 	258	['RefOs']	['reference objects']	[[73, 78]]	[[54, 71]]
258	then X Y =~ Z  then Y X ::~ Z  Permutation Closure of language L (PermL)  PermL = { s \[ s' in L and s is a per- 	259	[]	['Permutation Closure of language L', 's', 'L', 's', 'a']	[]	[[31, 64], [46, 47], [63, 64], [46, 47], [37, 38]]
259	" I. Introduction  SABA (""Semantic Analyser , Backward Ap-  proach"") is an automatic parser of French "	260	[]	['Analyser ,', ')', 'an']	[]	[[33, 43], [65, 66], [27, 29]]
260	Proceedings of  the First International Symposium on Compurers and Chinese  Inpuf/Output Systems, Acadernig Sinico, 983-998  in the FCL (FACOM Composition Language) System, information is punched on paper tape  with a Kanji keyboard.	261	[]	['on', 'Composition Language )', 'on', 'a']	[]	[[35, 37], [-1, 21], [35, 37], [32, 33]]
261	In order to answer this question, we propose a new model called the Recursive Neural Tensor Network (RNTN). The main idea is to use	262	['RNTN']	['a', 'Recursive Neural Tensor Network']	[[101, 105]]	[[12, 13], [68, 99]]
262	In Proceedings of the 19th International Conference on Computational Linguistics (COLING), volume I, pages 267?273.	263	[')']	['on', 'Linguistics']	[[88, 89]]	[[36, 38], [69, 80]]
263	tating full-text passages that describe the functional relationships between bio-entities summarised in a Molecular Interaction Map (MIM). Our corpus	264	['MIM']	['a Molecular Interaction Map']	[[133, 136]]	[[104, 131]]
264	Abstract A number of issues arise when trying to scaleup natural language understanding (NLU) tools designed for relatively simple domains (e.g.,	265	['NLU']	['natural language understanding']	[[89, 92]]	[[57, 87]]
265	distance (EDIT), which is the Levenshtein distance between generated word string and human reference output, and string accuracy (S-A), which is the proportion of times the word string was identical to the	266	['EDIT', 'S-A']	['string', 'string accuracy', 'string']	[[10, 14], [130, 133]]	[[74, 80], [113, 128], [74, 80]]
266	The second column represents three SMT systems, namely: the baseline system adapted to the domain (DA), the same system with a CSLM (DA+CSLM) and the project adapted sys-	267	['SMT', 'DA', 'CSLM']	['domain']	[[35, 38], [99, 101], [127, 131]]	[[91, 97]]
267	(i)(a) If the verb is the last word  of the surface shape of the  sentence (SS), it always be-  longs to the focus.	268	[')']	['i', 'a', 'the', 'the', 'of the', 'shape of the sentence', 'the']	[[2, 3]]	[[1, 2], [4, 5], [10, 13], [10, 13], [37, 43], [-1, 20], [10, 13]]
268	 In Expertise column, C=Computer Scientist, BI=Bioinformatician, B=Biologist, L=Linguist ?	269	[]	['Scientist']	[]	[[32, 41]]
269	As is common practice for continuous features, we choose this pdf to be a Gaussian mixture model (GMM) since any continuous distribution can be approximated with ar-	270	['GMM']	['is', 'a Gaussian mixture model']	[[98, 101]]	[[3, 5], [72, 96]]
270	So, for example, the preposition in addition to (krom?) appears altogether in 309 instances in PDT,  within which there are 44 instances in the function of AltLex (automatically looked up). All 	271	['PDT', 'AltLex']	[]	[[95, 98], [156, 162]]	[]
271	 Finally, we propose using the beam-search decoder to combine multiple discriminative models such as M3N and multiple generative models such as language models (LM) and perform multiple passes of disfluency detection.	272	['M3N', 'LM']	['models', 'models', 'language models']	[[100, 103], [160, 162]]	[[85, 91], [85, 91], [143, 158]]
272	The first system, as its name suggests, is very  simple: using the WSD model, it chooses the  most frequent sense (MFS) of the lemma l with  POS p according to WN (that is, the lowest num-	273	['WSD', 'MFS', 'POS', 'WN']	['is', 'most frequent sense', 'is']	[[67, 70], [115, 118], [141, 144], [160, 162]]	[[40, 42], [94, 113], [40, 42]]
273	 1 Introduction Margin infused relaxed algorithm (MIRA) has been widely adopted for the parameter optimization in	274	[')']	['infused relaxed algorithm']	[[53, 54]]	[[22, 47]]
274	 Our approach differs in important ways from the  use of hidden Markov models (HMMs) for class-  based language modeling (Jelinek et al, 1992).	275	[')']	['Markov models']	[[82, 83]]	[[63, 76]]
275	the semantics of the head noun of the reference  object. A noun phrase (NP) denoting a place  gives rise to a spatial PP.	276	['NP', 'PP']	['noun', 'noun phrase', 'a', 'a']	[[72, 74], [118, 120]]	[[26, 30], [59, 70], [7, 8], [7, 8]]
276	contact(CeNT) motion(MOT)  emoeion(ENO) perception(PER)  possession(POSS) stat ive(STA)  ~eather(WEA) ingestion(ING) 	277	['CeNT', 'MOT', 'ENO', 'PER', 'POSS', 'STA', 'WEA', 'ING']	['contact', 'motion', 'emoeion', 'perception', 'possession', 'stat ive', 'ingestion']	[[8, 12], [21, 24], [35, 38], [51, 54], [68, 72], [83, 86], [97, 100], [112, 115]]	[[0, 7], [14, 20], [27, 34], [40, 50], [57, 67], [74, 82], [102, 111]]
277	tropy modeling. Berger et al (1996) presents an incremental feature selection (IFS) algorithm, which computes the approximate gains	278	['IFS']	['al', 'incremental feature selection']	[[79, 82]]	[[26, 28], [48, 77]]
278	pre-processed ATB (Table 10). Consequently, this particular Arabic MWE identification experiment is similar to joint parsing and named entity recognition (NER) (Finkel and Manning 2009).	279	['ATB', 'MWE', 'NER']	['named entity recognition']	[[14, 17], [67, 70], [155, 158]]	[[129, 153]]
279	ficient. The remainder of the data can be partially addressed with noun phrase (NP) detectors (Abney, 1991; Ramshaw and Marcus, 1995; Mu?noz et	280	['NP']	['noun phrase']	[[80, 82]]	[[67, 78]]
280	Frame abbreviations:  INAN=inanimate NP, ANIM=animate NP, VBZ--inflected  main verb, IS=is, VBG=gerund, PP=prepositional phrase,  TO=to (prep.),	281	['NP', 'VBZ']	['inflected main', 'verb', 'phrase', '( prep']	[[37, 39], [58, 61]]	[[-1, 13], [79, 83], [121, 127], [-1, 5]]
281	2 where AF = adjusted frequency di = relative size of category i	282	[]	['frequency']	[]	[[22, 31]]
282	respective polarities. This new value will be called  Positive Association (PosA). The PosA value is 	283	['PosA']	['Positive Association']	[[76, 80]]	[[54, 74]]
283	production strategies. In Proceedings of the 16th International Conference on Computational Linguistics (COLING?96), pages 249?254.	284	['COLING?96']	['Conference on Computational Linguistics']	[[105, 114]]	[[64, 103]]
284	paring to BL system (N.S.), the average number of alternative translations of each source phrase (T/S) and the average source phrase length in the output (A.L.) -1.80 on average TER.	285	['BL', 'N.S.', 'T/S']	['source phrase', 'source phrase length']	[[10, 12], [21, 25], [98, 101]]	[[83, 96], [119, 139]]
285	and Johnson, 2011), particularly from the DARPA EARS (Effective, Affordable, Reusable Speech-toText) MDE (MetaData Extraction) (DARPA Information Processing Technology Office, 2003) pro-	286	['DARPA', 'EARS', 'MDE']	['MetaData Extraction']	[[42, 47], [48, 52], [101, 104]]	[[106, 125]]
286	lion words. From TIPSTER,  we used the Associ-  ated Press (AP), Wall Street Journal (WSJ), and  San Jose Mercury News (SJM) data, yielding 123, 	287	['AP', 'WSJ', 'SJM']	['Associ- ated Press', 'Wall Street Journal', 'San Jose Mercury News']	[[60, 62], [86, 89], [120, 123]]	[[-1, 17], [65, 84], [97, 118]]
287	Chinese sentence into a sequence of words. This is  the task of Chinese word segmentation (CWS), an  important and challenging task in Chinese NLP.	288	['CWS', 'NLP']	['Chinese', 'a', 'Chinese word segmentation', 'an', 'in Chinese']	[[91, 94], [143, 146]]	[[0, 7], [22, 23], [64, 89], [97, 99], [132, 142]]
288	Video in sentences out.  In Association for Uncertainty in Artificial Intelligence (UAI). 	289	['UAI']	['in', 'In', 'for Uncertainty in Artificial Intelligence']	[[84, 87]]	[[6, 8], [25, 27], [40, 82]]
289	BOEING CO(BA) OTC  UTL USA  UTL CORP(UTLC)  BOEING'S ARGOSYSTEMS SUBSIDIARY TO MAKE TENDER OFFER FOR ALL UTL CORE SHARES 	290	['CO', 'BA', 'OTC', 'UTLC']	['BOEING', 'UTL USA UTL CORP', 'BOEING', 'UTL']	[[7, 9], [10, 12], [14, 17], [37, 41]]	[[0, 6], [-1, 15], [0, 6], [19, 22]]
290	 For comparison we re-implemented the probabilistic Visual Objects Algorithm (VOA) of Mitchell et al(2013).	291	[')']	['Objects Algorithm']	[[80, 81]]	[[58, 75]]
291	 2 Platform Architecture  The Application Generation Platform (AGP), created during the European project GEMINI, is an 	292	[')', ',']	['Platform', 'Generation Platform']	[[65, 66], [66, 67]]	[[2, 10], [41, 60]]
292	The query-based selection model utilizes Support Vector Regression (SVR) models to predict the mean average precision (MAP) of each query from the ambiguity measures, and to choose an ap-	293	[')']	['Vector Regression', 'to', 'average precision', 'to', 'an']	[[71, 72]]	[[49, 66], [52, 54], [100, 117], [52, 54], [97, 99]]
293	will describe our method of automatically creating a training set based on the click-through links and how we build an SVM (Support Vector Machine) classifier with the integration of enriched informa-	294	['SVM']	['a', 'Support Vector Machine']	[[119, 122]]	[[28, 29], [124, 146]]
294	Mophological processing, syntactic parsing and  other useflfl tools have been proposed in the field  of natural language processing(NLP). Many 	295	['NLP']	['processing', 'in', 'natural language processing']	[[132, 135]]	[[13, 23], [20, 22], [104, 131]]
295	Computational Linguistics Volume 23, Number 2  1993c). FUF (Functional Unification Formalism) is a programming language based on  functional unification (Kay 1979).	296	['FUF']	['Functional Unification Formalism', 'is a', 'on']	[[55, 58]]	[[60, 92], [94, 98], [9, 11]]
296	translation with overall understanding?.  Rhetorical structure theory (RST) (Mann and  Thompson, 1988) provides us with a good per-	297	['RST']	['Rhetorical structure theory', 'a']	[[71, 74]]	[[42, 69], [2, 3]]
297	Sentences from TST2-MUC4-0048 Sl : SALVADORAN PRESIDENT-ELECT ALFREDO CRISTIAII CONDEMNED THE TERRORIST KILLING OF ATTORNE Y GENERAL ROBERTO GARCIA ALVARADO AND ACCUSED THE FARABUNDO MARTI NATIONAL LIBERATION FRONT (FMLN ) OF THE CRIME .	298	['Sl', 'FMLN']	['FARABUNDO MARTI NATIONAL LIBERATION FRONT']	[[30, 32], [216, 220]]	[[173, 214]]
298	Finally, the intention  translates into a call to UC's expression mechanism,  UCExpress (UCexpressl in the trace), which eventu-  ally calls UCGen to produce the answer.	299	[]	['the', 'UC', 'UCexpressl in the', 'the']	[]	[[9, 12], [50, 52], [89, 106], [9, 12]]
299	For 1http://maltparser.org/ English?Chinese (EN?ZH) word alignment, we observe that 75.62% of the consecutive Chinese	300	[]	['English', '? Chinese', '?']	[]	[[28, 35], [-1, 8], [35, 36]]
300	28  Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 39?47, October 25, 2014, Doha, Qatar.	301	['EMNLP', 'ANLP']	['Arabic Natural Langauge Processing']	[[23, 28], [82, 86]]	[[46, 80]]
301	and  Communications Industry Association (CCIA) filed differing recommendations  with the OMB on Federal automatic data processing (ADP) procurement. CBEW 	302	['CCIA', 'OMB', 'ADP']	['Communications Industry Association', 'on Federal automatic data processing']	[[42, 46], [90, 93], [132, 135]]	[[5, 40], [94, 130]]
302	for many NLP applications including machine translation. In fact, Google Translate (GT)3 translates Examples (1) and (3) as ?	303	['NLP', 'GT']	['Translate']	[[9, 12], [84, 86]]	[[73, 82]]
303	Economics neighborhood f bank  bank  Subject Code EC = Economics  have it person out 	304	['EC']	['Economics', 'Economics have']	[[50, 52]]	[[0, 9], [-1, 13]]
304	" The meaning of complex phrases is represented as  a composed LCS (CLCS). This is constructed ""com- "	305	[]	['LCS']	[]	[[61, 64]]
305	which has been developed within the projects K1T-NASEV and its  successor KIT-FAST 2 will be described (for details see \[Hanen-  1 LP = Linear Precedence; FCR = Feature Co-oecmenee R striction  KIT-FAST (FAST = Functor-Argument Structure for Translation; KIT = 	306	['K1T-NASEV', 'KIT-FAST', 'LP', 'FCR', 'KIT']	['for', 'Linear Precedence', 'Feature Co-oecmenee R', 'FAST', 'Functor-Argument Structure for Translation']	[[45, 54], [74, 82], [132, 134], [156, 159], [74, 77]]	[[104, 107], [137, 154], [162, 183], [78, 82], [212, 254]]
306	 2 Universal Networking Language Universal Networking Language (UNL) is an interlingua that represents a sentence in a language inde-	307	[')']	['Networking Language', 'Networking Language', 'an', 'a', 'in a']	[[66, 67]]	[[12, 31], [12, 31], [24, 26], [9, 10], [113, 117]]
307	 Ckakraborty, Tanmoy, 2010, Identification of NounNoun (N-N) Collocations as Multi-Word Expressions  in Bengali Corpus.	308	['N-N']	['NounNoun']	[[55, 58]]	[[45, 53]]
308	4.2 Dataset and preprocessing To evaluate the proposed approach, we use SemEval-2013 datasets: TW (tweets obtained by merging learn and development data) and SMS, in	309	['SemEval-2013', 'TW', 'SMS']	['tweets']	[[72, 84], [95, 97], [158, 161]]	[[99, 105]]
309	 The experiments were performed using the  Wall Street Journal (WSJ) corpus of the Uni-  versity of Pennsylvania (Marcus et al, 1993) 	310	[')']	['Street Journal', 'et']	[[66, 67]]	[[47, 61], [51, 53]]
310	INIT MED FIN TOTAL 201 (87.8%) 13 (5.7%) 15 (6.5%) 229 Table 1: Distribution of the Position (POS) of Discourse Adverbials	311	['POS']	['Distribution of the Position', 'of']	[[94, 97]]	[[64, 92], [77, 79]]
311	rada@cs.unt.edu Abstract Amazon Mechanical Turk (MTurk) is a marketplace for so-called ?	312	[]	['Mechanical Turk', 'a']	[]	[[32, 47], [1, 2]]
312	tions and so on.  3.2 The Greedy Prepend Algorithm (GPA) To learn a decision list from a given set of training	313	['GPA']	['Greedy Prepend Algorithm', 'a', 'a']	[[52, 55]]	[[26, 50], [6, 7], [6, 7]]
313	"legislatures, councils, ""other government bodies , I 1  and the private sector  should withhold action implementing major proposals for EFTS until the  National Commission on Electronic Fund transfers (NCEFT) has completed its  studies."	314	['EFTS', 'NCEFT']	['National Commission on Electronic Fund transfers']	[[136, 140], [202, 207]]	[[152, 200]]
314	 2. Na?ve Bayesian approach with full vocabulary (NBF). It	315	[')']	['? ve Bayesian']	[[52, 53]]	[[-1, 12]]
315	correction. ? P3E3N4S2, F W I Controlled Automotive Service Language (CASL) (Means and Godden 1996; Means, Chapman, and Liu 2000) is a controlled language for writing service manuals and bul-	316	['P3E3N4S2', 'CASL']	['Controlled Automotive Service Language', 'a']	[[14, 22], [70, 74]]	[[30, 68], [61, 62]]
316	extend Eigenwords, spectral monolingual word embeddings based on canonical correlation analysis (CCA), to crosslingual settings with sentence-alignment.	317	['CCA']	['on canonical correlation analysis']	[[97, 100]]	[[62, 95]]
317	The initial translation outputs from Google Translate (GT) and the results of the targeted paraphrasing translation process (TP) were evaluated according to widely used critera of fluency and adequacy.	318	['GT', 'TP']	['translation', 'Translate', 'translation process']	[[55, 57], [125, 127]]	[[12, 23], [44, 53], [104, 123]]
318	"simultaneous (SML) with another proposition: ""Fred washed the car  while John chased Mary"", Figure 50 A sequenttal rn iering of proposi-  t ions is also found, characterized by a sequence (SEQ) relation. The "	319	['SML', 'SEQ']	['simultaneous']	[[14, 17], [189, 192]]	[[0, 12]]
319	wards Task 2.  4.1 Wikipedia system (WIKI) In the WIKI data a sentence is marked as uncertain	320	['WIKI']	['Wikipedia system', 'a']	[[37, 41]]	[[19, 35], [1, 2]]
320	 4. Coreference (COR) As mentioned in our discussion of transitional phrases, a strong argument	321	[')']	[]	[[19, 20]]	[]
321	Bayesian Networks (Samuelsson, 1993), Neural  Networks (Marques and Lopes, 1996) and  Conditional Random Fields (CRF) (Lafferty et  al.,	322	['CRF']	['and', 'and Conditional Random Fields']	[[113, 116]]	[[64, 67], [-1, 28]]
322	Evaluation Metrics: We evaluate the performance of question retrieval using the following metrics: Mean Average Precision (MAP) and Precision@N (P@N).	323	['MAP']	['Mean Average Precision', 'Precision @ N', 'P @ N']	[[123, 126]]	[[99, 121], [-1, 12], [-1, 4]]
323	quen cies Figure 6: Distribution of Ratio of Frequencies(RF) values over the nouns in the corpus	324	['RF']	['of Ratio of Frequencies']	[[57, 59]]	[[33, 56]]
324	system utterances with respect o dialog context.  Utterances can be either appropriate (AP), inappro-  priate (IP), or ambiguous (AM).	325	['AP', 'IP', 'AM']	['o', 'appropriate', 'inappro- priate', 'ambiguous']	[[88, 90], [111, 113], [130, 132]]	[[31, 32], [75, 86], [-1, 14], [119, 128]]
325	 2.2 Tree substitution grammars Tree substitution grammars (TSGs) allow for complementary analysis.	326	[')']	['substitution grammars', 'substitution grammars']	[[63, 64]]	[[9, 30], [9, 30]]
326	 2 Background and Related Work Amazon?s Mechanical Turk (MTurk) is an online marketplace for work that gives employers	327	[]	['Turk', 'an']	[]	[[50, 54], [13, 15]]
327	the points plus 10% of the surrounding area. For this, The Generic Map Tools (GMT)10 were used, in this case via HTTP.11	328	['.', 'GMT']	['Generic Map Tools']	[[43, 44], [78, 81]]	[[59, 76]]
328	entry description to a lexeme. A part-of-speech of the lexeme is set to a common noun (NN ) where the minimum word probability of NN is assigned	329	['NN']	['noun']	[[87, 89]]	[[81, 85]]
329	ary, we assign a default value 3.0.  3.2 Named Entities (NE)  Named Entities are important semantic information 	330	['NE']	['a', 'Named Entities', 'Named Entities']	[[57, 59]]	[[0, 1], [41, 55], [41, 55]]
330	"2.1 Processing definitions  Our algorithms are used in an overall system  called ""onomasiological search system"" (OSS),  whose aim is to allow the user to find terms by "	331	['OSS']	['system', 'onomasiological search system', 'is']	[[114, 117]]	[[66, 72], [82, 111], [131, 133]]
331	In MT Summit XIII: the Thirteenth Machine Translation Summit [organized by the] AsiaPacific Association for Machine Translation (AAMT), pages 513-520.	332	['MT']	['Machine Translation', 'AsiaPacific Association for Machine Translation']	[[3, 5]]	[[34, 53], [80, 127]]
332	guished from mentions in text or mentions in other sources. The Terence Annotation Format (TAF) provides a unified framework to annotate events, par-	333	['TAF']	['Terence Annotation Format', 'a']	[[91, 94]]	[[64, 89], [77, 78]]
333	Subjacency sub-  sumes, as well as other principles, Ross's lO  Complex Noun Phrase Constraint (CNPC), which  prohibits movements out o f~-NpNPS ~ structures, 	334	['CNPC']	['as', 'as', 'Noun Phrase Constraint', 'o']	[[96, 100]]	[[24, 26], [24, 26], [72, 94], [35, 36]]
334	We report both the aggregate curves precision/recall curves and Precision@N (P@N) in our experiments.	335	[]	['@ N', 'P @ N']	[]	[[-1, 2], [-1, 4]]
335	On the source-language side of the  corpus we will automatically generate lists of  frequent multiword expressions (MWEs) and  grammatical constructions using the methodology 	336	['MWEs']	['multiword expressions']	[[116, 120]]	[[93, 114]]
336	al. were entered into Graph Spider using the  metapattern language (MPL) designed by the  Graph Spider authors.	337	['MPL']	['metapattern language']	[[68, 71]]	[[46, 66]]
337	In interaction with the user, the system should play the role of an Information Search Assistant (ISA). 	338	[')']	['In', 'Search Assistant']	[[101, 102]]	[[0, 2], [80, 96]]
338	ducted experiments on the same dataset for sentence identification using interaction patterns generated by another pattern generating algorithm (PGA) (Huang et al.,	339	['PGA']	['pattern generating']	[[145, 148]]	[[115, 133]]
339	{zhaosq,xlan,tliu,lisheng}@ir.hit.edu.cn Abstract Paraphrase generation (PG) is important in plenty of NLP applications.	340	['PG', 'NLP']	['Paraphrase generation']	[[73, 75], [103, 106]]	[[50, 71]]
340	1. Introduction Word segmentation is an important task in natural language processing (NLP) for languages without word delimiters (e.g., Chinese).	341	['NLP']	['an', 'in natural language processing']	[[87, 90]]	[[37, 39], [55, 85]]
341	of derivations. Each such derivation is realized in  PROVERB by a proof communicative act (PEA),  following the viewpoint hat language utterances are 	342	['PROVERB', 'PEA']	['a proof communicative act']	[[53, 60], [91, 94]]	[[64, 89]]
342	 Introduction The Penn Chinese Treebank (CTB) is an ongoing project, with its objective being to	343	[')']	['Treebank', 'an']	[[43, 44]]	[[30, 38], [35, 37]]
343	News stories typically describe real-world events.  Topic detection and tracking (TDT) aims to detect stories that discuss identical or directly related	344	['TDT']	['Topic detection and tracking']	[[82, 85]]	[[52, 80]]
344	For Arabic, morphological segmentation is performed by MADA 3.2 (Habash et al, 2009), using the Penn Arabic Treebank (PATB) segmentation scheme as recommended by El Kholy and Habash	345	['MADA', 'PATB']	['Arabic', 'Penn Arabic Treebank']	[[55, 59], [118, 122]]	[[4, 10], [96, 116]]
345	In ear l ier  papers devoted to interpersonal  interaction iFrank,1981; Levinson,1981\] much atten-  tion is paid to studying the role of speecb act (SA)  i n  d ia logue  s t ructure .	346	['SA']	['speecb act', 's']	[[150, 152]]	[[138, 148], [19, 20]]
346	we can use these annotations to measure an average precision across the precision-recall curve, and an aggregate mean average precision (MAP) across all relations.	347	['MAP']	['an average precision', 'an aggregate mean average precision']	[[137, 140]]	[[40, 60], [100, 135]]
347	 ? BLEU (bilingual evalutation understudy) score: This score measures the precision of unigrams, bigrams, trigrams, and 4-grams with respect to a	348	[]	['evalutation understudy )']	[]	[[-1, 23]]
348	2007 task into four sub-tasks: (1) target word frame disambiguation (TWFD); (2) FE boundary detection (FEBD); (3) GF label classification (GFLC) and (4) FE label classification (FELC).	349	['TWFD', 'FEBD']	['target word frame disambiguation', 'FE boundary detection', 'GF label classification', 'label classification']	[[69, 73], [103, 107]]	[[35, 67], [80, 101], [114, 137], [117, 137]]
349	 Table 2 shows part of a decision list for the target noun chicken that was learned from a subset of the BNC (British National Corpus) [17]. Note that the	350	['BNC']	['a', 'a', 'British National Corpus']	[[104, 107]]	[[1, 2], [1, 2], [109, 132]]
350	The table shows percentage of phrases that we have to retain. ES=Spanish, EN=English, FR=French, CS=Czech, DE=German. 	351	[]	[]	[]	[]
351	josefr@coli.uni-sb.de Abstract Active Learning (AL) has been proposed as a technique to reduce the amount of annotated	352	['AL']	['Active Learning', 'a']	[[48, 50]]	[[31, 46], [27, 28]]
352	 2.1 Weighted regular tree grammars A weighted regular tree grammar (WRTG) is a 4tuple G = (S,L,R, s`), where S and L are two	353	[')']	['regular tree', 'regular tree grammar', 'a', 's']	[[72, 73]]	[[13, 25], [13, 33], [18, 19], [33, 34]]
353	(i) identify the scope of coordinations regardless of phrase types, and (ii) detect noun phrase (NP) coordinations and identify their scopes.	354	['NP']	['phrase', 'noun phrase']	[[97, 99]]	[[54, 60], [84, 95]]
354	 1 Introduction Among many natural language processing (NLP) tasks, such as text classification, question answer-	355	[')']	['language processing']	[[58, 59]]	[[34, 53]]
355	(01) AT (Singular Article)  (03) BED (were)  (05) BEG (being)  (07) BER (are, 're) 	356	['AT', 'BED', 'BEG', 'BER']	['being']	[[5, 7], [33, 36], [50, 53], [68, 71]]	[[55, 60]]
356	In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI?77), page 67=76. 	357	['IJCAI?77']	['In', 'International Joint Conference on Artificial Intelligence']	[[81, 89]]	[[0, 2], [22, 79]]
357	In Proc. of the Human Language Technologies (HLT): The Annual Conf.	358	['HLT']	['Human Language Technologies']	[[45, 48]]	[[16, 43]]
358	We experimentally evaluated the test collection for single document summarization contained in the RST Discourse Treebank (RST-DTB) (Carlson et al.,	359	[]	['RST Discourse Treebank']	[]	[[99, 121]]
359	implementation of SVM.  Lexical Classifier (LC): This method calculates the number of positive words and negative words	360	['SVM', 'LC']	['Lexical Classifier']	[[18, 21], [44, 46]]	[[24, 42]]
360	 (Undecided) Meronym(MER)  (a) IF x=ANT 	361	[')']	[]	[[10, 11]]	[]
361	organizations in knowledge mining approaches to  master this information for quality assurance or  Customer Relationship Management (CRM) purposes.	362	['CRM']	['Customer Relationship Management']	[[133, 136]]	[[99, 131]]
362	12 Interac Figure 2: Upper chart: Turn-wise Interaction Quality (IQ) annotation from 3 raters. The final label is the median of	363	['IQ']	['Interaction Quality']	[[65, 67]]	[[44, 63]]
363	We annotate the relation node in the path with the exact relation word (as a lexical constraint) and the POS (postag constraint). We create a re-	364	['POS']	['in', 'a', 'constraint', 'postag constraint', 'a']	[[105, 108]]	[[30, 32], [3, 4], [85, 95], [110, 127], [3, 4]]
364	(#classes) with respect o each part of speech.  Table 1 Outline of Bunruigoihy3 (BGH)  POS noun I verb adj other total 	365	['BGH', 'POS']	['Bunruigoihy3']	[[81, 84], [87, 90]]	[[67, 79]]
365	 Conditional Random Field  A conditional random field (CRF)[5] can be seen  as an undirected graph model in which the nodes 	366	['CRF']	['conditional random field', 'an']	[[54, 57]]	[[28, 52], [13, 15]]
366	VIOLATED EXPECTATION (Ho) NONVOLITIONAL-RESULT (M&T) EXPLANATION (Ho) ( CAUSAL  ADDITIVE ) - RESULT (A&L) ( SEMANTIC  PRAGMATIC ) - EXPLANATION (A&L)	367	['Ho']	['M', 'T', 'EXPLANATION', 'CAUSAL \x04', '-', '(', '( SEMANTIC', ')', 'EXPLANATION', 'A']	[[22, 24]]	[[48, 49], [5, 6], [53, 64], [72, 80], [39, 40], [21, 22], [107, 117], [24, 25], [53, 64], [4, 5]]
367	 5 Conclusion Our approach is akin to so-called semantic role labelling (SRL) approaches [CM05] and to several rewriting approaches developed to modify parsing output in RTE systems [Ass07].	368	['RTE']	['role labelling', 'in']	[[169, 172]]	[[56, 70], [31, 33]]
368	   (5) Flattened CPT (FCPT): the CPT with the  single in and out arcs of non-terminal nodes (ex-	369	[')']	['CPT', 'CPT']	[[2, 3]]	[[14, 17], [14, 17]]
369	two requirements. Since it has to be transformed  into context?free grammar (CFG) for recognition,  features must have a finite number of values, as 	370	['CFG']	['context', 'free grammar', 'a']	[[77, 80]]	[[55, 62], [63, 75], [28, 29]]
370	capture various relationships related to the predicate, we assign function label ? ADT (adjunct)? for	371	['ADT']	['adjunct']	[[83, 86]]	[[88, 95]]
371	SN  where CN = common oun  PN = proper name  SN = Sa-inflection oun (nominal verb) 	372	['SN', 'CN', 'PN']	['common', 'oun', 'oun']	[[0, 2], [10, 12], [27, 29]]	[[15, 21], [22, 25], [22, 25]]
372	 They solve this by formulating the problem as a quadratic assignment problem (QAP). But, even	373	['QAP']	['problem', 'a quadratic assignment problem']	[[78, 81]]	[[35, 42], [46, 76]]
373	on its n?1 previous tokens, i.e. we directly model the following conditional probability (in practice, we choose n = 3, Tri-gram (TRI) ): p(w	374	['TRI']	['Tri-gram']	[[130, 133]]	[[120, 128]]
374	on adjunction (Joshi, 1987):  ? Null adjunction (NA): disallow any adjunc-  tion on the given node.	375	['NA']	['on adjunction', 'Null adjunction', 'tion on']	[[49, 51]]	[[0, 13], [32, 47], [76, 83]]
375	It takes an examplebased approach to recognize IV words and follows description length gain (DLG) to infer OOV words in terms of their text compression effect.	376	['IV', 'DLG']	['description', 'length gain', 'in']	[[47, 49], [93, 96]]	[[68, 79], [80, 91], [89, 91]]
376	8. Strong forms of pronouns not preceded by a preposition (unless they carry IC) t Table 1: Annotation guidelines; IC = Intonation Center. 	377	['IC']	['a', 't', 'Intonation Center']	[[77, 79]]	[[44, 45], [4, 5], [120, 137]]
377	 1 Introduction Topical Text Categorization (TC), the task of classifying documents by pre-defined topics, is most	378	[')']	['Text', 'Categorization']	[[46, 47]]	[[23, 27], [28, 42]]
378	As an example, the following arrow property says that within an interrogative phrase (Pint), an interrogative chunk (IntC) with an interrogative pronoun inside (pint) ar-	379	['Pint', 'IntC']	['interrogative phrase', 'interrogative', 'interrogative']	[[86, 90], [117, 121]]	[[64, 84], [64, 77], [64, 77]]
379	Controlled English at Douglas SMART Controlled English ASD Simplified Technical English (ASD-STE) AECMA Simplified English (AECMA-SE)	380	['SMART']	['English', 'English ASD Simplified Technical English', 'AECMA Simplified English']	[[30, 35]]	[[11, 18], [47, 87], [98, 122]]
380	16: end while 17: return builtPPs 3.3 Extended GNPPA (E-GNPPA) The GNPPA described in section 3.1 assumes that	381	[]	['Extended GNPPA', 'GNPPA']	[]	[[38, 52], [47, 52]]
381	  3.3 Optimality Theory  Optimality Theory (OT) is a theory of language  and grammar, developed by Alan Prince and Paul 	382	[')']	['Theory', 'Theory', 'a']	[[44, 45]]	[[15, 21], [15, 21], [9, 10]]
382	1001   Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 844?853, October 25-29, 2014, Doha, Qatar.	383	['EMNLP']	['Empirical Methods in Natural Language Processing']	[[95, 100]]	[[45, 93]]
383	2 tMi The two parameter classes for generating modifying nonterminals that are children of base NPs (NPB nodes), PM,NPB and PMw,NPB, have the following back-off structures. 	384	['NPB', 'PM']	[]	[[101, 104], [113, 115]]	[]
384	being developed as an Apache incubator project.  UIMA?s Common Analysis System (CAS) is used to describe typed objects (annotations) associated	385	['UIMA?', 'CAS']	['an', 's Common Analysis System', 'is']	[[49, 54], [80, 83]]	[[19, 21], [54, 78], [69, 71]]
385	Sane: ..PERJANTAINA (pltkanl iper jantalna)  PER3ANTAI FRIDAY Noun $8 Eaa  Sane: PITK&KSI.. (p i tk ika iper Janta iks i )   PITK& LI3NG Ad ject ive  $8 Trane l  	386	['PITK&KSI..']	['p']	[[81, 91]]	[[21, 22]]
386	115  Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 566?576, October 25-29, 2014, Doha, Qatar.	387	['EMNLP']	['Empirical Methods in Natural Language Processing']	[[93, 98]]	[[43, 91]]
387	831 . . . demonstrated that HOIL-1L interacting protein (HOIP), a ubiquitin ligase that can catalyze the assembly of linear polyubiquitin chains, is recruited to DC40 in a TRAF2-dependent manner following engagement of CD40 . . .	388	[')']	['interacting protein', 'in']	[[61, 62]]	[[36, 55], [36, 38]]
388	tasks. While having the same model structure as Hidden Markov Models (HMMs), CRFs are trained discriminatively and can use large numbers of corre-	389	['HMMs', 'CRFs']	['Hidden Markov Models']	[[70, 74], [77, 81]]	[[48, 68]]
389	derstanding our approach.  2.1.1 The Conversat ional  Roles Model  (COR)   In the field of information retrieval (IR) the interactive 	390	['COR', 'IR']	['Conversat ional Roles Model', 'information retrieval']	[[68, 71], [114, 116]]	[[-1, 26], [91, 112]]
390	evt EVENT lfr LIVING THING sub SUBSTANCE fod FOOD lme LINEAR MEASURE tme TIME Table 1: The 39 CoreLex basic types (BTs) and their WordNet anchor nodes Basic type WordNet anchor Examples	391	['lme', 'CoreLex', 'BTs']	['basic types', 'type']	[[50, 53], [94, 101], [115, 118]]	[[102, 113], [108, 112]]
391	The first observation is that the task is quite difficult as evidenced by extremely poor performance  of the bag of words approach (BOW). The correct 	392	['BOW']	['words approach']	[[132, 135]]	[[116, 130]]
392	Table 3 describes the used data sets.  Assault Weapons (AW) 4	393	['AW']	['Assault Weapons']	[[56, 58]]	[[39, 54]]
393	 Definition 1 A character string ABC is called an overlap ambiguity string (OAS) if it can be segmented into two words either as AB/C or A/BC (not both), depending on context.	394	['A']	['string', 'ambiguity string', 'it']	[[13, 14]]	[[25, 31], [57, 73], [5, 7]]
394	 Irish students do not receive any instruction in  Modern Foreign Languages (MFL) up until this  point (Irish is not considered a MFL).	395	[')']	['Foreign Languages', 'a']	[[79, 80]]	[[57, 74], [30, 31]]
395	resulting grammar. We cast the minimization as an integer linear program (ILP). Let V be the set of	396	['ILP']	['integer linear program']	[[74, 77]]	[[50, 72]]
396	L J  = lea:-ncd j o u r n a l s   PJ - 1 journals  NR = newt;pc?pcr reportasc  F = fictlon 	397	[]	['n a l']	[]	[[24, 29]]
397	icoglu and Bergler, 2009). The second group uses a  machine learning (ML)-based approach which exploits various specific features and learning algo-	398	['ML']	['a machine learning', 'learning']	[[70, 72]]	[[-1, 17], [60, 68]]
398	1 The  SCAN System  SCAN was developed for the TREC-96 SDR task,  a known item information retrieval (IR) task from  approximately 47hours of the NIST/DARPA HUB4 	399	['SDR', 'IR']	['for', 'a', 'information retrieval']	[[55, 58], [102, 104]]	[[39, 42], [26, 27], [79, 100]]
399	Department of Linguistics, ? Center for the Preservation of Ancient Religious Texts (CPART) Brigham Young University	400	['CPART']	['of', 'Center for the Preservation of Ancient Religious Texts']	[[85, 90]]	[[11, 13], [29, 83]]
400	145  Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1092?1103, October 25-29, 2014, Doha, Qatar.	401	['EMNLP']	['Empirical Methods in Natural Language Processing']	[[93, 98]]	[[43, 91]]
401	Specifically, we investigate dialectal language in publicly available Twitter data, focusing on AfricanAmerican English (AAE), a dialect of Standard American English (SAE) spoken by millions of peo-	402	['AAE', 'SAE']	['AfricanAmerican', 'English', 'a', 'Standard American English']	[[121, 124], [167, 170]]	[[96, 111], [112, 119], [8, 9], [140, 165]]
402	? ?  Table 4: Results for the best baseline (B5) and the learning to rank method (LTR), using all entity pairs in the dataset, including those without any relevant sentences.	403	['B5', 'LTR']	['baseline', 'learning', 'to rank', 'in']	[[45, 47], [82, 85]]	[[35, 43], [57, 65], [66, 73], [40, 42]]
403	active (ACT) and passive (PASS) 3. causative (CAUS) 4.	404	['ACT', 'PASS', 'CAUS']	['active', 'passive', 'causative']	[[8, 11], [26, 30], [46, 50]]	[[0, 6], [17, 24], [35, 44]]
404	problems. Informally, a CRF bears resemblance to a Hidden Markov Model (HMM) in which, for each input position in a sequence, there is an observed	405	['CRF', 'HMM']	['a', 'a Hidden Markov Model', 'a']	[[24, 27], [72, 75]]	[[16, 17], [49, 70], [16, 17]]
405	Gambling neighborhood f bank  bank  Subject Code GB = Gambling  person use money piece 	406	['GB']	['Gambling', 'Gambling']	[[49, 51]]	[[0, 8], [0, 8]]
406	He poured wine from the barrel into the bottle The semantic description of (20) appeals to an intermediate locus IME(LOC), which is not specified here.	407	['IME', 'LOC']	['locus']	[[113, 116], [117, 120]]	[[107, 112]]
407	UC 3 NLP, 1 BioNLP ML (Weka SVM) Table 2: Participation. UU = UofU, UZ = UZH, CU=ConcordU, UT = UTurku, UZ = UZH, US =	408	['UC', 'NLP', 'BioNLP', 'ML', 'SVM', 'UU', 'UZ', 'UT', 'US']	['UofU', 'UZH', 'UTurku']	[[0, 2], [5, 8], [12, 18], [19, 21], [28, 31], [57, 59], [68, 70], [91, 93], [114, 116]]	[[62, 66], [73, 76], [96, 102]]
408	ratio of the number of completely corrected generated MIUs over the number of all MIUs, and character accuracy (Ch-Acc), but the sentence accuracy (S-Acc) will also be reported in evaluation	409	['Ch-Acc', 'S-Acc']	['character accuracy', 'sentence accuracy']	[[112, 118], [148, 153]]	[[92, 110], [129, 146]]
409	They are Na?ve  Bayes (NB), Support Vector Machine (SVM),  Maximum Entropy (MaxEnt) (Kamal Nigam et al  1999) and standard chain CRFs (Fei et al 2003).	410	['NB', 'SVM)']	['Na ? ve Bayes', 'Vector Machine', 'Entropy']	[[23, 25], [52, 56]]	[[-1, 12], [36, 50], [67, 74]]
410	The similarity of decisions can be evaluated by calculating the proportion of identical decisions (PID)when comparing the test results with those of the gold stan-	411	[')']	['decisions', 'decisions']	[[102, 103]]	[[18, 27], [18, 27]]
411	 ? HybFSum (Hybrid Flat Summarizer): To investigate the performance of hierarchical topic	412	['(']	['Flat Summarizer )']	[[10, 11]]	[[-1, 16]]
412	been proposed in \[Uszkoreit 87\]: p.145 in his German  grammar. It makes the adverbial phrase (AdvP) a sister  node of the verb and its arguments: 	413	['AdvP']	['adverbial phrase', 'a', 'verb']	[[96, 100]]	[[78, 94], [52, 53], [80, 84]]
413	(Zhao et al, 2014), The Meaning Factory (Bjerva et al, 2014), UNAL-NLP (Jimenez et al, 2014), and Illinois-LH (Lai and Hockenmaier, 2014). 	414	['UNAL-NLP']	[]	[[62, 70]]	[]
414	sentence, Multiple Linear Regression is used to  build a quantitative model relating the content  tags of the source language (SL) sentence to the  response, which is assumed to be the sum of the 	415	['SL']	['a', 'source language']	[[127, 129]]	[[23, 24], [110, 125]]
415	Commentary We distinguish three types of events in the domain: identification (ID) events trigger the system to name the street the car is on, turn events fire	416	['ID']	['identification', 'on']	[[79, 81]]	[[63, 77], [75, 77]]
416	For biomedical terms other than genes/gene products, the Unified Medical Language System (UMLS) meta-thesaurus (Lindberg et al, 1993) is a large	417	['UMLS']	['Unified Medical Language System', 'al', 'a']	[[90, 94]]	[[57, 88], [12, 14], [12, 13]]
417	snippets with a frequency higher than three. Then we calculate the inverse sentence frequency (ISF) for these phrases using the entire ICSI meeting corpus.	418	['ISF', 'ICSI']	['a frequency', 'inverse sentence frequency']	[[95, 98], [135, 139]]	[[14, 25], [67, 93]]
418	 1 Introduction In recognizing textual entailment (RTE), automated systems assess whether a human reader	419	[')']	['entailment', 'a']	[[53, 54]]	[[38, 48], [35, 36]]
419	A decade ago, students interested in natural language processing arrived at universities having been exposed to the idea of machine translation (MT) primarily through science fiction.	420	['MT']	['in', 'at', 'machine translation']	[[145, 147]]	[[23, 25], [38, 40], [124, 143]]
420	man annotators identified in the texts. TP (true positives) is |A?G|, FP (false positives) is |A\G|, FN (false negatives) is |G\A|, and precision (P ),	421	['TP', 'FP', 'FN']	['true', 'positives', 'false positives', 'is', 'false negatives']	[[40, 42], [70, 72], [101, 103]]	[[44, 48], [49, 58], [74, 89], [60, 62], [105, 120]]
421	We report results for the ATAS versions (ATAS-TC, ATAS-CRF) and for the baselines (Z-CRF, C-value, FRTC) as well as for using supervised (S-SEL) and unsupervised feature selection (U-SEL) in system setting (S) and gold boundary setting (G).	422	['ATAS', 'Z-CRF', 'FRTC', 'S-SEL', 'U-SEL']	['supervised', 'unsupervised feature selection']	[[26, 30], [83, 88], [99, 103], [138, 143], [181, 186]]	[[126, 136], [149, 179]]
422	amjbara@umich.edu Abstract The ACL Anthology Network (AAN)1 is a comprehensive manually curated networked	423	['AAN']	['ACL', 'Anthology Network', 'a']	[[54, 57]]	[[31, 34], [35, 52], [0, 1]]
423	where Q(w,w?) is proportional to the integral term in Equation (IX). The term PC(w) corresponds	424	['PC']	[]	[[78, 80]]	[]
424	Their by-country breakdown is as follows: 3.99M (61%) from Saudi Arabia (SA), 880K (13%) from Egypt (EG), 707K (11%) from Kuwait (KW), 302K (5%) from United Arab Emi-	425	['SA', 'EG', 'KW']	['Saudi Arabia', 'Kuwait']	[[73, 75], [101, 103], [130, 132]]	[[59, 71], [122, 128]]
425	section 8.1). Then, the grammar underlying the parser is provided with a specific attachment heuristic that uses corequirement (CR) information from the lexicon. 	426	['CR']	['corequirement']	[[128, 130]]	[[113, 126]]
426	 In line 4, G91 provides an Acknowledge type of evidence, and Moves On to the next task item: identifying the Target Location - Grid (TL-GR) of the CFF. The Acknowledge and Move On, referring to the CGU	427	['CFF']	['Target Location - Grid']	[[147, 150]]	[[109, 131]]
427	 With basic CG there are just two rules for combining categories: the forward (FA) and backward (BA) functional application rules.	428	['CG', 'FA', 'BA']	['forward', 'backward']	[[11, 13], [78, 80], [96, 98]]	[[69, 76], [86, 94]]
428	To overcome this problem, Shen et al (2008) proposed a dependency language model (DLM) to exploit longdistance word relations for SMT.	429	[')']	['a', 'language model']	[[42, 43]]	[[34, 35], [66, 80]]
429	Abstract In this paper, we explore the possibility of leveraging Residual Networks (ResNet), a powerful structure in constructing extremely	430	['ResNet']	['Residual Networks', 'a']	[[84, 90]]	[[65, 82], [5, 6]]
430	the end we build two NGCMs: NGCMP  (NGCM according to preceding context) and  NGCMS (NGCM according to succeeding  context).	431	['NGCMs', 'NGCMP', 'NGCMS']	['NGCM']	[[21, 26], [28, 33], [78, 83]]	[[21, 25]]
431	Ures uniformly (Dadam et al, 1986). Our LDB  rmat and Lexical Query l_anguage (LQL) sup-  port the hierarchical model for dictionary data; 	432	['LDB', 'LQL']	['al', 'Lexical Query l_anguage']	[[40, 43], [79, 82]]	[[25, 27], [54, 77]]
432	The Office. Television series, the National Broadcasting Company (NBC). 	433	['NBC']	['National Broadcasting Company']	[[66, 69]]	[[35, 64]]
433	 1 Introduction Question Answering (QA) is a challenging task that draws upon many aspects of NLP.	434	[')']	['Answering']	[[37, 38]]	[[24, 33]]
434	opment and sentence generation. Report, German National Center for Information Technology (GMD),  Institute for integrated publication and information systems (IPSI), Darmstadt, Germany, January 1997. 	435	['GMD', 'IPSI']	['and', 'German National Center for Information Technology', 'Institute for integrated publication and information systems', 'Germany']	[[91, 94], [160, 164]]	[[7, 10], [40, 89], [98, 158], [178, 185]]
435	knowledge, mnong others in l:'ei~onal or DBMT systems.  Such Discovery Assistants (DA) slmuld certainly be  highly cooperative, namely show sensible interactivity 	436	['DBMT', 'DA']	['Discovery Assistants']	[[41, 45], [83, 85]]	[[61, 81]]
436	pact of syllabification on the L2P problem in English. Their Syllabification by Analogy (SbA) algorithm is a data-driven, lazy learning approach.	437	['L2P', 'SbA']	['on', 'Syllabification by Analogy', 'a']	[[31, 34], [89, 92]]	[[21, 23], [61, 87], [1, 2]]
437	1 Introduction Resolving the ambiguity of person names in web search results is a challenging problem becoming an area of interest for Natural Language Processing (NLP) and Information Retrieval (IR) communities. 	438	['NLP', 'IR']	['in', 'a', 'an', 'for Natural Language Processing', 'Information Retrieval']	[[164, 167], [196, 198]]	[[21, 23], [29, 30], [111, 113], [131, 162], [173, 194]]
438	In Proceedings  from the 16th International Conference on  Computational Linguistics (COLING-96), pages  592-597.	439	['COLING-96']	['on Computational Linguistics']	[[86, 95]]	[[-1, 27]]
439	e .g .  M C ~  --7 SUM + PRED* + IOBJ + WBJ + PREP P  *PRED = predicator - not predicate  1-1  detailed analysis of first occurring element of 	440	['SUM', 'IOBJ', 'WBJ', 'PREPP']	['e', 'predicator']	[[19, 22], [33, 37], [40, 43], [-1, 4]]	[[0, 1], [62, 72]]
440	We think, based on the explicit sentences, several Support Vector Machine (SVM) classifiers can be established to do this task.	441	[')']	['Vector Machine', 'to']	[[78, 79]]	[[59, 73], [62, 64]]
441	average values. Figure 6 shows the average pitch of the phrase do you have in task interruption (INT) and poker-playing (PKR) of each player, with the actual values displayed in the columns below.	442	['INT', 'PKR']	['in', 'interruption', 'poker-playing', 'in']	[[97, 100], [121, 124]]	[[75, 77], [83, 95], [106, 119], [75, 77]]
442	enizes, tags, lemmatizes and parses the input sentences, outputting syntactic trees and then adding grammatical relations (GR) as described by (Buttery and Korhonen, 2005).	443	['GR']	['grammatical relations']	[[123, 125]]	[[100, 121]]
443	 We discuss the available functions of the  prototype Chinese Sketch Engine (CSE) as well  as the robustness of language-independent 	444	['CSE']	['Chinese Sketch Engine']	[[76, 79]]	[[53, 74]]
444	tionary. In (Zingarelli, 2008), we found 33 different types of prepositional phrases (PPs), which we grouped into 21 classes (for instance, all of the 48	445	['PPs']	['prepositional phrases']	[[86, 89]]	[[63, 84]]
445	for Statistical Machine Translation Shixiang Lu, Zhenbiao Chen, Bo Xu Interactive Digital Media Technology Research Center (IDMTech) Institute of Automation, Chinese Academy of Sciences, Beijing, China	446	['IDMTech']	['Interactive Digital Media Technology Research Center']	[[124, 131]]	[[70, 122]]
446	overall scores considering all metrics. To these systems we added minimum Bayes risk (MBR) decoding (Kumar and Byrne, 2004).	447	['MBR']	['minimum Bayes risk']	[[86, 89]]	[[66, 84]]
447	(see also Sima?an, 1999, 2003). We haven?t implemented the max rule product (MRP) where posteriors are multiplied instead of added (Petrov and	448	['MRP']	['t', 'max rule product']	[[77, 80]]	[[41, 42], [59, 75]]
448	of the intuition behind the inclusion of Tree Adjoining Lan-  gages (TAL) in the class of languages generated by a variant  of HG's called Modified Head Grammars (MHG's). In the 	449	"['TAL', 'HG', ""'s""]"	['Tree Adjoining', 'in', 'a', 'Modified Head Grammars']	[[69, 72], [127, 129], [129, 131]]	[[41, 55], [7, 9], [57, 58], [139, 161]]
449	If a goal is not accomplished before worst-time  timeout value,  ACCUMVALUE = ACCUM.VALUE - \[response-  complexity(punishment) * sub-goal(worst-ease timeout punis- 	450	['ACCUMVALUE']	[]	[[65, 75]]	[]
450	Each of these sets is further divided by three domains: newswire (NWire), newspaper (NPaper), and broadcast news (BNews). 	451	['BNews']	['broadcast news']	[[114, 119]]	[[98, 112]]
451	The set of ncs in ? are selected from all the possibilities in the hyponym hierarchy according to the minimum description length (MDL) principle (Rissanen 1978) as used by Li and Abe (1995, 1998).	452	['MDL']	['in', 'in', 'minimum description length']	[[130, 133]]	[[15, 17], [15, 17], [102, 128]]
452	However, we are interesting in the potential power of our model by incorporating lexical reordering (LR) models and comparing it with syntax-based models.	453	['LR']	['in', 'lexical reordering']	[[101, 103]]	[[16, 18], [81, 99]]
453	 In the next sections, we briefly introduce the kernel trick and describe the subtree (ST) kernel devised in Vishwanathan and Smola (2002), the subset tree (SST) kernel defined in Collins and Duffy (2002), and the partial tree (PT) kernel proposed in	454	['ST', 'SST', 'PT']	['subtree', 'subset', 'tree', 'partial tree']	[[86, 88], [156, 159], [227, 229]]	[[77, 84], [143, 149], [80, 84], [213, 225]]
454	*****- TRANSFOREATIONS * l f**   SCAN CALLED AT 1 I  ANTEST CALLED FOR 12?F ALAT 3 (AACC) ,SO= 13. RES= 0, TOP= 1:s 	455	['AACC']	['CALLED AT', 'ANTEST CALLED FOR', 'F ALAT']	[[84, 88]]	[[38, 47], [53, 70], [74, 80]]
455	 ? Shallow Syntactic Similarity (SP) SP-Op-?.	456	[')']	['Similarity']	[[34, 35]]	[[20, 30]]
456	"using only a single, probable alignment."" The single most probable assignment Ama~  is the maximum a posteriori (MAP) assignment:  Amax = ar~maxPr(U,A, VIO ) (22) -- AE~4 "	457	['MAP', 'VIO']	['a', 'maximum a posteriori']	[[113, 116], [152, 155]]	[[11, 12], [91, 111]]
457	Sentence). The dependency labels are NK (Noun Kernel), SB (Subject), AO (Object Accusative), HD (Head), MO (Modifier), AC (Adpositional Case Marker), CJ (Conjunct), and OC (Clausal Object).	458	['NK', 'SB', 'AO', 'HD', 'MO', 'AC', 'CJ', 'OC']	['Noun Kernel', 'Subject', 'Object Accusative', 'Head', 'Modifier', 'Adpositional Case Marker', 'Conjunct', 'Clausal Object']	[[37, 39], [55, 57], [69, 71], [93, 95], [104, 106], [119, 121], [150, 152], [169, 171]]	[[41, 52], [59, 66], [73, 90], [97, 101], [108, 116], [123, 147], [154, 162], [173, 187]]
458	 Semantic relatedness of two given terms (text fragments, phrases or words) can be obtained by calculating the correlation between two high dimensional vectors of a Distributional Semantic Model (DSM), which is based on the assumption that semantic meaning of a text can be inferred from its usage in context	459	['DSM']	['Semantic', 'a Distributional Semantic Model', 'on', 'a']	[[195, 198]]	[[0, 8], [162, 193], [119, 121], [3, 4]]
459	An integrated, conditional model of information extraction and coreference with application to citation graph construction. In 20th Conference on Uncertainty in Artificial Intelligence (UAI). 	460	['UAI']	['In', 'Uncertainty in Artificial Intelligence']	[[186, 189]]	[[124, 126], [146, 184]]
460	4 Experiments In this section, we evaluate performance of different methods on the Relation Schema Induction (RSI) task.	461	['RSI']	['In', 'on', 'Relation Schema Induction']	[[110, 113]]	[[14, 16], [27, 29], [83, 108]]
461	We developed and tested our system on 30 full  length UK archaeological reports archived by the  Arts and Humanities Data Service (AHDS)4. 	462	['UK', 'AHDS']	['and', 'Arts and Humanities Data Service']	[[54, 56], [131, 135]]	[[13, 16], [97, 129]]
462	formance. They are the One-error Loss (O-Loss) function, the Symmetric Loss (S-Loss) function, and the Hierarchical Loss (H-Loss) function:	463	[]	['One-error Loss', 'Symmetric Loss', 'Hierarchical Loss']	[]	[[23, 37], [61, 75], [103, 120]]
463	Instead of simple web page counts and complex  web page collection, we propose a novel model,  a Web Search with Double Checking (WSDC), to  analyze snippets.	464	['WSDC']	['Web Search with Double Checking']	[[130, 134]]	[[97, 128]]
464	hedge words Table 3: Participants and summary of system descriptions. Abbreviations: BI=Bioinformatician, NLP=Natural Language Processing researcher, SDE=Software Development Engineer, CoreNLP=Stanford CoreNLP, Porter=Porter	465	[]	['Language Processing', 'Development Engineer', 'CoreNLP']	[]	[[118, 137], [163, 183], [185, 192]]
465	 4 Dimensionality Reduction In this section, the Sparse Projection (SP) algorithm is described (see also Algorithm 1). SP is the core	466	[')']	['Projection']	[[69, 70]]	[[55, 65]]
466	2.2 Hierarchical Agglomerative Clustering After discovering sense clusters of paths, we employ hierarchical agglomerative clustering (HAC) to discover semantic relations from these sense clusters.	467	['HAC']	['hierarchical agglomerative clustering']	[[134, 137]]	[[95, 132]]
467	extremely limited in this domain. Thus, language 1KEY: COM=completive aspect, DEM=demonstrative, DIR=directional	468	[]	['aspect']	[]	[[70, 76]]
468	 2 Background: MaxEnt Models Maximum Entropy (MaxEnt) models are widely used in Natural Language Processing (Berger et	469	[]	['Entropy']	[]	[[36, 43]]
469	is set to 0.95 and threshold_f is set to 1;  Step 3. Use TCT (triple context template) matching  model to extract 2-char, 3-char and 4-char 	470	['TCT']	['is', 'triple context template']	[[57, 60]]	[[0, 2], [62, 85]]
470	trigger in the Trigger Rule Factbase.  Consistency Checkers ( CC' s): Report  inconsistencies within and between factbases and, 	471	"[""CC'""]"	['Consistency Checkers', 's']	[[62, 65]]	[[39, 59], [34, 35]]
471	task: Argumentative Zoning (Teufel and Moens, 2002). Argumentative Zoning (AZ) is the task of applying one of seven discourse level tags (Fig-	472	['AZ']	['Argumentative Zoning', 'Argumentative Zoning']	[[75, 77]]	[[6, 26], [6, 26]]
472	ture of I end set to 1.  Unique Occurrences and Zone (UNIQ): This group of features indicates whether the word 	473	[]	['Unique Occurrences and Zone']	[]	[[25, 52]]
473	examples in (5). This change in beliefs about the past is treated as an error identification signal (EIS). 	474	['EIS']	['error identification signal']	[[101, 104]]	[[72, 99]]
474	non-terminal symbols to characterize linguistic objects allow us to use much richer statistical means such as ME (maximum entropy model), etc.	475	['ME']	['maximum entropy']	[[110, 112]]	[[114, 129]]
475	An example of a comma rule is the following: SX=S X ; ? SX=S X (18)	476	[]	['X', 'X']	[]	[[46, 47], [46, 47]]
476	recognition. In Proceedings of the 26th Conference on Artificial Intelligence (AAAI). 	477	['AAAI']	['In', 'Artificial Intelligence']	[[79, 83]]	[[13, 15], [54, 77]]
477	nication after speech and email.4 Millions of users of instant messaging (IM) services and short message service (SMS) generate electronic content in a dialect that does not adhere to conventional gram-	478	['IM', 'SMS']	['instant messaging', 'short message service', 'in a']	[[74, 76], [114, 117]]	[[55, 72], [91, 112], [147, 151]]
478	speech recognition (ASR), dialog management (DM), database access (DB Access), data storage (DB) and oral response generation (RG). In ad-	479	['ASR', 'DM', 'DB', 'RG']	['speech recognition', 'dialog management', 'data storage', 'oral response generation']	[[20, 23], [45, 47], [67, 69], [127, 129]]	[[0, 18], [26, 43], [79, 91], [101, 125]]
479	classifier.  6.1   Language Model (LM)  As language model has already been used in question classification [7], it is taken as 	480	['LM']	['Language Model']	[[35, 37]]	[[19, 33]]
480	argument facet inducer. We introduce a new task of ARGUMENT FACET SIMILARITY (AFS). We discuss	481	['AFS']	['ARGUMENT FACET SIMILARITY']	[[78, 81]]	[[51, 76]]
481	Question reformulation ? Information Extraction (IE) ?	482	['IE']	['Information Extraction']	[[49, 51]]	[[25, 47]]
482	results training on Multi-Domain Sentiment Dataset and testing on citation dataset (CITD). The horizontal line	483	['CITD']	['on', 'on citation dataset']	[[84, 88]]	[[17, 19], [63, 82]]
483	 In this paper, we propose to disambiguate NEs using a Personalized PageRank (PPR)-based random walk algorithm.	484	['NEs', 'PPR']	['a Personalized PageRank']	[[42, 45], [77, 80]]	[[52, 75]]
484	coverage of the course material.  The quality estimation task (QET) (CallisonBurch et al 2012) aims to develop quality indica-	485	['QET']	['quality estimation task', 'quality']	[[63, 66]]	[[38, 61], [38, 45]]
485	4.2 Evaluation of Different Representation Learning Methods Experiment Setup and Dataset We conduct sentiment classification of items in two traditional sentiment lexicons, HL (Hu and Liu, 2004) and MPQA (Wilson et al., 2005), to evaluate the effective of the	486	['HL', 'MPQA']	['and', 'Hu and Liu', 'and']	[[173, 175], [199, 203]]	[[77, 80], [177, 187], [77, 80]]
486	match number, SM (Short Match) is the continuous match number which is no more than 4, and LM (Long Match) is the continuous match number which is more than 4.	487	['SM', 'LM']	['Short Match', 'Long Match']	[[14, 16], [91, 93]]	[[18, 29], [95, 105]]
487	are written in the original language.  Direct orthographical mapping (DOM), which performs the transliteration between two lan-	488	['DOM']	['in', 'Direct orthographical mapping']	[[70, 73]]	[[12, 14], [39, 68]]
488	for each mention, four pieces of information: 1. the mention type: person (PER), organization (ORG), location (LOC), geopolitical en-	489	['PER', 'ORG', 'LOC']	['person', 'organization', 'location']	[[75, 78], [95, 98], [111, 114]]	[[67, 73], [81, 93], [101, 109]]
489	degree of semantic equivalence between a pair of texts. Natural Language Processing (NLP) applications such as Question Answering (Lin and	490	['NLP']	['a', 'Natural Language Processing']	[[85, 88]]	[[13, 14], [56, 83]]
490	from comparable in-domain corpora. We used the AFP (Agence France Presse) and APW (Associated Press Worldstream Service) news texts since there	491	['AFP', 'APW']	['Agence France Presse', 'Associated Press Worldstream Service']	[[47, 50], [78, 81]]	[[52, 72], [83, 119]]
491	additional computation costs, and can be applied to  several different learners, such as Naive Bayes  (NB), Maximum Entropy (ME), and Support  Vector Machines (SVMs) models.	492	['NB', 'ME', 'SVMs']	['to', 'Naive Bayes', 'Maximum Entropy', 'Support Vector Machines']	[[103, 105], [125, 127], [160, 164]]	[[49, 51], [89, 100], [108, 123], [-1, 22]]
492	train statistical models that rely on annotated data.8 In this paper, we test automatic annotation using Conditional Random Fields (CRFs) (Lafferty et al, 2001) which have achieved high performance for in-	493	['CRFs']	['on', 'Conditional Random Fields', 'al']	[[132, 136]]	[[35, 37], [105, 130], [15, 17]]
493	measured on separate grammatical and ungrammatical data: Gr = Grammatical, AG = Agreement, RW = Real-Word, EW = Extra Word, MW = Missing Word	494	['AG', 'RW', 'EW', 'MW']	['Gr', 'Grammatical', 'Agreement', 'Real-Word', 'Extra Word']	[[75, 77], [91, 93], [107, 109], [124, 126]]	[[57, 59], [62, 73], [80, 89], [96, 105], [112, 122]]
494	Schu?tze reduces the dimensionality of this feature space using Singular Value Decomposition (SVD), which is also employed by related techniques such as Latent Semantic Indexing (Deerwester et	495	['SVD']	['Singular Value Decomposition']	[[94, 97]]	[[64, 92]]
495	is a.t least cubic in t, ime, this fl)llows trivially  fronl the inequality  A a+B a <A a+:C4 ~B+aAB=+B a =(A+B)  a  for A,B positive - length of strings) 	496	[]	['a', 'B']	[]	[[3, 4], [81, 82]]
496	present specialized knowledge, since both the writer and readers are experts. Medical texts include the abstracts of all medical articles written in Basque in the Gaceta M?edica de Bilbao (GMB) ? Medical	497	[]	['Gaceta M ? edica de Bilbao', '?']	[]	[[-1, 25], [171, 172]]
497	2014). We note the linguistic rules included in the Lease, Johnson & Charniak (2006) tree adjoining grammar (TAG) noisy-channel model ? lexical,	498	['TAG']	['in', 'tree adjoining grammar']	[[109, 112]]	[[20, 22], [85, 107]]
