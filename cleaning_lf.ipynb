{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sadan\\OneDrive\\GitHub\\PR-AAAI22-SDU-ST1-AE\\results\\finetuned_models\\model_all_xb_v1_512\\output\n"
     ]
    }
   ],
   "source": [
    "cd C:/Users/sadan/OneDrive/GitHub/PR-AAAI22-SDU-ST1-AE/results/finetuned_models/model_all_xb_v1_512/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean stopword from inside the form\n",
    "def clean_stops_inform(t):\n",
    "    \n",
    "    t = [f.split() for f in t]\n",
    "    for ls in t:\n",
    "        if ls[0] == 'a':\n",
    "            del ls[0]\n",
    "        if ls[-1] == 'is':\n",
    "            del ls[-1]\n",
    "    t = [[' '.join(sublist)] for sublist in t]\n",
    "    flat_list = [item for sublist in t for item in sublist]\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding to  Constantin's function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Text Data Mining'] \n",
      "\t\t ['a', 'Text Data Mining']\n",
      "\t\t ['Text Data Mining']\n",
      "['Mean Average Precision'] \n",
      "\t\t ['Mean Average Precision']\n",
      "\t\t ['Mean Average Precision']\n",
      "['sequential dependence', 'Markov random field'] \n",
      "\t\t ['a', 'query likelihood', 'and a', 'sequential dependence', 'Markov random field', 'and']\n",
      "\t\t ['query likelihood', 'sequential dependence', 'Markov random field']\n",
      "['pseudo relevance feedback'] \n",
      "\t\t ['pseudo relevance feedback', 'in']\n",
      "\t\t ['pseudo relevance feedback']\n",
      "['proper', 'verbs'] \n",
      "\t\t ['non-proper', 'nouns', 'proper nouns', 'verbs']\n",
      "\t\t ['non-proper', 'proper nouns', 'verbs']\n",
      "['Minimum Phone Error', 'Maximum Likelihood Linear Transform', 'Boosted Maximum Mutual Information'] \n",
      "\t\t ['Maximum Likelihood Linear Transform', 'Boosted Maximum Mutual Information', 'Minimum Phone Error']\n",
      "\t\t ['Maximum Likelihood Linear Transform', 'Boosted Maximum Mutual Information', 'Minimum Phone Error']\n",
      "['Structured Weighted Violations Perceptron'] \n",
      "\t\t ['Structured Weighted Violations Perceptron', 'on a']\n",
      "\t\t ['Structured Weighted Violations Perceptron']\n",
      "['Chomsky Normal Form'] \n",
      "\t\t ['or', 'Chomsky Normal Form']\n",
      "\t\t ['Chomsky Normal Form']\n",
      "['Probabilistic CFG'] \n",
      "\t\t ['a CFG is', 'a Probabilistic CFG', 'n']\n",
      "\t\t ['Probabilistic CFG']\n",
      "['Language Neutral Syntax'] \n",
      "\t\t ['a', 'Language Neutral Syntax']\n",
      "\t\t ['Language Neutral Syntax']\n",
      "['Base+Appositives', 'FrameNet', 'Verb Pair'] \n",
      "\t\t ['Base+FrameNet', 'Base+Verb Pairs', 'Base+Appositives']\n",
      "\t\t ['Base+FrameNet', 'Base+Verb Pairs', 'Base+Appositives']\n",
      "['natural language generation'] \n",
      "\t\t ['language', 'a natural language generation', 'a']\n",
      "\t\t ['natural language generation']\n",
      "['labeled recall', 'labeled precision'] \n",
      "\t\t ['labeled recall', 'labeled precision']\n",
      "\t\t ['labeled recall', 'labeled precision']\n",
      "['Response Planner'] \n",
      "\t\t ['Response Planner', 'an']\n",
      "\t\t ['Response Planner']\n",
      "['truncated', 'terse information', 'interrupted', 'transposed'] \n",
      "\t\t ['terse information', 'interrupted', 'truncated', 'transposed sentence']\n",
      "\t\t ['terse information', 'interrupted', 'truncated', 'transposed sentence']\n",
      "['Support Vector Machines'] \n",
      "\t\t ['in', 'Support Vector Machines', 'in']\n",
      "\t\t ['Support Vector Machines']\n",
      "['an adverb', 'verb group'] \n",
      "\t\t ['adverb', 'a verb group']\n",
      "\t\t ['adverb', 'verb group']\n",
      "['posttraumatic stress disorder'] \n",
      "\t\t ['a', 'posttraumatic stress disorder', 'is a', 'disorder', 'a', 'trauma', 'a']\n",
      "\t\t ['posttraumatic stress disorder']\n",
      "['Language Technology Components'] \n",
      "\t\t ['Language Technology Components']\n",
      "\t\t ['Language Technology Components']\n",
      "['product attribut'] \n",
      "\t\t []\n",
      "\t\t []\n",
      "['Discourse Tagging Tool'] \n",
      "\t\t ['a', 'Discourse Tagging Tool', 'Discourse Tagging']\n",
      "\t\t ['Discourse Tagging Tool']\n",
      "['Alignment Error Rate'] \n",
      "\t\t ['Alignment Error Rate']\n",
      "\t\t ['Alignment Error Rate']\n",
      "['relation extraction'] \n",
      "\t\t ['relation extraction']\n",
      "\t\t ['relation extraction']\n",
      "['Mean Reciprocal Rank'] \n",
      "\t\t ['Mean Reciprocal Rank']\n",
      "\t\t ['Mean Reciprocal Rank']\n",
      "['Functional unification'] \n",
      "\t\t ['Functional unification', 'a']\n",
      "\t\t ['Functional unification']\n",
      "['Missed Samples', 'Perplex', 'Missed Samples'] \n",
      "\t\t ['Missed Samples', 'Missed Samples']\n",
      "\t\t ['Missed Samples', 'Missed Samples']\n",
      "['Computer Vision and Pattern Recognition'] \n",
      "\t\t ['Conference on Computer Vision and Pattern Recognition']\n",
      "\t\t ['Conference on Computer Vision and Pattern Recognition']\n",
      "['Support Vector Machine'] \n",
      "\t\t ['Support Vector Machines', 'to']\n",
      "\t\t ['Support Vector Machines']\n",
      "['Sound Pattern of English'] \n",
      "\t\t ['of', 'Sound Pattern of English']\n",
      "\t\t ['Sound Pattern of English']\n",
      "['2*P*R'] \n",
      "\t\t []\n",
      "\t\t []\n",
      "['BioNLP'] \n",
      "\t\t []\n",
      "\t\t []\n",
      "['graphical user interface'] \n",
      "\t\t ['a', 'a', 'a graphical user interface', 'users', 'o a', 'a']\n",
      "\t\t ['graphical user interface', 'users']\n",
      "['Subordination Link'] \n",
      "\t\t ['in', 'at', 'Subordination Link']\n",
      "\t\t ['Subordination Link']\n",
      "['final'] \n",
      "\t\t ['final stress']\n",
      "\t\t ['final stress']\n",
      "['Uncertainty in Artificial Intelligence'] \n",
      "\t\t ['In', 'Uncertainty in Artificial Intelligence']\n",
      "\t\t ['Uncertainty in Artificial Intelligence']\n",
      "['Automated Knowledge LDA'] \n",
      "\t\t ['a', 'a', 'Automated Knowledge LDA']\n",
      "\t\t ['Automated Knowledge LDA']\n",
      "['Markov Logic Network'] \n",
      "\t\t ['Markov', 'Markov Logic Network']\n",
      "\t\t ['Markov Logic Network']\n",
      "['language model', 'translation model'] \n",
      "\t\t ['language model', 'translation model']\n",
      "\t\t ['language model', 'translation model']\n",
      "['to', 'inanimate', 'animate', 'is', 'gerund', 'prepositional phrase'] \n",
      "\t\t ['NP', 'verb', 'phrase', 'prep', 'prep']\n",
      "\t\t ['verb', 'phrase', 'prep', 'prep']\n",
      "['Information Gain'] \n",
      "\t\t ['in', 'Information Gain']\n",
      "\t\t ['Information Gain']\n",
      "['named page', 'home page', 'topic distillation'] \n",
      "\t\t ['in', 'home page finding', 'page finding', 'topic distillation']\n",
      "\t\t ['home page finding', 'topic distillation']\n",
      "['convolution kernels'] \n",
      "\t\t ['convolution kernels']\n",
      "\t\t ['convolution kernels']\n",
      "['Named entity'] \n",
      "\t\t ['Named entity']\n",
      "\t\t ['Named entity']\n",
      "['specificity character goals'] \n",
      "\t\t ['s', 'is', 'specificity character goals', 'character goals', 'character goal']\n",
      "\t\t ['specificity character goals']\n",
      "['Maximum Entropy'] \n",
      "\t\t ['Maximum Entropy']\n",
      "\t\t ['Maximum Entropy']\n",
      "['average perceptron'] \n",
      "\t\t ['perceptron', 'average perceptron']\n",
      "\t\t ['average perceptron']\n",
      "['BLAST bit score'] \n",
      "\t\t ['a', 'BLAST bit score', 'score']\n",
      "\t\t ['BLAST bit score']\n",
      "['Treelet Phrasal'] \n",
      "\t\t ['Treelet', 'Treelet Phrasal Diff']\n",
      "\t\t ['Treelet Phrasal Diff']\n",
      "['Biquadratic Kerne', 'Quadratic Kernel', '8-th Degree Polynomial Kernel'] \n",
      "\t\t ['Quadratic Kernel', 'Biquadratic Kernel', 'Kernel']\n",
      "\t\t ['Quadratic Kernel', 'Biquadratic Kernel']\n",
      "['machine learning', 'audiobased', 'knowledge-based'] \n",
      "\t\t ['in', 'audiobased', 'knowledge-based', 'machine learning', 'in']\n",
      "\t\t ['audiobased', 'knowledge-based', 'machine learning']\n",
      "['positive+unlabeled'] \n",
      "\t\t ['positive+unlabeled', 'positive']\n",
      "\t\t ['positive+unlabeled']\n",
      "['City University'] \n",
      "\t\t ['City University']\n",
      "\t\t ['City University']\n",
      "['Dbest'] \n",
      "\t\t ['bi', 'Dbest', 'argmaxD P']\n",
      "\t\t ['Dbest', 'argmaxD P']\n",
      "['Functional Grammar'] \n",
      "\t\t ['a', 'Functional Grammar', 'a']\n",
      "\t\t ['Functional Grammar']\n",
      "['named entities'] \n",
      "\t\t ['named entities']\n",
      "\t\t ['named entities']\n",
      "['Support Vector Machine'] \n",
      "\t\t ['Support Vector Machine']\n",
      "\t\t ['Support Vector Machine']\n",
      "['University of Manchester'] \n",
      "\t\t ['University of Manchester']\n",
      "\t\t ['University of Manchester']\n",
      "['Broadcast Conversations', 'Broadcast News', 'Conversational Telephone Speech', 'Newswire'] \n",
      "\t\t ['Broadcast Conversations', 'Broadcast', 'News', 'Conversational Telephone', 'Newswire']\n",
      "\t\t ['Broadcast Conversations', 'Conversational Telephone', 'Newswire']\n",
      "['Attribute Relation Graph'] \n",
      "\t\t ['Representation Attribute Relation Graph']\n",
      "\t\t ['Representation Attribute Relation Graph']\n",
      "['distortion limit'] \n",
      "\t\t ['a', 'low distortion limit', 'a']\n",
      "\t\t ['low distortion limit']\n",
      "['maximum a posteriori'] \n",
      "\t\t ['maximum a posteriori', 'a']\n",
      "\t\t ['maximum a posteriori']\n",
      "['Natural language processin', 'Part-Of-Speech'] \n",
      "\t\t ['of', 'Natural language processing']\n",
      "\t\t ['Natural language processing']\n",
      "['Verb Arity Sampling Test'] \n",
      "\t\t ['a', 'in', 'Verb Arity Sampling Test']\n",
      "\t\t ['Verb Arity Sampling Test']\n",
      "['Rand Index'] \n",
      "\t\t ['or', 'Rand Index', 'Rand']\n",
      "\t\t ['Rand Index']\n",
      "['Support Vector Machine'] \n",
      "\t\t ['a Support Vector Machine']\n",
      "\t\t ['Support Vector Machine']\n",
      "['descriptor array'] \n",
      "\t\t ['Neural network architecture', 'descriptor array']\n",
      "\t\t ['Neural network architecture', 'descriptor array']\n",
      "['Regular Expressions'] \n",
      "\t\t ['on', 'a', 'Regular Expressions', 'a', 'a']\n",
      "\t\t ['Regular Expressions']\n",
      "['Association for Computational Linguistic'] \n",
      "\t\t ['on Association for Computational Linguistics']\n",
      "\t\t ['on Association for Computational Linguistics']\n",
      "['Quranic Arabic Dependency Treebank'] \n",
      "\t\t ['Quranic Arabic Dependency Treebank']\n",
      "\t\t ['Quranic Arabic Dependency Treebank']\n",
      "['logical form'] \n",
      "\t\t ['a logical form', 'a']\n",
      "\t\t ['logical form']\n",
      "['Word Distributional Similarity', 'Random', 'LexRank', 'DivRank', 'DivRank with Priors', 'C-LexRank', 'Confidence Interval'] \n",
      "\t\t [';', 'p', 'with Priors', 'Distributional Similarity']\n",
      "\t\t ['with Priors', 'Distributional Similarity']\n",
      "['conjunctions'] \n",
      "\t\t ['conjunctions']\n",
      "\t\t ['conjunctions']\n",
      "['lexical rules'] \n",
      "\t\t ['lexical rules']\n",
      "\t\t ['lexical rules']\n",
      "['Rand Index'] \n",
      "\t\t ['Rand Index', 'Rand']\n",
      "\t\t ['Rand Index']\n",
      "['algorithmic on(foiled grammar'] \n",
      "\t\t ['a grammar', '( foiled grammar']\n",
      "\t\t ['grammar', '( foiled grammar']\n",
      "['regular expressions'] \n",
      "\t\t ['regular expressions']\n",
      "\t\t ['regular expressions']\n",
      "['Adjective phras', 'Adverb phrase'] \n",
      "\t\t ['Adverb phrase', 'Adjective phrase']\n",
      "\t\t ['Adverb phrase', 'Adjective phrase']\n",
      "['Memory Efficient Tucker'] \n",
      "\t\t ['Memory Efficient Tucker']\n",
      "\t\t ['Memory Efficient Tucker']\n",
      "['language model'] \n",
      "\t\t ['model', 'a', 'a', 'a', 'language model']\n",
      "\t\t ['language model']\n",
      "['Noun Stem', 'Adjectival Sta', 'Verb Stem', 'Determine', 'Nominal Inflexion', 'Verbal Inflsxion', 'Pronoun', 'Adjectival Inflexion'] \n",
      "\t\t ['Adjectival Sta~', 'Verb Stem', 'Determine~', 'Nominal', 'Inflexion', 'Noun Stem', 'Verbal Inflsxion', 'Pronoun']\n",
      "\t\t ['Adjectival Sta~', 'Verb Stem', 'Determine~', 'Nominal', 'Inflexion', 'Noun Stem', 'Verbal Inflsxion', 'Pronoun']\n",
      "['Support Vector Machines'] \n",
      "\t\t ['Vector Machines', 'in']\n",
      "\t\t ['Vector Machines']\n",
      "['Penn Treebank'] \n",
      "\t\t ['Penn Treebank']\n",
      "\t\t ['Penn Treebank']\n",
      "['Machine translation'] \n",
      "\t\t ['Machine translation']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t ['Machine translation']\n",
      "['vowel', 'any char'] \n",
      "\t\t ['y', 'vowel', 'any char']\n",
      "\t\t ['vowel', 'any char']\n",
      "['French - Englis', 'human-assisted'] \n",
      "\t\t ['French - English', 'human-assisted']\n",
      "\t\t ['French - English', 'human-assisted']\n",
      "['Sense Data Item'] \n",
      "\t\t ['a', 'Sense Data Item']\n",
      "\t\t ['Sense Data Item']\n",
      "['combinatory categorial grammar'] \n",
      "\t\t ['a combinatory categorial grammar']\n",
      "\t\t ['combinatory categorial grammar']\n",
      "['as the Agent'] \n",
      "\t\t ['Agent']\n",
      "\t\t ['Agent']\n",
      "['training set', 'validating set'] \n",
      "\t\t ['in', 'mean training set', 'validating set', 'in']\n",
      "\t\t ['mean training set', 'validating set']\n",
      "['Empirical Methods in Natural Language Processing'] \n",
      "\t\t ['Methods in Natural Language Processing (']\n",
      "\t\t ['Methods in Natural Language Processing (']\n",
      "['Question Answering', 'Information Extraction'] \n",
      "\t\t ['Question Answering', 'Information Extraction', 'a']\n",
      "\t\t ['Question Answering', 'Information Extraction']\n",
      "['expected term frequencies'] \n",
      "\t\t ['expected term frequencies', 'i']\n",
      "\t\t ['expected term frequencies']\n",
      "['Mary', 'Mary'] \n",
      "\t\t ['KMary', 'Mary']\n",
      "\t\t ['KMary']\n",
      "['Computer scientist', 'Stanford', 'Link Grammar Parser', 'McClosky-Charniak-Johnson'] \n",
      "\t\t ['Language Processing', 'scientist', 'CoreNLP', 'stemmer', 'stemmer', 'Grammar']\n",
      "\t\t ['Language Processing', 'scientist', 'CoreNLP', 'stemmer', 'stemmer', 'Grammar']\n",
      "['cost-sensitive classification'] \n",
      "\t\t ['a', 'cost-sensitive classification']\n",
      "\t\t ['cost-sensitive classification']\n",
      "['Distributed Artificial Intelligence Laboratory'] \n",
      "\t\t ['Artificial Intelligence Laboratory', 't']\n",
      "\t\t ['Artificial Intelligence Laboratory']\n",
      "['Analysis of Variance'] \n",
      "\t\t ['Analysis of Variance']\n",
      "\t\t ['Analysis of Variance']\n",
      "['Source Connectivity Strength', 'Target Connectivity Strength'] \n",
      "\t\t ['Connectivity', 'Strength', 'Source Connectivity Strength', 'Target Connectivity Strength']\n",
      "\t\t ['Source Connectivity Strength', 'Target Connectivity Strength']\n",
      "['Integer Linear Programming'] \n",
      "\t\t ['Integer Linear Programming']\n",
      "\t\t ['Integer Linear Programming']\n",
      "['Educational Testing Service'] \n",
      "\t\t ['an', 'at Educational Testing Service']\n",
      "\t\t ['at Educational Testing Service']\n",
      "['negative Matrix Factorization', 'Latent Semantic Analysis'] \n",
      "\t\t ['Latent Semantic Analysis', 'o', 'or Non-negative Matrix Factorization']\n",
      "\t\t ['Latent Semantic Analysis', 'or Non-negative Matrix Factorization']\n",
      "['dialog act'] \n",
      "\t\t ['dialog act']\n",
      "\t\t ['dialog act']\n",
      "['Latent Semantic Analysis'] \n",
      "\t\t ['Semantic Analysis', 'Semantic Analysis', 'is a']\n",
      "\t\t ['Semantic Analysis', 'Semantic Analysis']\n",
      "['Switchboard Dialog Act'] \n",
      "\t\t ['Switchboard Dialog Act']\n",
      "\t\t ['Switchboard Dialog Act']\n",
      "['Penn Discourse Tree Bank'] \n",
      "\t\t ['is', 'Penn Discourse Tree Bank']\n",
      "\t\t ['Penn Discourse Tree Bank']\n",
      "['PennTreebank'] \n",
      "\t\t ['a', 'PennTreebank', 'a']\n",
      "\t\t ['PennTreebank']\n",
      "['spoken dialog system', 'spoken language understanding'] \n",
      "\t\t ['a', 'in', 'spoken dialog system', 'spoken language understanding']\n",
      "\t\t ['spoken dialog system', 'spoken language understanding']\n",
      "['linker for activation of T'] \n",
      "\t\t ['B', 'cell', 'activation of T cells', 'c']\n",
      "\t\t ['activation of T cells']\n",
      "['long short term memory'] \n",
      "\t\t ['long short term memory', 'a']\n",
      "\t\t ['long short term memory']\n",
      "['automated coreference'] \n",
      "\t\t ['automated coreference']\n",
      "\t\t ['automated coreference']\n",
      "['Mean Average Precision'] \n",
      "\t\t ['tion', 'Mean Average Precision', 'on']\n",
      "\t\t ['tion', 'Mean Average Precision']\n",
      "['diminishers', 'highly negative', 'negative', 'positive', 'highly positive', 'invertors', 'invertors'] \n",
      "\t\t ['negative', 'positive']\n",
      "\t\t ['negative', 'positive']\n",
      "['Automated Student Assessment Prize'] \n",
      "\t\t ['Automated Student Assessment Prize']\n",
      "\t\t ['Automated Student Assessment Prize']\n",
      "['subcategorization frames'] \n",
      "\t\t ['frames', 'subcategorization frames']\n",
      "\t\t ['subcategorization frames']\n",
      "['most frequent sense'] \n",
      "\t\t ['frequent sense', 'is']\n",
      "\t\t ['frequent sense']\n",
      "['Tageszeitung'] \n",
      "\t\t ['Tageszeitung']\n",
      "\t\t ['Tageszeitung']\n",
      "['Latent Mixture of Discriminative Experts'] \n",
      "\t\t ['of', 'Latent Mixture of Discriminative Experts']\n",
      "\t\t ['Latent Mixture of Discriminative Experts']\n",
      "['World Wide Web'] \n",
      "\t\t ['World Wide Web']\n",
      "\t\t ['World Wide Web']\n",
      "['language model'] \n",
      "\t\t ['an', 'language model']\n",
      "\t\t ['language model']\n",
      "['accumulated tag counts'] \n",
      "\t\t ['accumulated tag counts']\n",
      "\t\t ['accumulated tag counts']\n",
      "['Optimality Theory'] \n",
      "\t\t ['Optimality Theory']\n",
      "\t\t ['Optimality Theory']\n",
      "['context group discrimination'] \n",
      "\t\t ['a group', 'context group discrimination']\n",
      "\t\t ['group', 'context group discrimination']\n",
      "['Document frequency'] \n",
      "\t\t ['Document frequency of constituents', 'frequency of a constituent']\n",
      "\t\t ['Document frequency of constituents', 'frequency of a constituent']\n",
      "['direct orthographic mapping'] \n",
      "\t\t ['in', 'a', 'mapping', 'a']\n",
      "\t\t ['mapping']\n",
      "['unlabeled attachment score', 'labeled attachment score'] \n",
      "\t\t ['labeled attachment score', 'unlabeled attachment score']\n",
      "\t\t ['unlabeled attachment score']\n",
      "['support vector machine'] \n",
      "\t\t ['machine', 'to', 'support vector machine']\n",
      "\t\t ['support vector machine']\n",
      "['Natural Language Processing'] \n",
      "\t\t ['Natural Language Processing']\n",
      "\t\t ['Natural Language Processing']\n",
      "['all gazetteer'] \n",
      "\t\t ['all gazetteer']\n",
      "\t\t ['all gazetteer']\n",
      "['Treebank Apl)roach'] \n",
      "\t\t ['A', 'Treebank', 'roach']\n",
      "\t\t ['Treebank', 'roach']\n",
      "['phrase by phrase', 'word by word'] \n",
      "\t\t ['phrase by phrase', 'word by word']\n",
      "\t\t ['phrase by phrase', 'word by word']\n",
      "['false positives', 'true positives'] \n",
      "\t\t ['true positives', 'true positives', 'false positives']\n",
      "\t\t ['true positives', 'true positives', 'false positives']\n",
      "['Computer Vision and Pattern Recognition'] \n",
      "\t\t ['Conference', 'on Computer Vision and Pattern Recognition']\n",
      "\t\t ['Conference', 'on Computer Vision and Pattern Recognition']\n",
      "['Person', 'Organization', 'Facility', 'Geo-Political'] \n",
      "\t\t ['Person', 'Organization', 'Facility']\n",
      "\t\t ['Person', 'Organization', 'Facility']\n",
      "['Question Answering', 'Semantic Role Labeling'] \n",
      "\t\t ['Semantic Role Labeling', 'in', 'Question Answering']\n",
      "\t\t ['Semantic Role Labeling', 'Question Answering']\n",
      "['Named Entity Recognition'] \n",
      "\t\t ['Entity Recognition', 'a']\n",
      "\t\t ['Entity Recognition']\n",
      "['Subset of Stockholm'] \n",
      "\t\t ['Adding valency', 'Subset of']\n",
      "\t\t ['Adding valency', 'Subset of']\n",
      "['maximum entropy'] \n",
      "\t\t ['maximum entropy']\n",
      "\t\t ['maximum entropy']\n",
      "['Cross Language Evaluation Forum'] \n",
      "\t\t ['Cross Language Evaluation Forum']\n",
      "\t\t ['Cross Language Evaluation Forum']\n",
      "['PENNBIOIE gene'] \n",
      "\t\t ['gene corpus', 'gene']\n",
      "\t\t ['gene corpus']\n",
      "['machine translation'] \n",
      "\t\t ['in', 'on', 'in', 'machine translation', 'a']\n",
      "\t\t ['machine translation']\n",
      "['Philadelphia'] \n",
      "\t\t ['Philadelphia']\n",
      "\t\t ['Philadelphia']\n",
      "['Support Vector Machines'] \n",
      "\t\t ['Support Vector Machines']\n",
      "\t\t ['Support Vector Machines']\n",
      "['semantic relatedness'] \n",
      "\t\t ['semantic relatedness']\n",
      "\t\t ['semantic relatedness']\n",
      "['noun', 'determiner'] \n",
      "\t\t [')', ')']\n",
      "\t\t []\n",
      "['Center for Natural Language'] \n",
      "\t\t ['for', 'Center for Natural Language Processing']\n",
      "\t\t ['Center for Natural Language Processing']\n",
      "['Mission Rehearsal Exercise'] \n",
      "\t\t ['a', 'Mission Rehearsal Exercise']\n",
      "\t\t ['Mission Rehearsal Exercise']\n",
      "['number of markables'] \n",
      "\t\t ['number of']\n",
      "\t\t ['number of']\n",
      "['autism spectrum disorder'] \n",
      "\t\t ['autism spectrum disorder']\n",
      "\t\t ['autism spectrum disorder']\n",
      "['null grammar'] \n",
      "\t\t ['a', 'grammar', 'null grammar', 'a']\n",
      "\t\t ['null grammar']\n",
      "['Beneficial'] \n",
      "\t\t ['Beneficial']\n",
      "\t\t ['Beneficial']\n",
      "['possessive pronoun', 'determiner', 'cardinal'] \n",
      "\t\t ['determiner', 'a', 'cardinal numbers']\n",
      "\t\t ['determiner', 'cardinal numbers']\n",
      "['Computational Linguistics'] \n",
      "\t\t ['on', 'Linguistics']\n",
      "\t\t ['Linguistics']\n",
      "['generalized expectation'] \n",
      "\t\t ['expectation']\n",
      "\t\t ['expectation']\n",
      "['difference'] \n",
      "\t\t []\n",
      "\t\t []\n",
      "['Leaf Node Network'] \n",
      "\t\t ['Leaf Node Network']\n",
      "\t\t ['Leaf Node Network']\n",
      "['Implicit Attitude'] \n",
      "\t\t ['Attitude', 'n', 't']\n",
      "\t\t ['Attitude']\n",
      "['Computational Linguistics'] \n",
      "\t\t ['on Computational Linguistics']\n",
      "\t\t ['on Computational Linguistics']\n",
      "['language model'] \n",
      "\t\t ['a', 'an', 'language model']\n",
      "\t\t ['language model']\n",
      "['named entities'] \n",
      "\t\t ['named entities']\n",
      "\t\t ['named entities']\n",
      "['Customization Solution'] \n",
      "\t\t ['Customization', 'a', 'Customization Solution', 'a']\n",
      "\t\t ['Customization Solution']\n",
      "['prepositional phrase'] \n",
      "\t\t ['prepositional phrase']\n",
      "\t\t ['prepositional phrase']\n",
      "['Association for Computational Linguistics'] \n",
      "\t\t ['Association for Computational Linguistics']\n",
      "\t\t ['Association for Computational Linguistics']\n",
      "['Filled Pause', 'Reparandum', 'Interregnum'] \n",
      "\t\t ['Pause']\n",
      "\t\t ['Pause']\n",
      "['TurnCos', 'TaskCompletionReward', 'TotalTurnCost'] \n",
      "\t\t ['TaskCompletionReward', 'TurnCost', 'TotalTurnCost']\n",
      "\t\t ['TaskCompletionReward', 'TotalTurnCost']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['machine translation'] \n",
      "\t\t ['on machine translation', 'in']\n",
      "\t\t ['on machine translation']\n",
      "['supervised binarized PCFG', 'supervised binarized DOP'] \n",
      "\t\t ['a supervised binarized PCFG', 'a supervised binarized DOP']\n",
      "\t\t ['supervised binarized PCFG', 'supervised binarized DOP']\n",
      "['Recursive Autoencoder'] \n",
      "\t\t ['Recursive Autoencoder']\n",
      "\t\t ['Recursive Autoencoder']\n",
      "['document representation'] \n",
      "\t\t ['l', 'rhetorical representation', 'document representation']\n",
      "\t\t ['rhetorical representation', 'document representation']\n",
      "['agent', 'ins t rumenta l', 'objective', 'experiencer'] \n",
      "\t\t ['m', 'a t i', 'a l l', 't r u', 't u r e', 'a', 't', 'r e l a t i o n', 'p a r t i', 'i p a t i o n', 't', 'agent', 'ins t rumenta l', 'objective', 'experiencer']\n",
      "\t\t ['agent', 'ins t rumenta l', 'objective', 'experiencer']\n",
      "['attribute', 'art~fact', 'body', 'an~'] \n",
      "\t\t ['an~', 'art~fact', 'attribute', 'body']\n",
      "\t\t ['art~fact', 'attribute', 'body']\n",
      "['part of speech'] \n",
      "\t\t ['o', 'part of speech']\n",
      "\t\t ['part of speech']\n",
      "['native language identification'] \n",
      "\t\t ['native language identification', 'a']\n",
      "\t\t ['native language identification']\n",
      "['minimum error rate training'] \n",
      "\t\t ['error rate training']\n",
      "\t\t ['error rate training']\n",
      "['Speech and Language Processing for Assistive Technologies'] \n",
      "\t\t ['Speech and Language Processing for Assistive Technologies']\n",
      "\t\t ['Speech and Language Processing for Assistive Technologies']\n",
      "['elementary discourse units'] \n",
      "\t\t ['a', 'elementary discourse units']\n",
      "\t\t ['elementary discourse units']\n",
      "['conditional random fields'] \n",
      "\t\t ['and a', 'and', 'a conditional random fields', 'an']\n",
      "\t\t ['conditional random fields']\n",
      "['Machine Translation', 'Question Answering', 'Information Retrieval'] \n",
      "\t\t ['Question Answering', 'Machine Translation', 'Information Retrieval']\n",
      "\t\t ['Question Answering', 'Machine Translation', 'Information Retrieval']\n",
      "['Transactions of the ACL'] \n",
      "\t\t ['ation for Computational Linguistics', 'he', 'on the', 'of the', 'Transactions of the ACL', 'Computational Linguistics']\n",
      "\t\t ['ation for Computational Linguistics', 'Transactions of the ACL']\n",
      "['Dual Encoder', 'recurrent neural network'] \n",
      "\t\t ['recurrent neural network', 'Dual Encoder', 'et']\n",
      "\t\t ['recurrent neural network', 'Dual Encoder']\n",
      "['communicative act', 'meaningful expression'] \n",
      "\t\t ['meaningful expression', 'act', 'a', 'meaning', 'communicative act', 'a']\n",
      "\t\t ['meaningful expression', 'communicative act']\n",
      "['database'] \n",
      "\t\t ['a', 'database', 'a']\n",
      "\t\t ['database']\n",
      "['Full Verb'] \n",
      "\t\t ['Full Verb']\n",
      "\t\t ['Full Verb']\n",
      "['Foundation'] \n",
      "\t\t ['Research Foundation']\n",
      "\t\t ['Research Foundation']\n",
      "['source code author profile'] \n",
      "\t\t ['source code author profile']\n",
      "\t\t ['source code author profile']\n",
      "['Document Understanding Conference'] \n",
      "\t\t ['Understanding Conference', 'in']\n",
      "\t\t ['Understanding Conference']\n",
      "['True Positive', 'False Positive'] \n",
      "\t\t ['True Positive', 'False Positive']\n",
      "\t\t ['True Positive', 'False Positive']\n",
      "['Logical Forms'] \n",
      "\t\t ['Logical Forms']\n",
      "\t\t ['Logical Forms']\n",
      "['Levenshtein with substitution penalty'] \n",
      "\t\t ['substitution', 'Levenshtein with substitution penalty', 'a', 'in']\n",
      "\t\t ['Levenshtein with substitution penalty']\n",
      "['out of vocabulary'] \n",
      "\t\t ['of', 'a', 'out of vocabulary']\n",
      "\t\t ['out of vocabulary']\n",
      "['International Joint Conference on Natural Language Processing'] \n",
      "\t\t []\n",
      "\t\t []\n",
      "['verb phrases'] \n",
      "\t\t ['as verb']\n",
      "\t\t ['as verb']\n",
      "['Air Force Research Laboratory', 'Research Projects Agency', 'Deep Exploration and Filtering of Text'] \n",
      "\t\t ['Research Projects Agency', 'Deep Exploration and Filtering of Text', 'Air Force Research Laboratory']\n",
      "\t\t ['Research Projects Agency', 'Deep Exploration and Filtering of Text', 'Air Force Research Laboratory']\n",
      "['Dependency relation'] \n",
      "\t\t ['relation']\n",
      "\t\t ['relation']\n",
      "['short form', 'long form'] \n",
      "\t\t ['the', 'of the long', 'short']\n",
      "\t\t ['of the long', 'short']\n",
      "['shared variables', 'filling status'] \n",
      "\t\t ['lexemes', 'filling status', 'shared variables', 'variables', 'sentence']\n",
      "\t\t ['lexemes', 'filling status', 'shared variables', 'sentence']\n",
      "['quadratic program'] \n",
      "\t\t ['t', 'a quadratic program', 'a']\n",
      "\t\t ['quadratic program']\n",
      "['Confidence Weighted'] \n",
      "\t\t ['Confidence Weighted']\n",
      "\t\t ['Confidence Weighted']\n",
      "['punctuation', 'particle'] \n",
      "\t\t ['punctuation', 'particle', 'residual', 'a']\n",
      "\t\t ['punctuation', 'particle', 'residual']\n",
      "['domain model level', 'English-oriented level'] \n",
      "\t\t ['English-oriented', 'level', 'domain model level', 'is']\n",
      "\t\t ['English-oriented', 'domain model level']\n",
      "['system'] \n",
      "\t\t ['a speech dialogue system']\n",
      "\t\t ['speech dialogue system']\n",
      "['base temporal phrase', 'base noun phrase', 'base verb phrase', 'base location  phrase'] \n",
      "\t\t ['phrase', 'base noun phrase', 'base temporal phrase', 'base location phrase', 'base verb phrase']\n",
      "\t\t ['base noun phrase', 'base temporal phrase', 'base location phrase', 'base verb phrase']\n",
      "['computational branding analytics'] \n",
      "\t\t ['a', 'computational branding analytics']\n",
      "\t\t ['computational branding analytics']\n",
      "['Chunk'] \n",
      "\t\t ['Chunk']\n",
      "\t\t ['Chunk']\n",
      "['Recursive Neural Tensor Network'] \n",
      "\t\t ['to', 'a', 'Recursive Neural Tensor Network']\n",
      "\t\t ['Recursive Neural Tensor Network']\n",
      "['Large Dataset', 'Small Dataset'] \n",
      "\t\t ['a Small Dataset', 'a Large Dataset']\n",
      "\t\t ['Small Dataset', 'Large Dataset']\n",
      "[] \n",
      "\t\t [\"Nu ' (\", ')', 'Nu (', ')', '(', ')', \"Nu ' (\", ')', 'Nu (', ')', '(', '(', ')', \"' (\", ') ) (', ')']\n",
      "\t\t []\n",
      "['Wordnet first sense baseline'] \n",
      "\t\t ['in', 'Wordnet first sense']\n",
      "\t\t ['Wordnet first sense']\n",
      "['semantic role labeling'] \n",
      "\t\t ['semantic', 'semantic role labeling']\n",
      "\t\t ['semantic role labeling']\n",
      "['Association for Machine Translation in the Americas'] \n",
      "\t\t ['the', 'for Machine Translation in the Americas']\n",
      "\t\t ['for Machine Translation in the Americas']\n",
      "['selectional preferences'] \n",
      "\t\t ['selectional preferences', 'preferences', 'on']\n",
      "\t\t ['selectional preferences']\n",
      "['unlabeled attachment score', 'shared modifier', 'conjunct'] \n",
      "\t\t ['shared modifier', 'conjunct']\n",
      "\t\t ['shared modifier', 'conjunct']\n",
      "['Total', 'sentence', 'Relevant Links', 'Active Chain', 'Growth rate'] \n",
      "\t\t ['Number', 'Growth', 'of', 'sentence', 'of', 'Relevant Links', 'Number of Active Chains']\n",
      "\t\t ['Growth', 'sentence', 'Relevant Links', 'Number of Active Chains']\n",
      "['Chinese Treebank version 5.1', 'Penn Treebank'] \n",
      "\t\t ['Penn', 'Treebank', 'Chinese Treebank version 5.1', 'Chinese']\n",
      "\t\t ['Penn', 'Chinese Treebank version 5.1']\n",
      "['maximum entropy'] \n",
      "\t\t ['maximum entropy', 'a']\n",
      "\t\t ['maximum entropy']\n",
      "['Basic Additive'] \n",
      "\t\t ['Basic Additive']\n",
      "\t\t ['Basic Additive']\n",
      "['Script model + Concept clustering'] \n",
      "\t\t ['Concept clustering']\n",
      "\t\t ['Concept clustering']\n",
      "['classification accuracy'] \n",
      "\t\t ['classification accuracy']\n",
      "\t\t ['classification accuracy']\n",
      "['coordieatien ned apposition'] \n",
      "\t\t ['i', 't', 'd', 't', 'coordieatien ned apposition constructions', 'i']\n",
      "\t\t ['coordieatien ned apposition constructions']\n",
      "['Information Technology', 'Telecommunication Services', 'Consumer Staples'] \n",
      "\t\t ['for', 'Information Technology', 'Consumer Staples']\n",
      "\t\t ['Information Technology', 'Consumer Staples']\n",
      "['minimum squared error'] \n",
      "\t\t ['error', 'minimum squared error', 'in']\n",
      "\t\t ['minimum squared error']\n",
      "['false negative'] \n",
      "\t\t ['false negative']\n",
      "\t\t ['false negative']\n",
      "['noun phrase'] \n",
      "\t\t ['noun phrase', 'a']\n",
      "\t\t ['noun phrase']\n",
      "['substantif', 'article g~n&al', 'verbe'] \n",
      "\t\t ['article g~n & al', 'substantif', 'verbe']\n",
      "\t\t ['article g~n & al', 'substantif', 'verbe']\n",
      "['Hidden Markov Model'] \n",
      "\t\t ['a', 'Hidden Markov Model']\n",
      "\t\t ['Hidden Markov Model']\n",
      "['Pattern Analysis and Machine Intelligence'] \n",
      "\t\t ['Transactions on Pattern Analysis and Machine Intelligence']\n",
      "\t\t ['Transactions on Pattern Analysis and Machine Intelligence']\n",
      "['automatic speech recognition', 'machine translation'] \n",
      "\t\t ['in automatic speech recognition', 'statistical machine translation']\n",
      "\t\t ['in automatic speech recognition', 'statistical machine translation']\n",
      "['Interactive query expansion'] \n",
      "\t\t ['Interactive query expansion', 't']\n",
      "\t\t ['Interactive query expansion']\n",
      "['Multilayer Perceptro', 'Support Vector Machine', 'Decision Tree', 'AdaBoost'] \n",
      "\t\t ['Support Vector Machine', 'Multilayer Perceptron', 'Decision Trees', 'AdaBoost']\n",
      "\t\t ['Support Vector Machine', 'Multilayer Perceptron', 'Decision Trees', 'AdaBoost']\n",
      "['target condition'] \n",
      "\t\t ['condition', 'on']\n",
      "\t\t ['condition']\n",
      "['linear precedenc', 'immediate  dominance'] \n",
      "\t\t ['immediate dominance', 'linear precedence', 'a']\n",
      "\t\t ['immediate dominance', 'linear precedence']\n",
      "['Locality sensitive hashing'] \n",
      "\t\t ['sensitive hashing', 'is']\n",
      "\t\t ['sensitive hashing']\n",
      "['Hidden Vector State'] \n",
      "\t\t ['Vector State', 'a']\n",
      "\t\t ['Vector State']\n",
      "['Lexical Accuracy'] \n",
      "\t\t ['al', 'Lexical Accuracy', 'Lexical']\n",
      "\t\t ['Lexical Accuracy']\n",
      "['Translation'] \n",
      "\t\t ['Translation Correctness']\n",
      "\t\t ['Translation Correctness']\n",
      "['maximum likelihood estimator'] \n",
      "\t\t ['maximum likelihood estimator']\n",
      "\t\t ['maximum likelihood estimator']\n",
      "['Information gain'] \n",
      "\t\t ['for', 'Information gain', 'for']\n",
      "\t\t ['Information gain']\n",
      "['Word Formation Analogy', 'Independent Word Probability', 'Anti-Word Pair'] \n",
      "\t\t ['Independent', 'Word Probability', 'Anti-Word Pair', 'Word Formation Analogy']\n",
      "\t\t ['Independent', 'Word Probability', 'Anti-Word Pair', 'Word Formation Analogy']\n",
      "['Swedish FrameNet'] \n",
      "\t\t ['a', 'Swedish FrameNet', 'et']\n",
      "\t\t ['Swedish FrameNet']\n",
      "['location'] \n",
      "\t\t ['person', 'organization', 'location', 'geopolitical entity', 'facility', 'vehicle']\n",
      "\t\t ['person', 'organization', 'location', 'geopolitical entity', 'facility', 'vehicle']\n",
      "['RST Discourse Treebank'] \n",
      "\t\t ['RST Discourse Treebank']\n",
      "\t\t ['RST Discourse Treebank']\n",
      "['Referring Expression Generation'] \n",
      "\t\t ['Referring Expression Generation']\n",
      "\t\t ['Referring Expression Generation']\n",
      "['low attachment'] \n",
      "\t\t ['attachment', 'attachment']\n",
      "\t\t ['attachment', 'attachment']\n",
      "['question answering'] \n",
      "\t\t ['a', 'question answering']\n",
      "\t\t ['question answering']\n",
      "['preposition'] \n",
      "\t\t ['preposition feature', 'preposition']\n",
      "\t\t ['preposition feature']\n",
      "['Stochastic Segment Model'] \n",
      "\t\t ['a d', 'Stochastic Segment Model']\n",
      "\t\t ['Stochastic Segment Model']\n",
      "['Homogenous Poisson Process'] \n",
      "\t\t ['Homogenous Poisson Process', 'on']\n",
      "\t\t ['Homogenous Poisson Process']\n",
      "['Lexical Functional Grammar'] \n",
      "\t\t ['Lexical Functional Grammar', 'a']\n",
      "\t\t ['Lexical Functional Grammar']\n",
      "['Universal Theory'] \n",
      "\t\t ['a', 'The', 'Universal Theory', 'a']\n",
      "\t\t ['Universal Theory']\n",
      "['Text REtrieval Conferences'] \n",
      "\t\t ['o', 'Text REtrieval Conferences']\n",
      "\t\t ['Text REtrieval Conferences']\n",
      "['machine translation', 'natural language generation'] \n",
      "\t\t ['it', 'in', 'language', 'machine translation', 'a natural language generation', 'a']\n",
      "\t\t ['machine translation', 'natural language generation']\n",
      "['prEposition'] \n",
      "\t\t ['participe', 'prEposition', 'substamif']\n",
      "\t\t ['participe', 'prEposition', 'substamif']\n",
      "['Semantic Network', 'Metathesaurus'] \n",
      "\t\t ['the', 'the', 'Network', 'a', 'the']\n",
      "\t\t ['Network']\n",
      "['support vector machine', 'classifiers for detecting'] \n",
      "\t\t ['support vector machine', 'in']\n",
      "\t\t ['support vector machine']\n",
      "['Parsed syntactic structures', 'Conceptual structures'] \n",
      "\t\t ['Conceptual structures', 'syntactic structures']\n",
      "\t\t ['Conceptual structures', 'syntactic structures']\n",
      "['natural language processing', 'information extraction'] \n",
      "\t\t ['information extraction', 'natural language processing', 'for', 'in']\n",
      "\t\t ['information extraction', 'natural language processing']\n",
      "['unlabeled precision', 'unlabeled recall'] \n",
      "\t\t ['unlabeled precision', 'unlabeled recall']\n",
      "\t\t ['unlabeled precision', 'unlabeled recall']\n",
      "['Royal Spanish Academy', 'Computer Center of  the University of Madrid'] \n",
      "\t\t ['of the Spanish', 'a', 'of the Royal Spanish Academy', 'the Computer Center of the University of Madrid']\n",
      "\t\t ['of the Spanish', 'of the Royal Spanish Academy', 'the Computer Center of the University of Madrid']\n",
      "['strictly local'] \n",
      "\t\t ['strictly local']\n",
      "\t\t ['strictly local']\n",
      "['heritage'] \n",
      "\t\t []\n",
      "\t\t []\n",
      "['phrases'] \n",
      "\t\t ['tion', 'prepositional phrases', 'as']\n",
      "\t\t ['prepositional phrases']\n",
      "['Narrativ', 'Title', 'Number', 'Concepts'] \n",
      "\t\t ['Topic', 'Topic', 'Title', 'Topic', 'Topic Narrative', 'Topic']\n",
      "\t\t ['Title', 'Topic Narrative']\n",
      "['Continuous Match Valu'] \n",
      "\t\t ['MN/length', 'Continuous Match Value', 'Continuous']\n",
      "\t\t ['MN/length', 'Continuous Match Value']\n",
      "['weighted average'] \n",
      "\t\t ['a', 'a', 'weighted average']\n",
      "\t\t ['weighted average']\n",
      "['Chinese Restaurant Processes', 'Dirichlet Processes'] \n",
      "\t\t ['Chinese Restaurant Processes', 'Dirichlet Processes']\n",
      "\t\t ['Chinese Restaurant Processes', 'Dirichlet Processes']\n",
      "['maximum entropy'] \n",
      "\t\t ['a', 'maximum entropy']\n",
      "\t\t ['maximum entropy']\n",
      "['word error rate'] \n",
      "\t\t ['a', 'word error rate']\n",
      "\t\t ['word error rate']\n",
      "['conjunct verbs', 'junct verbs', 'Non-MonoClausal  Verbs', 'Auxiliary Construction'] \n",
      "\t\t ['junct', 'verbs', 'Non-MonoClausal Verbs', 'Auxiliary Construction', 'conjunct verbs']\n",
      "\t\t ['Non-MonoClausal Verbs', 'Auxiliary Construction', 'conjunct verbs']\n",
      "['Majority Rule', 'Na??veBayes classifier'] \n",
      "\t\t ['Na ? ? veBayes', 'Majority Rule']\n",
      "\t\t ['Na ? ? veBayes', 'Majority Rule']\n",
      "['Early Modern German'] \n",
      "\t\t ['Early Modern German']\n",
      "\t\t ['Early Modern German']\n",
      "['phrase structure grmmmar'] \n",
      "\t\t ['a', 'as', 'a', 'phrase structure grmmmar']\n",
      "\t\t ['phrase structure grmmmar']\n",
      "['HOO shared task of 2012'] \n",
      "\t\t ['shared', 'HOO shared task of 2012', 'CoNLL-2013 shared task']\n",
      "\t\t ['HOO shared task of 2012', 'CoNLL-2013 shared task']\n",
      "['Probabilistic Latent Semantic Analysis', 'Canonical Correlation Analysis'] \n",
      "\t\t ['on', 'Canonical Correlation Analysis', 'Probabilistic Latent Semantic Analysis']\n",
      "\t\t ['Canonical Correlation Analysis', 'Probabilistic Latent Semantic Analysis']\n",
      "['relative clause', 'infinitival clause'] \n",
      "\t\t ['infinitival', 'clause', 'a', 'embedded relative clause']\n",
      "\t\t ['infinitival', 'embedded relative clause']\n",
      "['conditional random fields', 'support vector machines', 'hidden Markov models'] \n",
      "\t\t ['and', 'models', 'support vector machines', 'conditional random fields', 'and hidden Markov models']\n",
      "\t\t ['support vector machines', 'conditional random fields', 'and hidden Markov models']\n",
      "['Most Frequent Sense'] \n",
      "\t\t ['Most Frequent Sense']\n",
      "\t\t ['Most Frequent Sense']\n",
      "['Named Entity Recognition'] \n",
      "\t\t ['a Named Entity Recognition']\n",
      "\t\t ['Named Entity Recognition']\n",
      "['term', 'intransitive verb'] \n",
      "\t\t ['a', 'verb phrase']\n",
      "\t\t ['verb phrase']\n",
      "['natural language processing'] \n",
      "\t\t ['a', 'in natural language processing']\n",
      "\t\t ['in natural language processing']\n",
      "['Language Resources'] \n",
      "\t\t ['Language Resources']\n",
      "\t\t ['Language Resources']\n",
      "['broadcast news'] \n",
      "\t\t ['a', 'broadcast news']\n",
      "\t\t ['broadcast news']\n",
      "['Detai l izat ion'] \n",
      "\t\t ['Detai l izat ion', 'a', 'i', 'ion', 'a', 'a', 's i']\n",
      "\t\t ['Detai l izat ion']\n",
      "[\"N='BYPASS':(SINGULAR\"] \n",
      "\t\t ['NPOS']\n",
      "\t\t ['NPOS']\n",
      "['Greedy String Tiling'] \n",
      "\t\t ['Greedy String Tiling']\n",
      "\t\t ['Greedy String Tiling']\n",
      "['California'] \n",
      "\t\t ['state', 'California : state']\n",
      "\t\t ['California : state']\n",
      "['support vector machine'] \n",
      "\t\t ['support vector machine']\n",
      "\t\t ['support vector machine']\n",
      "['Partial Least Squares Regression'] \n",
      "\t\t ['Partial Least Squares Regression', 'a']\n",
      "\t\t ['Partial Least Squares Regression']\n",
      "['Institute for Robotics and Intelligent Systems', 'Natural Sciences and Engineering Research Council'] \n",
      "\t\t ['is', 'a', 'Institute for Robotics and Intelligent Systems', 'and', 'e', 'Natural Sciences and Engineering Research']\n",
      "\t\t ['Institute for Robotics and Intelligent Systems', 'Natural Sciences and Engineering Research']\n",
      "['Chinese Treebank'] \n",
      "\t\t ['Chinese Treebank']\n",
      "\t\t ['Chinese Treebank']\n",
      "['Transactions on Information Systems'] \n",
      "\t\t ['a', 'Transactions on Information Systems']\n",
      "\t\t ['Transactions on Information Systems']\n",
      "['super abstract role value'] \n",
      "\t\t ['a', 'super abstract role value']\n",
      "\t\t ['super abstract role value']\n",
      "['Reduction Factor'] \n",
      "\t\t ['duction Factor', 'a', 'Reduction Factor', 'ion Factor', 'Reduction Factor', 'a', '( ss f', 'n (']\n",
      "\t\t ['Reduction Factor', 'Reduction Factor']\n",
      "['training', 'training'] \n",
      "\t\t ['training corpus', 'training corpus']\n",
      "\t\t ['training corpus', 'training corpus']\n",
      "['Maschinelle Syntaxanalyse'] \n",
      "\t\t ['Maschinelle Syntaxanalyse', 'a']\n",
      "\t\t ['Maschinelle Syntaxanalyse']\n",
      "['argument structure'] \n",
      "\t\t ['argument structure']\n",
      "\t\t ['argument structure']\n",
      "['human effort'] \n",
      "\t\t ['human effort']\n",
      "\t\t ['human effort']\n",
      "['object'] \n",
      "\t\t ['focus']\n",
      "\t\t ['focus']\n",
      "['Named Entity Time'] \n",
      "\t\t ['a', 'it', 'a', 'Named Entity Time']\n",
      "\t\t ['Named Entity Time']\n",
      "['machine translation'] \n",
      "\t\t ['translation', 'on']\n",
      "\t\t ['translation']\n",
      "['Machine Translation', 'Information Retrieval', 'Natural Language Processing'] \n",
      "\t\t ['in', 'Information Retrieval', 'Natural Language Processing', 'in', 'in', 'n', 'al', 'In Machine Translation', 'at', 'in', 'a']\n",
      "\t\t ['Information Retrieval', 'Natural Language Processing', 'In Machine Translation']\n",
      "['BioNLP Shared Task'] \n",
      "\t\t ['a', 'as', 'BioNLP Shared Task 2013', 'BioNLP 2013', 'a']\n",
      "\t\t ['BioNLP Shared Task 2013', 'BioNLP 2013']\n",
      "['European Conference on Information Retrieval'] \n",
      "\t\t ['In', 'European Conference on Information Retrieval']\n",
      "\t\t ['European Conference on Information Retrieval']\n",
      "['machine translation'] \n",
      "\t\t ['translation', 'machine translation']\n",
      "\t\t ['machine translation']\n",
      "['Syntactic Tree Kernels', 'syntactic tree fragments', 'partial tree fragments'] \n",
      "\t\t ['syntactic', 'tree fragments', 'partial tree fragments', 'Syntactic Tree Kernels', 'a']\n",
      "\t\t ['syntactic', 'partial tree fragments', 'Syntactic Tree Kernels']\n",
      "['past tense'] \n",
      "\t\t ['Finite', 'in']\n",
      "\t\t ['Finite']\n",
      "['Gene Ontology'] \n",
      "\t\t ['Gene Ontology', 'to']\n",
      "\t\t ['Gene Ontology']\n",
      "['Minimum Bayes Risk'] \n",
      "\t\t ['Minimum Bayes Risk', 'in', 'in', 'a']\n",
      "\t\t ['Minimum Bayes Risk']\n",
      "['coreference resolution'] \n",
      "\t\t ['coreference resolution']\n",
      "\t\t ['coreference resolution']\n",
      "['Spontaneous  Scheduling Task'] \n",
      "\t\t ['Spontaneous Scheduling Task']\n",
      "\t\t ['Spontaneous Scheduling Task']\n",
      "['Wagner & Fischer'] \n",
      "\t\t ['Wagner & Fischer', '& F']\n",
      "\t\t ['Wagner & Fischer']\n",
      "['Longest Common Subsequenc'] \n",
      "\t\t ['Longest Common Subsequence']\n",
      "\t\t ['Longest Common Subsequence']\n",
      "['ocator'] \n",
      "\t\t ['locator', ', finder , location ,']\n",
      "\t\t ['locator', 'inde', 'ocatio']\n",
      "['Brown Laboratory for Linguistic Information Processing'] \n",
      "\t\t ['Laboratory for Linguistic Information Processing']\n",
      "\t\t ['Laboratory for Linguistic Information Processing']\n",
      "['2*P*R', 'precision', 'recall'] \n",
      "\t\t ['is precision', 'is recall', 'is', 'precision', 'a', 'a']\n",
      "\t\t ['is precision', 'is recall']\n",
      "['Similarity Core task'] \n",
      "\t\t ['Similarity', 'Semantic Textual Similarity Core']\n",
      "\t\t ['Semantic Textual Similarity Core']\n",
      "['broadcasting news', 'broadcasting conversation', 'magazine', 'newswire'] \n",
      "\t\t ['broadcasting conversation', 'broadcasting', 'news', 'Sinorama news magazine', 'newswire']\n",
      "\t\t ['broadcasting conversation', 'Sinorama news magazine', 'newswire']\n",
      "['Tree Adjoining Grammar'] \n",
      "\t\t ['Tree Adjoining Grammar', 'a Tree Adjoining Grammar']\n",
      "\t\t ['Tree Adjoining Grammar']\n",
      "['language mode'] \n",
      "\t\t ['a', 'language model']\n",
      "\t\t ['language model']\n",
      "['Chinese Lexical Ontology'] \n",
      "\t\t ['Chinese', 'to', 'Chinese Lexical Ontology']\n",
      "\t\t ['Chinese Lexical Ontology']\n",
      "['Bernoulli Naive Bayes', 'Stochastic Gradient Descent'] \n",
      "\t\t ['Stochastic Gradient Descent', 'hinge loss Bernoulli Naive Bayes']\n",
      "\t\t ['Stochastic Gradient Descent', 'hinge loss Bernoulli Naive Bayes']\n",
      "['address changes to Betty Walker'] \n",
      "\t\t ['Betty Walker']\n",
      "\t\t ['Betty Walker']\n",
      "['nition'] \n",
      "\t\t ['named entity recognition']\n",
      "\t\t ['named entity recognition']\n",
      "['Warning Order - Method of Fire'] \n",
      "\t\t ['s', 'a Warning Order - Method of Fire', 'of']\n",
      "\t\t ['Warning Order - Method of Fire']\n",
      "['CONTEXT SPACES'] \n",
      "\t\t ['CONTEXT SPACES']\n",
      "\t\t ['CONTEXT SPACES']\n",
      "['Maximum Entropy', 'Na??ve Bayes', 'Support Vector Machines'] \n",
      "\t\t ['Na ? ? ve Bayes', 'Maximum Entropy', 'Support Vector Machines']\n",
      "\t\t ['Na ? ? ve Bayes', 'Maximum Entropy', 'Support Vector Machines']\n",
      "['Basic Elements'] \n",
      "\t\t ['Basic Elements']\n",
      "\t\t ['Basic Elements']\n",
      "['Sistema'] \n",
      "\t\t ['Sistema de Escritura Alfab ? tica']\n",
      "\t\t ['Sistema de Escritura Alfab ? tica']\n",
      "['computing elements'] \n",
      "\t\t ['a', 'a', '8 computing elements', 'in']\n",
      "\t\t ['8 computing elements']\n",
      "['of Unithood'] \n",
      "\t\t ['Odds of Unithood', 'a']\n",
      "\t\t ['Odds of Unithood']\n",
      "['Word sense disambiguation'] \n",
      "\t\t ['sense disambiguation', 'is', 'at']\n",
      "\t\t ['sense disambiguation']\n",
      "['machine translation system'] \n",
      "\t\t ['a', 'system', 'a machine translation system', 'a']\n",
      "\t\t ['machine translation system']\n",
      "['transcripts', 'text'] \n",
      "\t\t ['text', 'a scoring function']\n",
      "\t\t ['text', 'scoring function']\n",
      "['linear precedence', 'domain'] \n",
      "\t\t ['a', 'a', 'linear precedence']\n",
      "\t\t ['linear precedence']\n",
      "['deterministic tree automaton'] \n",
      "\t\t ['i', 't ion', 'deterministic tree automaton', 'is a', 'is a']\n",
      "\t\t ['deterministic tree automaton']\n",
      "['Profile Hidden Markov Model'] \n",
      "\t\t ['Model', 'Profile Hidden Markov Model']\n",
      "\t\t ['Profile Hidden Markov Model']\n",
      "['linear precedenc'] \n",
      "\t\t ['linear precedence', 'immediate dominance']\n",
      "\t\t ['linear precedence', 'immediate dominance']\n",
      "['factorial CRF'] \n",
      "\t\t ['CRF']\n",
      "\t\t []\n",
      "['Word sense disambiguation'] \n",
      "\t\t ['sense disambiguation', 'is a']\n",
      "\t\t ['sense disambiguation']\n",
      "['discourse units'] \n",
      "\t\t ['discourse units']\n",
      "\t\t ['discourse units']\n",
      "['bag of words'] \n",
      "\t\t ['a bag of words', 'of', 'of']\n",
      "\t\t ['bag of words']\n",
      "['Natural Language Processing'] \n",
      "\t\t ['a', 'Natural Language Processing', 'in']\n",
      "\t\t ['Natural Language Processing']\n",
      "['Document Type Definition'] \n",
      "\t\t ['in', 'Document Type Definition']\n",
      "\t\t ['Document Type Definition']\n",
      "['syntactic structure'] \n",
      "\t\t ['a syntactic structure']\n",
      "\t\t ['syntactic structure']\n",
      "['hashtag pattern', 'hashtag'] \n",
      "\t\t ['hashtag', 'hashtag pattern']\n",
      "\t\t ['hashtag pattern']\n",
      "['Document Understanding Conference'] \n",
      "\t\t ['on', 'in', 'Document Understanding Conference']\n",
      "\t\t ['Document Understanding Conference']\n",
      "['Information Retrieval'] \n",
      "\t\t ['Information Retrieval']\n",
      "\t\t ['Information Retrieval']\n",
      "['Independent Random Projections'] \n",
      "\t\t ['a', 'Independent Random Projections', 'In']\n",
      "\t\t ['Independent Random Projections']\n",
      "['restriction'] \n",
      "\t\t ['a', 'or is a quantifier whose', 'is']\n",
      "\t\t ['or is a quantifier whose']\n",
      "['wN'] \n",
      "\t\t []\n",
      "\t\t []\n",
      "['Multilingual Text'] \n",
      "\t\t ['Multilingual Text', 'Fools and Corpora', 'in']\n",
      "\t\t ['Multilingual Text', 'Fools and Corpora']\n",
      "['Computational Linguistics'] \n",
      "\t\t ['on Computational Linguistics']\n",
      "\t\t ['on Computational Linguistics']\n",
      "['Information Retrieval'] \n",
      "\t\t ['at', 'a', 'In', 'Information Retrieval']\n",
      "\t\t ['Information Retrieval']\n",
      "['amed Entity'] \n",
      "\t\t ['Entity Recognition']\n",
      "\t\t ['Entity Recognition']\n",
      "['correct BP'] \n",
      "\t\t ['precision']\n",
      "\t\t ['precision']\n",
      "['speaker independent', 'speaker adaptive'] \n",
      "\t\t ['a', 'in', 'speaker independent', 'speaker adaptive']\n",
      "\t\t ['speaker independent', 'speaker adaptive']\n",
      "['node link'] \n",
      "\t\t ['node link', 'node']\n",
      "\t\t ['node link']\n",
      "['statistical machine translation'] \n",
      "\t\t ['translation', 'translation', 'translation on', 'statistical machine translation']\n",
      "\t\t ['translation on', 'statistical machine translation']\n",
      "['named entity recognition'] \n",
      "\t\t ['named entity recognition']\n",
      "\t\t ['named entity recognition']\n",
      "['target order', 'finally'] \n",
      "\t\t ['target order']\n",
      "\t\t ['target order']\n",
      "['rel loc'] \n",
      "\t\t ['prep rel', 'loc word', 'word', 'loc word']\n",
      "\t\t ['prep rel', 'loc word', 'loc word']\n",
      "['Oxford Pictorial English Dictionar'] \n",
      "\t\t ['o', 'Oxford Pictorial English Dictionary']\n",
      "\t\t ['Oxford Pictorial English Dictionary']\n",
      "['Domain Verb Association'] \n",
      "\t\t ['on', 'Domain Verb Association']\n",
      "\t\t ['Domain Verb Association']\n",
      "['Bhattacharyya coefficient'] \n",
      "\t\t ['Shannon divergence', 'Bhattacharyya coefficient']\n",
      "\t\t ['Shannon divergence', 'Bhattacharyya coefficient']\n",
      "['Words as Words'] \n",
      "\t\t ['Words as Words']\n",
      "\t\t ['Words as Words']\n",
      "['Arabic Language Technologies', 'Qatar Computing Research Institute'] \n",
      "\t\t ['Arabic Language Technologies', 'at Qatar Computing Research Institute', 'Qatar', 'in']\n",
      "\t\t ['Arabic Language Technologies', 'at Qatar Computing Research Institute']\n",
      "['Word Sense Disambiguatio'] \n",
      "\t\t ['s', 'a Word Sense Disambiguation']\n",
      "\t\t ['Word Sense Disambiguation']\n",
      "['subject matter experts'] \n",
      "\t\t ['subject matter experts', 'a']\n",
      "\t\t ['subject matter experts']\n",
      "['development set'] \n",
      "\t\t ['development']\n",
      "\t\t ['development']\n",
      "['Compound nouns'] \n",
      "\t\t ['Compound', 'Compound nouns']\n",
      "\t\t ['Compound nouns']\n",
      "['dictionary'] \n",
      "\t\t []\n",
      "\t\t []\n",
      "['limited memory BFGS'] \n",
      "\t\t ['limited memory BFGS']\n",
      "\t\t ['limited memory BFGS']\n",
      "['Indirect Object', 'Direct Object', 'Subject', 'Verb', 'Ergative', 'Dative'] \n",
      "\t\t ['Object', 'Object']\n",
      "\t\t ['Object', 'Object']\n",
      "['Speaker', 'Friendship', 'Visibility', 'Route'] \n",
      "\t\t ['Speaker', 'Visibility', 'Route']\n",
      "\t\t ['Speaker', 'Visibility', 'Route']\n",
      "['Combinatory Categorial Grammar'] \n",
      "\t\t ['a', 'Combinatory Categorial Grammar', 'Grammar']\n",
      "\t\t ['Combinatory Categorial Grammar']\n",
      "['Pacific Asia  Conference on Language, Information and Com-  putation'] \n",
      "\t\t ['In', ',', 'on', ', Information and Com- putation', ',']\n",
      "\t\t ['nformation and Com- putation']\n",
      "[] \n",
      "\t\t []\n",
      "\t\t []\n",
      "['original candidate list'] \n",
      "\t\t ['original candidate list']\n",
      "\t\t ['original candidate list']\n",
      "['Subject', 'Object', 'Arguments', 'Indirect Object'] \n",
      "\t\t ['In', 'Arguments', 'Subject', 'Object', 'Indirect Object', 'Indirect']\n",
      "\t\t ['Arguments', 'Subject', 'Indirect Object']\n",
      "['Akaike Information Criterion'] \n",
      "\t\t ['a', 'In', 'Akaike Information Criterion', 'a', 'Akaike']\n",
      "\t\t ['Akaike Information Criterion']\n",
      "['Logical Graph'] \n",
      "\t\t ['Logical Graph', 'a']\n",
      "\t\t ['Logical Graph']\n",
      "['Abbreviation'] \n",
      "\t\t []\n",
      "\t\t []\n",
      "['language mode'] \n",
      "\t\t ['language model']\n",
      "\t\t ['language model']\n",
      "['linear order subgraph', 'parse structure subgraph'] \n",
      "\t\t ['a', 'structure subgraph', 'a', 'order subgraph']\n",
      "\t\t ['structure subgraph', 'order subgraph']\n",
      "['0fiice of Science and Technology Policy', 'Intergovernmental  Science, Engineering, and Technology Advisory Pane'] \n",
      "\t\t ['o f', 'w i', 't h i n', 'of Telecommmicatians Policy', 'of Science and Technology Policy', 'Science , Engineering , and Technology Advisory Panel']\n",
      "\t\t ['of Telecommmicatians Policy', 'of Science and Technology Policy', 'ngineerin', 'nd Technology Advisory Panel']\n",
      "['computing surveys'] \n",
      "\t\t ['in', 'computing surveys']\n",
      "\t\t ['computing surveys']\n",
      "['noun phrases'] \n",
      "\t\t ['noun phrases', 'pronouns', 'pronouns']\n",
      "\t\t ['noun phrases', 'pronouns', 'pronouns']\n",
      "['Web of Science'] \n",
      "\t\t ['s', 'Web of Science', 'of']\n",
      "\t\t ['Web of Science']\n",
      "['text mining', 'information extraction'] \n",
      "\t\t ['in', 'extraction', 'mining']\n",
      "\t\t ['extraction', 'mining']\n",
      "['Determiner', 'Preposition', 'Noun', 'Plural Noun', 'Possessive', 'Adjective'] \n",
      "\t\t ['Noun', 'Plural Noun', 'Determiner', 'Preposition', 'Possessive']\n",
      "\t\t ['Plural Noun', 'Determiner', 'Preposition', 'Possessive']\n",
      "['Computer Vision and Pattern Recognition'] \n",
      "\t\t ['Conference', 'on Computer Vision and Pattern Recognition']\n",
      "\t\t ['Conference', 'on Computer Vision and Pattern Recognition']\n",
      "['Microelectronics', 'F-Measure', 'Japanese', 'Spanish'] \n",
      "\t\t ['F', 'with Recall', 'Weighted Equally', 'Japanese', 'S', 'Spanish', 'Microelectronics', 't i l']\n",
      "\t\t ['with Recall', 'Weighted Equally', 'Japanese', 'Spanish', 'Microelectronics']\n",
      "['GREC Named Entity Generation', 'Named Entity Reference Regeneration'] \n",
      "\t\t ['Generation', 'GREC', 'GREC Named Entity Generation', 'Named Entity Reference Detection', 'Named Entity Reference']\n",
      "\t\t ['GREC Named Entity Generation', 'Named Entity Reference Detection']\n",
      "['Selectional Preferences'] \n",
      "\t\t ['Selectional Preferences', 'in']\n",
      "\t\t ['Selectional Preferences']\n",
      "['lexical cohesion', 'repetition / content'] \n",
      "\t\t ['lexical cohesion', 'lexical cohesion', '/ content', 'repetition / content']\n",
      "\t\t ['lexical cohesion', 'lexical cohesion', 'repetition / content']\n",
      "['Empirical Methods in Natural Language Processing'] \n",
      "\t\t ['Methods in Natural Language Processing (']\n",
      "\t\t ['Methods in Natural Language Processing (']\n",
      "['Wathctower Society'] \n",
      "\t\t ['Wathctower Society']\n",
      "\t\t ['Wathctower Society']\n",
      "['deep averaging network'] \n",
      "\t\t ['an', 'deep averaging network', 'in']\n",
      "\t\t ['deep averaging network']\n",
      "['Web Person Search'] \n",
      "\t\t ['Web Person Search']\n",
      "\t\t ['Web Person Search']\n",
      "['independent verification and validation'] \n",
      "\t\t ['In', 'independent verification and validation', 'a']\n",
      "\t\t ['independent verification and validation']\n",
      "['machine translation'] \n",
      "\t\t ['a machine translation']\n",
      "\t\t ['machine translation']\n",
      "['National Research Foundation'] \n",
      "\t\t ['a', 'Research Foundation']\n",
      "\t\t ['Research Foundation']\n",
      "['statistical machine translation'] \n",
      "\t\t ['a statistical machine translation', 'at', 'in']\n",
      "\t\t ['statistical machine translation']\n",
      "['Log frequency', 'global entropy'] \n",
      "\t\t ['Log frequency', 'global entropy']\n",
      "\t\t ['Log frequency', 'global entropy']\n",
      "['agent semantic communications service'] \n",
      "\t\t ['agent semantic communications service']\n",
      "\t\t ['agent semantic communications service']\n",
      "['bag of words'] \n",
      "\t\t ['is', 'a', 'bag of words']\n",
      "\t\t ['bag of words']\n",
      "['same'] \n",
      "\t\t ['the', 'the', 'the', 'the', 'the']\n",
      "\t\t []\n",
      "['Index Thomisticus Treebank'] \n",
      "\t\t ['Index Thomisticus Treebank']\n",
      "\t\t ['Index Thomisticus Treebank']\n",
      "['Optimality Theory'] \n",
      "\t\t ['a', 'Optimality Theory', 'a']\n",
      "\t\t ['Optimality Theory']\n",
      "['True Negatives', 'False Negatives', 'True Positives', 'False Positives'] \n",
      "\t\t ['True Positives', 'False Positives', 'True Negatives', 'False Negatives', 'a']\n",
      "\t\t ['True Positives', 'False Positives', 'True Negatives', 'False Negatives']\n",
      "['Conditional Random Field'] \n",
      "\t\t ['Conditional Random Field']\n",
      "\t\t ['Conditional Random Field']\n",
      "['natural language', 'speech recognition', 'speech understanding'] \n",
      "\t\t ['in', 'speech recognition', 'natural language', 'or speech understanding']\n",
      "\t\t ['speech recognition', 'natural language', 'or speech understanding']\n",
      "['mean absolute difference'] \n",
      "\t\t ['man', 'mean absolute difference', 'a']\n",
      "\t\t ['mean absolute difference']\n",
      "['World Wide Web'] \n",
      "\t\t ['World Wide Web']\n",
      "\t\t ['World Wide Web']\n",
      "['Shakti Standard Format'] \n",
      "\t\t ['Standard Format']\n",
      "\t\t ['Standard Format']\n",
      "['Lexical Knowledge Bases'] \n",
      "\t\t ['a', 'Lexical Knowledge Bases']\n",
      "\t\t ['Lexical Knowledge Bases']\n",
      "['Simple recurrent networks'] \n",
      "\t\t ['networks', 'recurrent networks']\n",
      "\t\t ['recurrent networks']\n",
      "['machine translation'] \n",
      "\t\t ['in', 'machine translation']\n",
      "\t\t ['machine translation']\n",
      "['Document Input'] \n",
      "\t\t ['Input']\n",
      "\t\t ['Input']\n",
      "['Median Selection'] \n",
      "\t\t ['Median Selection', 'a']\n",
      "\t\t ['Median Selection']\n",
      "['dynamic programming'] \n",
      "\t\t ['in', 'dynamic programming']\n",
      "\t\t ['dynamic programming']\n",
      "['International Conference on Learning Representations'] \n",
      "\t\t ['In International Conference on Learning Representations']\n",
      "\t\t ['In International Conference on Learning Representations']\n",
      "['Discovering Inference Rules from Text'] \n",
      "\t\t ['Inference Rules from Text )', 'on']\n",
      "\t\t ['Inference Rules from Text )']\n",
      "['Conditional random field', 'Maximum Entropy Model'] \n",
      "\t\t ['Conditional', 'random field', 'an', 'Maximum Entropy Model']\n",
      "\t\t ['Conditional', 'random field', 'Maximum Entropy Model']\n",
      "['and potentially some'] \n",
      "\t\t []\n",
      "\t\t []\n",
      "['automatic speech recognition'] \n",
      "\t\t ['in automatic speech recognition']\n",
      "\t\t ['in automatic speech recognition']\n",
      "['Semantic Role Labeling'] \n",
      "\t\t ['in', 'a', 'Semantic Role Labeling', 'a', 'a']\n",
      "\t\t ['Semantic Role Labeling']\n",
      "['Main Verbs'] \n",
      "\t\t ['i', 'Main Verbs']\n",
      "\t\t ['Main Verbs']\n",
      "['Resource Description Framework'] \n",
      "\t\t ['Resource Description Framework']\n",
      "\t\t ['Resource Description Framework']\n",
      "['Background', 'Result', 'Objective', 'Method', 'Conclusion'] \n",
      "\t\t ['Results', 'is', 'Background', 'Objective', 'Method', 'Conclusion']\n",
      "\t\t ['Results', 'Background', 'Objective', 'Method', 'Conclusion']\n",
      "['Wall Street Journal'] \n",
      "\t\t ['Wall Street Journal']\n",
      "\t\t ['Wall Street Journal']\n",
      "['Gay', 'Obama', 'Abortion', 'Marijuana'] \n",
      "\t\t ['Abortion', 'Gay Rights', 'Obama', 'Marijuana']\n",
      "\t\t ['Abortion', 'Gay Rights', 'Obama', 'Marijuana']\n",
      "['ANTEST CALLED'] \n",
      "\t\t ['S', 'CALLED', \"1 I ANTEST CALLED FOR 4l ' I\"]\n",
      "\t\t [\"1 I ANTEST CALLED FOR 4l ' I\"]\n",
      "['Great Britain', 'British National Corpus', 'P,,nnsylvania'] \n",
      "\t\t ['Great Britain component', 'British National Corpus', 'in']\n",
      "\t\t ['Great Britain component', 'British National Corpus']\n",
      "['Beginning of a', 'Beginning of non committed belief chunk', 'Inside of a non committed belief chunk', 'Inside a not applicable'] \n",
      "\t\t ['Beginning of non committed belief', 'Inside of a non committed belief', 'Beginning of a not applicable']\n",
      "\t\t ['Beginning of non committed belief', 'Inside of a non committed belief', 'Beginning of a not applicable']\n",
      "['British National Corpus'] \n",
      "\t\t ['British National Corpus']\n",
      "\t\t ['British National Corpus']\n",
      "['Underspecified Segmented Discourse Representation Theory'] \n",
      "\t\t ['Segmented Discourse Representation Theory']\n",
      "\t\t ['Segmented Discourse Representation Theory']\n",
      "['Turkish Discourse Bank', 'Penn Discourse Tree Bank'] \n",
      "\t\t ['Turkish Discourse Bank', 'Penn Discourse Tree Bank', 'Turkish', 'a']\n",
      "\t\t ['Turkish Discourse Bank', 'Penn Discourse Tree Bank']\n",
      "['Natural Language Processing'] \n",
      "\t\t ['in', 'in', 'an', 'in a', 'Natural Language Processing']\n",
      "\t\t ['Natural Language Processing']\n",
      "['language model'] \n",
      "\t\t ['model', 'a', 'language model']\n",
      "\t\t ['language model']\n",
      "['language model'] \n",
      "\t\t ['language model', 'an', 'language model', 'a']\n",
      "\t\t ['language model', 'language model']\n",
      "['knowledge base'] \n",
      "\t\t ['a', 'a', 'a knowledge base', 'a morphological nalyzer', 'a']\n",
      "\t\t ['knowledge base', 'morphological nalyzer']\n",
      "['is worth noting'] \n",
      "\t\t ['worth noting']\n",
      "\t\t ['worth noting']\n",
      "['locus'] \n",
      "\t\t ['locus']\n",
      "\t\t ['locus']\n",
      "['NIF Standard'] \n",
      "\t\t ['and', 'a', 'and', 'NIF Standard', 'and', 'and']\n",
      "\t\t ['NIF Standard']\n",
      "['Same Sentence', 'Previous Sentence', 'precision'] \n",
      "\t\t ['Same', 'Sentence', 'Previous Sentence', 'precision']\n",
      "\t\t ['Same', 'Previous Sentence', 'precision']\n",
      "['noun phrase'] \n",
      "\t\t ['phrase', 'noun', 'noun phrase']\n",
      "\t\t ['noun phrase']\n",
      "['Minimum error rate training'] \n",
      "\t\t ['error rate training', 'in']\n",
      "\t\t ['error rate training']\n",
      "['temporal expression', 'trigger term', 'verb'] \n",
      "\t\t ['a', 'temporal expression', 'trigger term']\n",
      "\t\t ['temporal expression', 'trigger term']\n",
      "['Named Entities'] \n",
      "\t\t ['Entities', 'a']\n",
      "\t\t ['Entities']\n",
      "['language model'] \n",
      "\t\t ['a', 'an', 'a', 'a language model', 'a', 'a']\n",
      "\t\t ['language model']\n",
      "['named entity', 'CoNLL'] \n",
      "\t\t ['named entity']\n",
      "\t\t ['named entity']\n",
      "['Princeton Wordnet'] \n",
      "\t\t ['in', 'Princeton Wordnet', 'n', 'or']\n",
      "\t\t ['Princeton Wordnet']\n",
      "['information retrieval', 'Question Answering'] \n",
      "\t\t ['Question Answering', 'or', 'information retrieval']\n",
      "\t\t ['Question Answering', 'information retrieval']\n",
      "['Prefix Counted'] \n",
      "\t\t ['Prefix Counted Rule']\n",
      "\t\t ['Prefix Counted Rule']\n",
      "['Segment frequency'] \n",
      "\t\t ['a', 'Segment frequency']\n",
      "\t\t ['Segment frequency']\n",
      "['latent semantic analysis'] \n",
      "\t\t ['latent semantic analysis', 'al']\n",
      "\t\t ['latent semantic analysis']\n",
      "['inflectional groups'] \n",
      "\t\t ['r', 'r', 'al', 'inflectional groups', 'a']\n",
      "\t\t ['inflectional groups']\n",
      "['Shallow Semantic Tree Kernel'] \n",
      "\t\t ['a', 'Shallow Semantic Tree Kernel']\n",
      "\t\t ['Shallow Semantic Tree Kernel']\n",
      "['interlingual index'] \n",
      "\t\t ['interlingual index']\n",
      "\t\t ['interlingual index']\n",
      "['Previous', 'Main verb', 'Boolean feature for MV'] \n",
      "\t\t ['Boolean', 'for MV', 'Previous', 'sentence', 'for']\n",
      "\t\t ['Boolean', 'Previous', 'sentence']\n",
      "['Generalized Expectation'] \n",
      "\t\t ['Generalized Expectation']\n",
      "\t\t ['Generalized Expectation']\n",
      "['itlll pluase eltil'] \n",
      "\t\t []\n",
      "\t\t []\n",
      "['United List of Artist Names)17'] \n",
      "\t\t ['United List of Artist', 'of']\n",
      "\t\t ['United List of Artist']\n",
      "['referential net'] \n",
      "\t\t ['a', 'referential net']\n",
      "\t\t ['referential net']\n",
      "[] \n",
      "\t\t []\n",
      "\t\t []\n",
      "['FARABUIDO MARTI NATIONAL LIBERATION'] \n",
      "\t\t ['A', 'MARTI NATIONAL']\n",
      "\t\t ['MARTI NATIONAL']\n",
      "['position independent'] \n",
      "\t\t ['error rate', 'independent']\n",
      "\t\t ['error rate', 'independent']\n",
      "['label propagation'] \n",
      "\t\t ['a label propagation']\n",
      "\t\t ['label propagation']\n",
      "['Community question answering'] \n",
      "\t\t ['question answering', 'question']\n",
      "\t\t ['question answering']\n",
      "['newswire', 'broadcast news', 'broadcast conversation'] \n",
      "\t\t ['a', 'newswire', 'broadcast news', 'broadcast conversation']\n",
      "\t\t ['newswire', 'broadcast news', 'broadcast conversation']\n",
      "['viewpoint'] \n",
      "\t\t ['a', 'viewpoint']\n",
      "\t\t ['viewpoint']\n",
      "['anaphora resolution'] \n",
      "\t\t ['an', 'anaphora resolution']\n",
      "\t\t ['anaphora resolution']\n",
      "['FrameNet'] \n",
      "\t\t ['FrameNet']\n",
      "\t\t ['FrameNet']\n",
      "['part of speech'] \n",
      "\t\t ['part of speech']\n",
      "\t\t ['part of speech']\n",
      "['part of speech'] \n",
      "\t\t ['a', 'part of speech']\n",
      "\t\t ['part of speech']\n",
      "['Phonetic', 'Symbols', 'Spelling'] \n",
      "\t\t ['Phonetic/Sound', 'Spelling']\n",
      "\t\t ['Phonetic/Sound', 'Spelling']\n",
      "['Radiology and', 'Discharge Summary', 'Echocardiogram', 'Emergency Department', 'Gastrointestinal', 'Surgical Pathology'] \n",
      "\t\t ['Discharge Summary', 'Echo', 'Echocardiogram', 'Emergency Department', 'Operative', 'Gastrointestinal', 'Radiology', 'Surgical Pathology']\n",
      "\t\t ['Discharge Summary', 'Echocardiogram', 'Emergency Department', 'Operative', 'Gastrointestinal', 'Radiology', 'Surgical Pathology']\n",
      "['overt displays'] \n",
      "\t\t ['overt displays of power', 'in']\n",
      "\t\t ['overt displays of power']\n",
      "['facility', 'organization', 'geo-political entity', 'weapon', 'vehicle', 'location'] \n",
      "\t\t ['organization', 'geo-political entity', 'weapon', 'vehicle', 'location', 'facility']\n",
      "\t\t ['organization', 'geo-political entity', 'weapon', 'vehicle', 'location', 'facility']\n",
      "['machine translation'] \n",
      "\t\t ['a', 'machine translation', 'on', 'a']\n",
      "\t\t ['machine translation']\n",
      "['Double Levenshtein?s Edit Distance'] \n",
      "\t\t ['is a', 'Levenshtein ? s Edit Distance']\n",
      "\t\t ['Levenshtein ? s Edit Distance']\n",
      "['Modified Head Grammars'] \n",
      "\t\t ['s', 'Modified Head Grammars']\n",
      "\t\t ['Modified Head Grammars']\n",
      "['concept sequence instances'] \n",
      "\t\t ['concept sequence instances']\n",
      "\t\t ['concept sequence instances']\n",
      "['Transformation Based Learning'] \n",
      "\t\t ['Transformation Based Learning']\n",
      "\t\t ['Transformation Based Learning']\n",
      "['Maximum Entropy'] \n",
      "\t\t ['Maximum Entropy', 'a']\n",
      "\t\t ['Maximum Entropy']\n",
      "['Class Speaker HMM'] \n",
      "\t\t ['a', 'hidden Markov', 'HMM', 'Class Speaker HMM']\n",
      "\t\t ['hidden Markov', 'Class Speaker HMM']\n",
      "['Chieu and Ng', 'Florian'] \n",
      "\t\t ['Florian', 'and', 'Chieu and Ng']\n",
      "\t\t ['Florian', 'Chieu and Ng']\n",
      "['Question Answering'] \n",
      "\t\t ['Answering']\n",
      "\t\t ['Answering']\n",
      "['Empirical Methods in Natural Language Processing'] \n",
      "\t\t ['Empirical Methods in Natural Language Processing']\n",
      "\t\t ['Empirical Methods in Natural Language Processing']\n",
      "['Knowledge Base'] \n",
      "\t\t ['Knowledge Base', 'a']\n",
      "\t\t ['Knowledge Base']\n",
      "['abstracts', 'titles', 'authors', 'Journals'] \n",
      "\t\t ['th', 'representations abstracts', 'titles', 'authors', 'Journals']\n",
      "\t\t ['representations abstracts', 'titles', 'authors', 'Journals']\n",
      "['learning to rank'] \n",
      "\t\t ['a', 'to rank', 'in']\n",
      "\t\t ['to rank']\n",
      "['Topic models'] \n",
      "\t\t ['Topic models', 'a']\n",
      "\t\t ['Topic models']\n",
      "['Automatic Genre Classification'] \n",
      "\t\t ['a', 'Automatic Topic Classification', 'Automatic Genre Classification']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t ['Automatic Topic Classification', 'Automatic Genre Classification']\n",
      "['Omission Rate'] \n",
      "\t\t ['Omission Rate']\n",
      "\t\t ['Omission Rate']\n",
      "['noun', 'adjectives', 'name'] \n",
      "\t\t ['match', 'noun', 'noun', 'name']\n",
      "\t\t ['match', 'noun', 'noun', 'name']\n",
      "['Sentence Position Yield'] \n",
      "\t\t ['Sentence Position Yield']\n",
      "\t\t ['Sentence Position Yield']\n",
      "['inflectional property sets'] \n",
      "\t\t ['inflectional property sets', 'inflectional']\n",
      "\t\t ['inflectional property sets']\n"
     ]
    }
   ],
   "source": [
    "# improved function\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "#en_stop_words = set(stopwords.words('english'))\n",
    "en_stop_words = (stopwords.words('english'))\n",
    "sw = ['is a', 'and a', 'and', 'on a', 'is'] # added some other words\n",
    "stop_words = en_stop_words +sw\n",
    "\n",
    "\n",
    "# df = pd.read_csv('eng_scientific_dev_xb_512.tsv', sep='\\t')\n",
    "\n",
    "def string_to_list(string):\n",
    "    return [e.strip()[1:-1] for e in string[1:-1].split(\",\")]\n",
    "\n",
    "def get_reduced_list(pred_list):\n",
    "    new_lf_pred = []\n",
    "   \n",
    "    for form1 in string_to_list(pred_list):        \n",
    "        flag = True                \n",
    "        \n",
    "        if not [x for x in form1.split() if x not in stop_words and len(x) > 3]: # deleted words that are less than 3 char\n",
    "            continue\n",
    "        \n",
    "        for form2 in string_to_list(pred_list):            \n",
    "            if form1 == form2: \n",
    "                continue\n",
    "        \n",
    "            if form1 in form2:\n",
    "                flag = False\n",
    "                break\n",
    "                \n",
    "        if flag: \n",
    "            new_lf_pred.append(form1)\n",
    "            \n",
    "    return clean_stops_inform(new_lf_pred)\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    print(row[\"long-forms-text\"], \"\\n\\t\\t\", row[\"LF_Pred\"])\n",
    "    print(\"\\t\\t\", get_reduced_list(row[\"LF_Pred\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare to Constantin function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Text Data Mining'] \n",
      "\t\t ['a', 'Text Data Mining']\n",
      "\t\t ['Text Data Mining']\n",
      "['Mean Average Precision'] \n",
      "\t\t ['Mean Average Precision']\n",
      "\t\t ['Mean Average Precision']\n",
      "['sequential dependence', 'Markov random field'] \n",
      "\t\t ['a', 'query likelihood', 'and a', 'sequential dependence', 'Markov random field', 'and']\n",
      "\t\t ['query likelihood', 'sequential dependence', 'Markov random field']\n",
      "['pseudo relevance feedback'] \n",
      "\t\t ['pseudo relevance feedback', 'in']\n",
      "\t\t ['pseudo relevance feedback']\n",
      "['proper', 'verbs'] \n",
      "\t\t ['non-proper', 'nouns', 'proper nouns', 'verbs']\n",
      "\t\t ['non-proper', 'proper nouns', 'verbs']\n",
      "['Minimum Phone Error', 'Maximum Likelihood Linear Transform', 'Boosted Maximum Mutual Information'] \n",
      "\t\t ['Maximum Likelihood Linear Transform', 'Boosted Maximum Mutual Information', 'Minimum Phone Error']\n",
      "\t\t ['Maximum Likelihood Linear Transform', 'Boosted Maximum Mutual Information', 'Minimum Phone Error']\n",
      "['Structured Weighted Violations Perceptron'] \n",
      "\t\t ['Structured Weighted Violations Perceptron', 'on a']\n",
      "\t\t ['Structured Weighted Violations Perceptron']\n",
      "['Chomsky Normal Form'] \n",
      "\t\t ['or', 'Chomsky Normal Form']\n",
      "\t\t ['Chomsky Normal Form']\n",
      "['Probabilistic CFG'] \n",
      "\t\t ['a CFG is', 'a Probabilistic CFG', 'n']\n",
      "\t\t ['a CFG is', 'a Probabilistic CFG', 'n']\n",
      "['Language Neutral Syntax'] \n",
      "\t\t ['a', 'Language Neutral Syntax']\n",
      "\t\t ['Language Neutral Syntax']\n",
      "['Base+Appositives', 'FrameNet', 'Verb Pair'] \n",
      "\t\t ['Base+FrameNet', 'Base+Verb Pairs', 'Base+Appositives']\n",
      "\t\t ['Base+FrameNet', 'Base+Verb Pairs', 'Base+Appositives']\n",
      "['natural language generation'] \n",
      "\t\t ['language', 'a natural language generation', 'a']\n",
      "\t\t ['a natural language generation']\n",
      "['labeled recall', 'labeled precision'] \n",
      "\t\t ['labeled recall', 'labeled precision']\n",
      "\t\t ['labeled recall', 'labeled precision']\n",
      "['Response Planner'] \n",
      "\t\t ['Response Planner', 'an']\n",
      "\t\t ['Response Planner']\n",
      "['truncated', 'terse information', 'interrupted', 'transposed'] \n",
      "\t\t ['terse information', 'interrupted', 'truncated', 'transposed sentence']\n",
      "\t\t ['terse information', 'interrupted', 'truncated', 'transposed sentence']\n",
      "['Support Vector Machines'] \n",
      "\t\t ['in', 'Support Vector Machines', 'in']\n",
      "\t\t ['Support Vector Machines']\n",
      "['an adverb', 'verb group'] \n",
      "\t\t ['adverb', 'a verb group']\n",
      "\t\t ['adverb', 'a verb group']\n",
      "['posttraumatic stress disorder'] \n",
      "\t\t ['a', 'posttraumatic stress disorder', 'is a', 'disorder', 'a', 'trauma', 'a']\n",
      "\t\t ['posttraumatic stress disorder']\n",
      "['Language Technology Components'] \n",
      "\t\t ['Language Technology Components']\n",
      "\t\t ['Language Technology Components']\n",
      "['product attribut'] \n",
      "\t\t []\n",
      "\t\t []\n",
      "['Discourse Tagging Tool'] \n",
      "\t\t ['a', 'Discourse Tagging Tool', 'Discourse Tagging']\n",
      "\t\t ['Discourse Tagging Tool']\n",
      "['Alignment Error Rate'] \n",
      "\t\t ['Alignment Error Rate']\n",
      "\t\t ['Alignment Error Rate']\n",
      "['relation extraction'] \n",
      "\t\t ['relation extraction']\n",
      "\t\t ['relation extraction']\n",
      "['Mean Reciprocal Rank'] \n",
      "\t\t ['Mean Reciprocal Rank']\n",
      "\t\t ['Mean Reciprocal Rank']\n",
      "['Functional unification'] \n",
      "\t\t ['Functional unification', 'a']\n",
      "\t\t ['Functional unification']\n",
      "['Missed Samples', 'Perplex', 'Missed Samples'] \n",
      "\t\t ['Missed Samples', 'Missed Samples']\n",
      "\t\t ['Missed Samples', 'Missed Samples']\n",
      "['Computer Vision and Pattern Recognition'] \n",
      "\t\t ['Conference on Computer Vision and Pattern Recognition']\n",
      "\t\t ['Conference on Computer Vision and Pattern Recognition']\n",
      "['Support Vector Machine'] \n",
      "\t\t ['Support Vector Machines', 'to']\n",
      "\t\t ['Support Vector Machines']\n",
      "['Sound Pattern of English'] \n",
      "\t\t ['of', 'Sound Pattern of English']\n",
      "\t\t ['Sound Pattern of English']\n",
      "['2*P*R'] \n",
      "\t\t []\n",
      "\t\t []\n",
      "['BioNLP'] \n",
      "\t\t []\n",
      "\t\t []\n",
      "['graphical user interface'] \n",
      "\t\t ['a', 'a', 'a graphical user interface', 'users', 'o a', 'a']\n",
      "\t\t ['a graphical user interface', 'users']\n",
      "['Subordination Link'] \n",
      "\t\t ['in', 'at', 'Subordination Link']\n",
      "\t\t ['Subordination Link']\n",
      "['final'] \n",
      "\t\t ['final stress']\n",
      "\t\t ['final stress']\n",
      "['Uncertainty in Artificial Intelligence'] \n",
      "\t\t ['In', 'Uncertainty in Artificial Intelligence']\n",
      "\t\t ['Uncertainty in Artificial Intelligence']\n",
      "['Automated Knowledge LDA'] \n",
      "\t\t ['a', 'a', 'Automated Knowledge LDA']\n",
      "\t\t ['Automated Knowledge LDA']\n",
      "['Markov Logic Network'] \n",
      "\t\t ['Markov', 'Markov Logic Network']\n",
      "\t\t ['Markov Logic Network']\n",
      "['language model', 'translation model'] \n",
      "\t\t ['language model', 'translation model']\n",
      "\t\t ['language model', 'translation model']\n",
      "['to', 'inanimate', 'animate', 'is', 'gerund', 'prepositional phrase'] \n",
      "\t\t ['NP', 'verb', 'phrase', 'prep', 'prep']\n",
      "\t\t ['NP', 'verb', 'phrase', 'prep', 'prep']\n",
      "['Information Gain'] \n",
      "\t\t ['in', 'Information Gain']\n",
      "\t\t ['Information Gain']\n",
      "['named page', 'home page', 'topic distillation'] \n",
      "\t\t ['in', 'home page finding', 'page finding', 'topic distillation']\n",
      "\t\t ['home page finding', 'topic distillation']\n",
      "['convolution kernels'] \n",
      "\t\t ['convolution kernels']\n",
      "\t\t ['convolution kernels']\n",
      "['Named entity'] \n",
      "\t\t ['Named entity']\n",
      "\t\t ['Named entity']\n",
      "['specificity character goals'] \n",
      "\t\t ['s', 'is', 'specificity character goals', 'character goals', 'character goal']\n",
      "\t\t ['specificity character goals']\n",
      "['Maximum Entropy'] \n",
      "\t\t ['Maximum Entropy']\n",
      "\t\t ['Maximum Entropy']\n",
      "['average perceptron'] \n",
      "\t\t ['perceptron', 'average perceptron']\n",
      "\t\t ['average perceptron']\n",
      "['BLAST bit score'] \n",
      "\t\t ['a', 'BLAST bit score', 'score']\n",
      "\t\t ['BLAST bit score']\n",
      "['Treelet Phrasal'] \n",
      "\t\t ['Treelet', 'Treelet Phrasal Diff']\n",
      "\t\t ['Treelet Phrasal Diff']\n",
      "['Biquadratic Kerne', 'Quadratic Kernel', '8-th Degree Polynomial Kernel'] \n",
      "\t\t ['Quadratic Kernel', 'Biquadratic Kernel', 'Kernel']\n",
      "\t\t ['Quadratic Kernel', 'Biquadratic Kernel']\n",
      "['machine learning', 'audiobased', 'knowledge-based'] \n",
      "\t\t ['in', 'audiobased', 'knowledge-based', 'machine learning', 'in']\n",
      "\t\t ['audiobased', 'knowledge-based', 'machine learning']\n",
      "['positive+unlabeled'] \n",
      "\t\t ['positive+unlabeled', 'positive']\n",
      "\t\t ['positive+unlabeled']\n",
      "['City University'] \n",
      "\t\t ['City University']\n",
      "\t\t ['City University']\n",
      "['Dbest'] \n",
      "\t\t ['bi', 'Dbest', 'argmaxD P']\n",
      "\t\t ['bi', 'Dbest', 'argmaxD P']\n",
      "['Functional Grammar'] \n",
      "\t\t ['a', 'Functional Grammar', 'a']\n",
      "\t\t ['Functional Grammar']\n",
      "['named entities'] \n",
      "\t\t ['named entities']\n",
      "\t\t ['named entities']\n",
      "['Support Vector Machine'] \n",
      "\t\t ['Support Vector Machine']\n",
      "\t\t ['Support Vector Machine']\n",
      "['University of Manchester'] \n",
      "\t\t ['University of Manchester']\n",
      "\t\t ['University of Manchester']\n",
      "['Broadcast Conversations', 'Broadcast News', 'Conversational Telephone Speech', 'Newswire'] \n",
      "\t\t ['Broadcast Conversations', 'Broadcast', 'News', 'Conversational Telephone', 'Newswire']\n",
      "\t\t ['Broadcast Conversations', 'Conversational Telephone', 'Newswire']\n",
      "['Attribute Relation Graph'] \n",
      "\t\t ['Representation Attribute Relation Graph']\n",
      "\t\t ['Representation Attribute Relation Graph']\n",
      "['distortion limit'] \n",
      "\t\t ['a', 'low distortion limit', 'a']\n",
      "\t\t ['low distortion limit']\n",
      "['maximum a posteriori'] \n",
      "\t\t ['maximum a posteriori', 'a']\n",
      "\t\t ['maximum a posteriori']\n",
      "['Natural language processin', 'Part-Of-Speech'] \n",
      "\t\t ['of', 'Natural language processing']\n",
      "\t\t ['Natural language processing']\n",
      "['Verb Arity Sampling Test'] \n",
      "\t\t ['a', 'in', 'Verb Arity Sampling Test']\n",
      "\t\t ['Verb Arity Sampling Test']\n",
      "['Rand Index'] \n",
      "\t\t ['or', 'Rand Index', 'Rand']\n",
      "\t\t ['Rand Index']\n",
      "['Support Vector Machine'] \n",
      "\t\t ['a Support Vector Machine']\n",
      "\t\t ['a Support Vector Machine']\n",
      "['descriptor array'] \n",
      "\t\t ['Neural network architecture', 'descriptor array']\n",
      "\t\t ['Neural network architecture', 'descriptor array']\n",
      "['Regular Expressions'] \n",
      "\t\t ['on', 'a', 'Regular Expressions', 'a', 'a']\n",
      "\t\t ['Regular Expressions']\n",
      "['Association for Computational Linguistic'] \n",
      "\t\t ['on Association for Computational Linguistics']\n",
      "\t\t ['on Association for Computational Linguistics']\n",
      "['Quranic Arabic Dependency Treebank'] \n",
      "\t\t ['Quranic Arabic Dependency Treebank']\n",
      "\t\t ['Quranic Arabic Dependency Treebank']\n",
      "['logical form'] \n",
      "\t\t ['a logical form', 'a']\n",
      "\t\t ['a logical form']\n",
      "['Word Distributional Similarity', 'Random', 'LexRank', 'DivRank', 'DivRank with Priors', 'C-LexRank', 'Confidence Interval'] \n",
      "\t\t [';', 'p', 'with Priors', 'Distributional Similarity']\n",
      "\t\t [';', 'p', 'with Priors', 'Distributional Similarity']\n",
      "['conjunctions'] \n",
      "\t\t ['conjunctions']\n",
      "\t\t ['conjunctions']\n",
      "['lexical rules'] \n",
      "\t\t ['lexical rules']\n",
      "\t\t ['lexical rules']\n",
      "['Rand Index'] \n",
      "\t\t ['Rand Index', 'Rand']\n",
      "\t\t ['Rand Index']\n",
      "['algorithmic on(foiled grammar'] \n",
      "\t\t ['a grammar', '( foiled grammar']\n",
      "\t\t ['a grammar', '( foiled grammar']\n",
      "['regular expressions'] \n",
      "\t\t ['regular expressions']\n",
      "\t\t ['regular expressions']\n",
      "['Adjective phras', 'Adverb phrase'] \n",
      "\t\t ['Adverb phrase', 'Adjective phrase']\n",
      "\t\t ['Adverb phrase', 'Adjective phrase']\n",
      "['Memory Efficient Tucker'] \n",
      "\t\t ['Memory Efficient Tucker']\n",
      "\t\t ['Memory Efficient Tucker']\n",
      "['language model'] \n",
      "\t\t ['model', 'a', 'a', 'a', 'language model']\n",
      "\t\t ['language model']\n",
      "['Noun Stem', 'Adjectival Sta', 'Verb Stem', 'Determine', 'Nominal Inflexion', 'Verbal Inflsxion', 'Pronoun', 'Adjectival Inflexion'] \n",
      "\t\t ['Adjectival Sta~', 'Verb Stem', 'Determine~', 'Nominal', 'Inflexion', 'Noun Stem', 'Verbal Inflsxion', 'Pronoun']\n",
      "\t\t ['Adjectival Sta~', 'Verb Stem', 'Determine~', 'Nominal', 'Inflexion', 'Noun Stem', 'Verbal Inflsxion', 'Pronoun']\n",
      "['Support Vector Machines'] \n",
      "\t\t ['Vector Machines', 'in']\n",
      "\t\t ['Vector Machines']\n",
      "['Penn Treebank'] \n",
      "\t\t ['Penn Treebank']\n",
      "\t\t ['Penn Treebank']\n",
      "['Machine translation'] \n",
      "\t\t ['Machine translation']\n",
      "\t\t ['Machine translation']\n",
      "['vowel', 'any char'] \n",
      "\t\t ['y', 'vowel', 'any char']\n",
      "\t\t ['vowel', 'any char']\n",
      "['French - Englis', 'human-assisted'] \n",
      "\t\t ['French - English', 'human-assisted']\n",
      "\t\t ['French - English', 'human-assisted']\n",
      "['Sense Data Item'] \n",
      "\t\t ['a', 'Sense Data Item']\n",
      "\t\t ['Sense Data Item']\n",
      "['combinatory categorial grammar'] \n",
      "\t\t ['a combinatory categorial grammar']\n",
      "\t\t ['a combinatory categorial grammar']\n",
      "['as the Agent'] \n",
      "\t\t ['Agent']\n",
      "\t\t ['Agent']\n",
      "['training set', 'validating set'] \n",
      "\t\t ['in', 'mean training set', 'validating set', 'in']\n",
      "\t\t ['mean training set', 'validating set']\n",
      "['Empirical Methods in Natural Language Processing'] \n",
      "\t\t ['Methods in Natural Language Processing (']\n",
      "\t\t ['Methods in Natural Language Processing (']\n",
      "['Question Answering', 'Information Extraction'] \n",
      "\t\t ['Question Answering', 'Information Extraction', 'a']\n",
      "\t\t ['Question Answering', 'Information Extraction']\n",
      "['expected term frequencies'] \n",
      "\t\t ['expected term frequencies', 'i']\n",
      "\t\t ['expected term frequencies']\n",
      "['Mary', 'Mary'] \n",
      "\t\t ['KMary', 'Mary']\n",
      "\t\t ['KMary']\n",
      "['Computer scientist', 'Stanford', 'Link Grammar Parser', 'McClosky-Charniak-Johnson'] \n",
      "\t\t ['Language Processing', 'scientist', 'CoreNLP', 'stemmer', 'stemmer', 'Grammar']\n",
      "\t\t ['Language Processing', 'scientist', 'CoreNLP', 'stemmer', 'stemmer', 'Grammar']\n",
      "['cost-sensitive classification'] \n",
      "\t\t ['a', 'cost-sensitive classification']\n",
      "\t\t ['cost-sensitive classification']\n",
      "['Distributed Artificial Intelligence Laboratory'] \n",
      "\t\t ['Artificial Intelligence Laboratory', 't']\n",
      "\t\t ['Artificial Intelligence Laboratory']\n",
      "['Analysis of Variance'] \n",
      "\t\t ['Analysis of Variance']\n",
      "\t\t ['Analysis of Variance']\n",
      "['Source Connectivity Strength', 'Target Connectivity Strength'] \n",
      "\t\t ['Connectivity', 'Strength', 'Source Connectivity Strength', 'Target Connectivity Strength']\n",
      "\t\t ['Source Connectivity Strength', 'Target Connectivity Strength']\n",
      "['Integer Linear Programming'] \n",
      "\t\t ['Integer Linear Programming']\n",
      "\t\t ['Integer Linear Programming']\n",
      "['Educational Testing Service'] \n",
      "\t\t ['an', 'at Educational Testing Service']\n",
      "\t\t ['at Educational Testing Service']\n",
      "['negative Matrix Factorization', 'Latent Semantic Analysis'] \n",
      "\t\t ['Latent Semantic Analysis', 'o', 'or Non-negative Matrix Factorization']\n",
      "\t\t ['Latent Semantic Analysis', 'or Non-negative Matrix Factorization']\n",
      "['dialog act'] \n",
      "\t\t ['dialog act']\n",
      "\t\t ['dialog act']\n",
      "['Latent Semantic Analysis'] \n",
      "\t\t ['Semantic Analysis', 'Semantic Analysis', 'is a']\n",
      "\t\t ['Semantic Analysis', 'Semantic Analysis']\n",
      "['Switchboard Dialog Act'] \n",
      "\t\t ['Switchboard Dialog Act']\n",
      "\t\t ['Switchboard Dialog Act']\n",
      "['Penn Discourse Tree Bank'] \n",
      "\t\t ['is', 'Penn Discourse Tree Bank']\n",
      "\t\t ['Penn Discourse Tree Bank']\n",
      "['PennTreebank'] \n",
      "\t\t ['a', 'PennTreebank', 'a']\n",
      "\t\t ['PennTreebank']\n",
      "['spoken dialog system', 'spoken language understanding'] \n",
      "\t\t ['a', 'in', 'spoken dialog system', 'spoken language understanding']\n",
      "\t\t ['spoken dialog system', 'spoken language understanding']\n",
      "['linker for activation of T'] \n",
      "\t\t ['B', 'cell', 'activation of T cells', 'c']\n",
      "\t\t ['B', 'activation of T cells']\n",
      "['long short term memory'] \n",
      "\t\t ['long short term memory', 'a']\n",
      "\t\t ['long short term memory']\n",
      "['automated coreference'] \n",
      "\t\t ['automated coreference']\n",
      "\t\t ['automated coreference']\n",
      "['Mean Average Precision'] \n",
      "\t\t ['tion', 'Mean Average Precision', 'on']\n",
      "\t\t ['tion', 'Mean Average Precision']\n",
      "['diminishers', 'highly negative', 'negative', 'positive', 'highly positive', 'invertors', 'invertors'] \n",
      "\t\t ['negative', 'positive']\n",
      "\t\t ['negative', 'positive']\n",
      "['Automated Student Assessment Prize'] \n",
      "\t\t ['Automated Student Assessment Prize']\n",
      "\t\t ['Automated Student Assessment Prize']\n",
      "['subcategorization frames'] \n",
      "\t\t ['frames', 'subcategorization frames']\n",
      "\t\t ['subcategorization frames']\n",
      "['most frequent sense'] \n",
      "\t\t ['frequent sense', 'is']\n",
      "\t\t ['frequent sense']\n",
      "['Tageszeitung'] \n",
      "\t\t ['Tageszeitung']\n",
      "\t\t ['Tageszeitung']\n",
      "['Latent Mixture of Discriminative Experts'] \n",
      "\t\t ['of', 'Latent Mixture of Discriminative Experts']\n",
      "\t\t ['Latent Mixture of Discriminative Experts']\n",
      "['World Wide Web'] \n",
      "\t\t ['World Wide Web']\n",
      "\t\t ['World Wide Web']\n",
      "['language model'] \n",
      "\t\t ['an', 'language model']\n",
      "\t\t ['language model']\n",
      "['accumulated tag counts'] \n",
      "\t\t ['accumulated tag counts']\n",
      "\t\t ['accumulated tag counts']\n",
      "['Optimality Theory'] \n",
      "\t\t ['Optimality Theory']\n",
      "\t\t ['Optimality Theory']\n",
      "['context group discrimination'] \n",
      "\t\t ['a group', 'context group discrimination']\n",
      "\t\t ['a group', 'context group discrimination']\n",
      "['Document frequency'] \n",
      "\t\t ['Document frequency of constituents', 'frequency of a constituent']\n",
      "\t\t ['Document frequency of constituents', 'frequency of a constituent']\n",
      "['direct orthographic mapping'] \n",
      "\t\t ['in', 'a', 'mapping', 'a']\n",
      "\t\t ['mapping']\n",
      "['unlabeled attachment score', 'labeled attachment score'] \n",
      "\t\t ['labeled attachment score', 'unlabeled attachment score']\n",
      "\t\t ['unlabeled attachment score']\n",
      "['support vector machine'] \n",
      "\t\t ['machine', 'to', 'support vector machine']\n",
      "\t\t ['support vector machine']\n",
      "['Natural Language Processing'] \n",
      "\t\t ['Natural Language Processing']\n",
      "\t\t ['Natural Language Processing']\n",
      "['all gazetteer'] \n",
      "\t\t ['all gazetteer']\n",
      "\t\t ['all gazetteer']\n",
      "['Treebank Apl)roach'] \n",
      "\t\t ['A', 'Treebank', 'roach']\n",
      "\t\t ['A', 'Treebank', 'roach']\n",
      "['phrase by phrase', 'word by word'] \n",
      "\t\t ['phrase by phrase', 'word by word']\n",
      "\t\t ['phrase by phrase', 'word by word']\n",
      "['false positives', 'true positives'] \n",
      "\t\t ['true positives', 'true positives', 'false positives']\n",
      "\t\t ['true positives', 'true positives', 'false positives']\n",
      "['Computer Vision and Pattern Recognition'] \n",
      "\t\t ['Conference', 'on Computer Vision and Pattern Recognition']\n",
      "\t\t ['Conference', 'on Computer Vision and Pattern Recognition']\n",
      "['Person', 'Organization', 'Facility', 'Geo-Political'] \n",
      "\t\t ['Person', 'Organization', 'Facility']\n",
      "\t\t ['Person', 'Organization', 'Facility']\n",
      "['Question Answering', 'Semantic Role Labeling'] \n",
      "\t\t ['Semantic Role Labeling', 'in', 'Question Answering']\n",
      "\t\t ['Semantic Role Labeling', 'Question Answering']\n",
      "['Named Entity Recognition'] \n",
      "\t\t ['Entity Recognition', 'a']\n",
      "\t\t ['Entity Recognition']\n",
      "['Subset of Stockholm'] \n",
      "\t\t ['Adding valency', 'Subset of']\n",
      "\t\t ['Adding valency', 'Subset of']\n",
      "['maximum entropy'] \n",
      "\t\t ['maximum entropy']\n",
      "\t\t ['maximum entropy']\n",
      "['Cross Language Evaluation Forum'] \n",
      "\t\t ['Cross Language Evaluation Forum']\n",
      "\t\t ['Cross Language Evaluation Forum']\n",
      "['PENNBIOIE gene'] \n",
      "\t\t ['gene corpus', 'gene']\n",
      "\t\t ['gene corpus']\n",
      "['machine translation'] \n",
      "\t\t ['in', 'on', 'in', 'machine translation', 'a']\n",
      "\t\t ['machine translation']\n",
      "['Philadelphia'] \n",
      "\t\t ['Philadelphia']\n",
      "\t\t ['Philadelphia']\n",
      "['Support Vector Machines'] \n",
      "\t\t ['Support Vector Machines']\n",
      "\t\t ['Support Vector Machines']\n",
      "['semantic relatedness'] \n",
      "\t\t ['semantic relatedness']\n",
      "\t\t ['semantic relatedness']\n",
      "['noun', 'determiner'] \n",
      "\t\t [')', ')']\n",
      "\t\t [')', ')']\n",
      "['Center for Natural Language'] \n",
      "\t\t ['for', 'Center for Natural Language Processing']\n",
      "\t\t ['Center for Natural Language Processing']\n",
      "['Mission Rehearsal Exercise'] \n",
      "\t\t ['a', 'Mission Rehearsal Exercise']\n",
      "\t\t ['Mission Rehearsal Exercise']\n",
      "['number of markables'] \n",
      "\t\t ['number of']\n",
      "\t\t ['number of']\n",
      "['autism spectrum disorder'] \n",
      "\t\t ['autism spectrum disorder']\n",
      "\t\t ['autism spectrum disorder']\n",
      "['null grammar'] \n",
      "\t\t ['a', 'grammar', 'null grammar', 'a']\n",
      "\t\t ['null grammar']\n",
      "['Beneficial'] \n",
      "\t\t ['Beneficial']\n",
      "\t\t ['Beneficial']\n",
      "['possessive pronoun', 'determiner', 'cardinal'] \n",
      "\t\t ['determiner', 'a', 'cardinal numbers']\n",
      "\t\t ['determiner', 'cardinal numbers']\n",
      "['Computational Linguistics'] \n",
      "\t\t ['on', 'Linguistics']\n",
      "\t\t ['Linguistics']\n",
      "['generalized expectation'] \n",
      "\t\t ['expectation']\n",
      "\t\t ['expectation']\n",
      "['difference'] \n",
      "\t\t []\n",
      "\t\t []\n",
      "['Leaf Node Network'] \n",
      "\t\t ['Leaf Node Network']\n",
      "\t\t ['Leaf Node Network']\n",
      "['Implicit Attitude'] \n",
      "\t\t ['Attitude', 'n', 't']\n",
      "\t\t ['Attitude', 'n']\n",
      "['Computational Linguistics'] \n",
      "\t\t ['on Computational Linguistics']\n",
      "\t\t ['on Computational Linguistics']\n",
      "['language model'] \n",
      "\t\t ['a', 'an', 'language model']\n",
      "\t\t ['language model']\n",
      "['named entities'] \n",
      "\t\t ['named entities']\n",
      "\t\t ['named entities']\n",
      "['Customization Solution'] \n",
      "\t\t ['Customization', 'a', 'Customization Solution', 'a']\n",
      "\t\t ['Customization Solution']\n",
      "['prepositional phrase'] \n",
      "\t\t ['prepositional phrase']\n",
      "\t\t ['prepositional phrase']\n",
      "['Association for Computational Linguistics'] \n",
      "\t\t ['Association for Computational Linguistics']\n",
      "\t\t ['Association for Computational Linguistics']\n",
      "['Filled Pause', 'Reparandum', 'Interregnum'] \n",
      "\t\t ['Pause']\n",
      "\t\t ['Pause']\n",
      "['TurnCos', 'TaskCompletionReward', 'TotalTurnCost'] \n",
      "\t\t ['TaskCompletionReward', 'TurnCost', 'TotalTurnCost']\n",
      "\t\t ['TaskCompletionReward', 'TotalTurnCost']\n",
      "['machine translation'] \n",
      "\t\t ['on machine translation', 'in']\n",
      "\t\t ['on machine translation']\n",
      "['supervised binarized PCFG', 'supervised binarized DOP'] \n",
      "\t\t ['a supervised binarized PCFG', 'a supervised binarized DOP']\n",
      "\t\t ['a supervised binarized PCFG', 'a supervised binarized DOP']\n",
      "['Recursive Autoencoder'] \n",
      "\t\t ['Recursive Autoencoder']\n",
      "\t\t ['Recursive Autoencoder']\n",
      "['document representation'] \n",
      "\t\t ['l', 'rhetorical representation', 'document representation']\n",
      "\t\t ['rhetorical representation', 'document representation']\n",
      "['agent', 'ins t rumenta l', 'objective', 'experiencer'] \n",
      "\t\t ['m', 'a t i', 'a l l', 't r u', 't u r e', 'a', 't', 'r e l a t i o n', 'p a r t i', 'i p a t i o n', 't', 'agent', 'ins t rumenta l', 'objective', 'experiencer']\n",
      "\t\t ['a l l', 't r u', 't u r e', 'r e l a t i o n', 'p a r t i', 'i p a t i o n', 'agent', 'ins t rumenta l', 'objective', 'experiencer']\n",
      "['attribute', 'art~fact', 'body', 'an~'] \n",
      "\t\t ['an~', 'art~fact', 'attribute', 'body']\n",
      "\t\t ['an~', 'art~fact', 'attribute', 'body']\n",
      "['part of speech'] \n",
      "\t\t ['o', 'part of speech']\n",
      "\t\t ['part of speech']\n",
      "['native language identification'] \n",
      "\t\t ['native language identification', 'a']\n",
      "\t\t ['native language identification']\n",
      "['minimum error rate training'] \n",
      "\t\t ['error rate training']\n",
      "\t\t ['error rate training']\n",
      "['Speech and Language Processing for Assistive Technologies'] \n",
      "\t\t ['Speech and Language Processing for Assistive Technologies']\n",
      "\t\t ['Speech and Language Processing for Assistive Technologies']\n",
      "['elementary discourse units'] \n",
      "\t\t ['a', 'elementary discourse units']\n",
      "\t\t ['elementary discourse units']\n",
      "['conditional random fields'] \n",
      "\t\t ['and a', 'and', 'a conditional random fields', 'an']\n",
      "\t\t ['a conditional random fields']\n",
      "['Machine Translation', 'Question Answering', 'Information Retrieval'] \n",
      "\t\t ['Question Answering', 'Machine Translation', 'Information Retrieval']\n",
      "\t\t ['Question Answering', 'Machine Translation', 'Information Retrieval']\n",
      "['Transactions of the ACL'] \n",
      "\t\t ['ation for Computational Linguistics', 'he', 'on the', 'of the', 'Transactions of the ACL', 'Computational Linguistics']\n",
      "\t\t ['ation for Computational Linguistics', 'Transactions of the ACL']\n",
      "['Dual Encoder', 'recurrent neural network'] \n",
      "\t\t ['recurrent neural network', 'Dual Encoder', 'et']\n",
      "\t\t ['recurrent neural network', 'Dual Encoder']\n",
      "['communicative act', 'meaningful expression'] \n",
      "\t\t ['meaningful expression', 'act', 'a', 'meaning', 'communicative act', 'a']\n",
      "\t\t ['meaningful expression', 'communicative act']\n",
      "['database'] \n",
      "\t\t ['a', 'database', 'a']\n",
      "\t\t ['database']\n",
      "['Full Verb'] \n",
      "\t\t ['Full Verb']\n",
      "\t\t ['Full Verb']\n",
      "['Foundation'] \n",
      "\t\t ['Research Foundation']\n",
      "\t\t ['Research Foundation']\n",
      "['source code author profile'] \n",
      "\t\t ['source code author profile']\n",
      "\t\t ['source code author profile']\n",
      "['Document Understanding Conference'] \n",
      "\t\t ['Understanding Conference', 'in']\n",
      "\t\t ['Understanding Conference']\n",
      "['True Positive', 'False Positive'] \n",
      "\t\t ['True Positive', 'False Positive']\n",
      "\t\t ['True Positive', 'False Positive']\n",
      "['Logical Forms'] \n",
      "\t\t ['Logical Forms']\n",
      "\t\t ['Logical Forms']\n",
      "['Levenshtein with substitution penalty'] \n",
      "\t\t ['substitution', 'Levenshtein with substitution penalty', 'a', 'in']\n",
      "\t\t ['Levenshtein with substitution penalty']\n",
      "['out of vocabulary'] \n",
      "\t\t ['of', 'a', 'out of vocabulary']\n",
      "\t\t ['out of vocabulary']\n",
      "['International Joint Conference on Natural Language Processing'] \n",
      "\t\t []\n",
      "\t\t []\n",
      "['verb phrases'] \n",
      "\t\t ['as verb']\n",
      "\t\t ['as verb']\n",
      "['Air Force Research Laboratory', 'Research Projects Agency', 'Deep Exploration and Filtering of Text'] \n",
      "\t\t ['Research Projects Agency', 'Deep Exploration and Filtering of Text', 'Air Force Research Laboratory']\n",
      "\t\t ['Research Projects Agency', 'Deep Exploration and Filtering of Text', 'Air Force Research Laboratory']\n",
      "['Dependency relation'] \n",
      "\t\t ['relation']\n",
      "\t\t ['relation']\n",
      "['short form', 'long form'] \n",
      "\t\t ['the', 'of the long', 'short']\n",
      "\t\t ['of the long', 'short']\n",
      "['shared variables', 'filling status'] \n",
      "\t\t ['lexemes', 'filling status', 'shared variables', 'variables', 'sentence']\n",
      "\t\t ['lexemes', 'filling status', 'shared variables', 'sentence']\n",
      "['quadratic program'] \n",
      "\t\t ['t', 'a quadratic program', 'a']\n",
      "\t\t ['a quadratic program']\n",
      "['Confidence Weighted'] \n",
      "\t\t ['Confidence Weighted']\n",
      "\t\t ['Confidence Weighted']\n",
      "['punctuation', 'particle'] \n",
      "\t\t ['punctuation', 'particle', 'residual', 'a']\n",
      "\t\t ['punctuation', 'particle', 'residual']\n",
      "['domain model level', 'English-oriented level'] \n",
      "\t\t ['English-oriented', 'level', 'domain model level', 'is']\n",
      "\t\t ['English-oriented', 'domain model level']\n",
      "['system'] \n",
      "\t\t ['a speech dialogue system']\n",
      "\t\t ['a speech dialogue system']\n",
      "['base temporal phrase', 'base noun phrase', 'base verb phrase', 'base location  phrase'] \n",
      "\t\t ['phrase', 'base noun phrase', 'base temporal phrase', 'base location phrase', 'base verb phrase']\n",
      "\t\t ['base noun phrase', 'base temporal phrase', 'base location phrase', 'base verb phrase']\n",
      "['computational branding analytics'] \n",
      "\t\t ['a', 'computational branding analytics']\n",
      "\t\t ['computational branding analytics']\n",
      "['Chunk'] \n",
      "\t\t ['Chunk']\n",
      "\t\t ['Chunk']\n",
      "['Recursive Neural Tensor Network'] \n",
      "\t\t ['to', 'a', 'Recursive Neural Tensor Network']\n",
      "\t\t ['Recursive Neural Tensor Network']\n",
      "['Large Dataset', 'Small Dataset'] \n",
      "\t\t ['a Small Dataset', 'a Large Dataset']\n",
      "\t\t ['a Small Dataset', 'a Large Dataset']\n",
      "[] \n",
      "\t\t [\"Nu ' (\", ')', 'Nu (', ')', '(', ')', \"Nu ' (\", ')', 'Nu (', ')', '(', '(', ')', \"' (\", ') ) (', ')']\n",
      "\t\t [\"Nu ' (\", 'Nu (', \"Nu ' (\", 'Nu (', ') ) (']\n",
      "['Wordnet first sense baseline'] \n",
      "\t\t ['in', 'Wordnet first sense']\n",
      "\t\t ['Wordnet first sense']\n",
      "['semantic role labeling'] \n",
      "\t\t ['semantic', 'semantic role labeling']\n",
      "\t\t ['semantic role labeling']\n",
      "['Association for Machine Translation in the Americas'] \n",
      "\t\t ['the', 'for Machine Translation in the Americas']\n",
      "\t\t ['for Machine Translation in the Americas']\n",
      "['selectional preferences'] \n",
      "\t\t ['selectional preferences', 'preferences', 'on']\n",
      "\t\t ['selectional preferences']\n",
      "['unlabeled attachment score', 'shared modifier', 'conjunct'] \n",
      "\t\t ['shared modifier', 'conjunct']\n",
      "\t\t ['shared modifier', 'conjunct']\n",
      "['Total', 'sentence', 'Relevant Links', 'Active Chain', 'Growth rate'] \n",
      "\t\t ['Number', 'Growth', 'of', 'sentence', 'of', 'Relevant Links', 'Number of Active Chains']\n",
      "\t\t ['Growth', 'sentence', 'Relevant Links', 'Number of Active Chains']\n",
      "['Chinese Treebank version 5.1', 'Penn Treebank'] \n",
      "\t\t ['Penn', 'Treebank', 'Chinese Treebank version 5.1', 'Chinese']\n",
      "\t\t ['Penn', 'Chinese Treebank version 5.1']\n",
      "['maximum entropy'] \n",
      "\t\t ['maximum entropy', 'a']\n",
      "\t\t ['maximum entropy']\n",
      "['Basic Additive'] \n",
      "\t\t ['Basic Additive']\n",
      "\t\t ['Basic Additive']\n",
      "['Script model + Concept clustering'] \n",
      "\t\t ['Concept clustering']\n",
      "\t\t ['Concept clustering']\n",
      "['classification accuracy'] \n",
      "\t\t ['classification accuracy']\n",
      "\t\t ['classification accuracy']\n",
      "['coordieatien ned apposition'] \n",
      "\t\t ['i', 't', 'd', 't', 'coordieatien ned apposition constructions', 'i']\n",
      "\t\t ['coordieatien ned apposition constructions']\n",
      "['Information Technology', 'Telecommunication Services', 'Consumer Staples'] \n",
      "\t\t ['for', 'Information Technology', 'Consumer Staples']\n",
      "\t\t ['Information Technology', 'Consumer Staples']\n",
      "['minimum squared error'] \n",
      "\t\t ['error', 'minimum squared error', 'in']\n",
      "\t\t ['minimum squared error']\n",
      "['false negative'] \n",
      "\t\t ['false negative']\n",
      "\t\t ['false negative']\n",
      "['noun phrase'] \n",
      "\t\t ['noun phrase', 'a']\n",
      "\t\t ['noun phrase']\n",
      "['substantif', 'article g~n&al', 'verbe'] \n",
      "\t\t ['article g~n & al', 'substantif', 'verbe']\n",
      "\t\t ['article g~n & al', 'substantif', 'verbe']\n",
      "['Hidden Markov Model'] \n",
      "\t\t ['a', 'Hidden Markov Model']\n",
      "\t\t ['Hidden Markov Model']\n",
      "['Pattern Analysis and Machine Intelligence'] \n",
      "\t\t ['Transactions on Pattern Analysis and Machine Intelligence']\n",
      "\t\t ['Transactions on Pattern Analysis and Machine Intelligence']\n",
      "['automatic speech recognition', 'machine translation'] \n",
      "\t\t ['in automatic speech recognition', 'statistical machine translation']\n",
      "\t\t ['in automatic speech recognition', 'statistical machine translation']\n",
      "['Interactive query expansion'] \n",
      "\t\t ['Interactive query expansion', 't']\n",
      "\t\t ['Interactive query expansion']\n",
      "['Multilayer Perceptro', 'Support Vector Machine', 'Decision Tree', 'AdaBoost'] \n",
      "\t\t ['Support Vector Machine', 'Multilayer Perceptron', 'Decision Trees', 'AdaBoost']\n",
      "\t\t ['Support Vector Machine', 'Multilayer Perceptron', 'Decision Trees', 'AdaBoost']\n",
      "['target condition'] \n",
      "\t\t ['condition', 'on']\n",
      "\t\t ['condition']\n",
      "['linear precedenc', 'immediate  dominance'] \n",
      "\t\t ['immediate dominance', 'linear precedence', 'a']\n",
      "\t\t ['immediate dominance', 'linear precedence']\n",
      "['Locality sensitive hashing'] \n",
      "\t\t ['sensitive hashing', 'is']\n",
      "\t\t ['sensitive hashing']\n",
      "['Hidden Vector State'] \n",
      "\t\t ['Vector State', 'a']\n",
      "\t\t ['Vector State']\n",
      "['Lexical Accuracy'] \n",
      "\t\t ['al', 'Lexical Accuracy', 'Lexical']\n",
      "\t\t ['Lexical Accuracy']\n",
      "['Translation'] \n",
      "\t\t ['Translation Correctness']\n",
      "\t\t ['Translation Correctness']\n",
      "['maximum likelihood estimator'] \n",
      "\t\t ['maximum likelihood estimator']\n",
      "\t\t ['maximum likelihood estimator']\n",
      "['Information gain'] \n",
      "\t\t ['for', 'Information gain', 'for']\n",
      "\t\t ['Information gain']\n",
      "['Word Formation Analogy', 'Independent Word Probability', 'Anti-Word Pair'] \n",
      "\t\t ['Independent', 'Word Probability', 'Anti-Word Pair', 'Word Formation Analogy']\n",
      "\t\t ['Independent', 'Word Probability', 'Anti-Word Pair', 'Word Formation Analogy']\n",
      "['Swedish FrameNet'] \n",
      "\t\t ['a', 'Swedish FrameNet', 'et']\n",
      "\t\t ['Swedish FrameNet']\n",
      "['location'] \n",
      "\t\t ['person', 'organization', 'location', 'geopolitical entity', 'facility', 'vehicle']\n",
      "\t\t ['person', 'organization', 'location', 'geopolitical entity', 'facility', 'vehicle']\n",
      "['RST Discourse Treebank'] \n",
      "\t\t ['RST Discourse Treebank']\n",
      "\t\t ['RST Discourse Treebank']\n",
      "['Referring Expression Generation'] \n",
      "\t\t ['Referring Expression Generation']\n",
      "\t\t ['Referring Expression Generation']\n",
      "['low attachment'] \n",
      "\t\t ['attachment', 'attachment']\n",
      "\t\t ['attachment', 'attachment']\n",
      "['question answering'] \n",
      "\t\t ['a', 'question answering']\n",
      "\t\t ['question answering']\n",
      "['preposition'] \n",
      "\t\t ['preposition feature', 'preposition']\n",
      "\t\t ['preposition feature']\n",
      "['Stochastic Segment Model'] \n",
      "\t\t ['a d', 'Stochastic Segment Model']\n",
      "\t\t ['Stochastic Segment Model']\n",
      "['Homogenous Poisson Process'] \n",
      "\t\t ['Homogenous Poisson Process', 'on']\n",
      "\t\t ['Homogenous Poisson Process']\n",
      "['Lexical Functional Grammar'] \n",
      "\t\t ['Lexical Functional Grammar', 'a']\n",
      "\t\t ['Lexical Functional Grammar']\n",
      "['Universal Theory'] \n",
      "\t\t ['a', 'The', 'Universal Theory', 'a']\n",
      "\t\t ['Universal Theory']\n",
      "['Text REtrieval Conferences'] \n",
      "\t\t ['o', 'Text REtrieval Conferences']\n",
      "\t\t ['Text REtrieval Conferences']\n",
      "['machine translation', 'natural language generation'] \n",
      "\t\t ['it', 'in', 'language', 'machine translation', 'a natural language generation', 'a']\n",
      "\t\t ['machine translation', 'a natural language generation']\n",
      "['prEposition'] \n",
      "\t\t ['participe', 'prEposition', 'substamif']\n",
      "\t\t ['participe', 'prEposition', 'substamif']\n",
      "['Semantic Network', 'Metathesaurus'] \n",
      "\t\t ['the', 'the', 'Network', 'a', 'the']\n",
      "\t\t ['Network']\n",
      "['support vector machine', 'classifiers for detecting'] \n",
      "\t\t ['support vector machine', 'in']\n",
      "\t\t ['support vector machine']\n",
      "['Parsed syntactic structures', 'Conceptual structures'] \n",
      "\t\t ['Conceptual structures', 'syntactic structures']\n",
      "\t\t ['Conceptual structures', 'syntactic structures']\n",
      "['natural language processing', 'information extraction'] \n",
      "\t\t ['information extraction', 'natural language processing', 'for', 'in']\n",
      "\t\t ['information extraction', 'natural language processing']\n",
      "['unlabeled precision', 'unlabeled recall'] \n",
      "\t\t ['unlabeled precision', 'unlabeled recall']\n",
      "\t\t ['unlabeled precision', 'unlabeled recall']\n",
      "['Royal Spanish Academy', 'Computer Center of  the University of Madrid'] \n",
      "\t\t ['of the Spanish', 'a', 'of the Royal Spanish Academy', 'the Computer Center of the University of Madrid']\n",
      "\t\t ['of the Spanish', 'of the Royal Spanish Academy', 'the Computer Center of the University of Madrid']\n",
      "['strictly local'] \n",
      "\t\t ['strictly local']\n",
      "\t\t ['strictly local']\n",
      "['heritage'] \n",
      "\t\t []\n",
      "\t\t []\n",
      "['phrases'] \n",
      "\t\t ['tion', 'prepositional phrases', 'as']\n",
      "\t\t ['prepositional phrases']\n",
      "['Narrativ', 'Title', 'Number', 'Concepts'] \n",
      "\t\t ['Topic', 'Topic', 'Title', 'Topic', 'Topic Narrative', 'Topic']\n",
      "\t\t ['Title', 'Topic Narrative']\n",
      "['Continuous Match Valu'] \n",
      "\t\t ['MN/length', 'Continuous Match Value', 'Continuous']\n",
      "\t\t ['MN/length', 'Continuous Match Value']\n",
      "['weighted average'] \n",
      "\t\t ['a', 'a', 'weighted average']\n",
      "\t\t ['weighted average']\n",
      "['Chinese Restaurant Processes', 'Dirichlet Processes'] \n",
      "\t\t ['Chinese Restaurant Processes', 'Dirichlet Processes']\n",
      "\t\t ['Chinese Restaurant Processes', 'Dirichlet Processes']\n",
      "['maximum entropy'] \n",
      "\t\t ['a', 'maximum entropy']\n",
      "\t\t ['maximum entropy']\n",
      "['word error rate'] \n",
      "\t\t ['a', 'word error rate']\n",
      "\t\t ['word error rate']\n",
      "['conjunct verbs', 'junct verbs', 'Non-MonoClausal  Verbs', 'Auxiliary Construction'] \n",
      "\t\t ['junct', 'verbs', 'Non-MonoClausal Verbs', 'Auxiliary Construction', 'conjunct verbs']\n",
      "\t\t ['Non-MonoClausal Verbs', 'Auxiliary Construction', 'conjunct verbs']\n",
      "['Majority Rule', 'Na??veBayes classifier'] \n",
      "\t\t ['Na ? ? veBayes', 'Majority Rule']\n",
      "\t\t ['Na ? ? veBayes', 'Majority Rule']\n",
      "['Early Modern German'] \n",
      "\t\t ['Early Modern German']\n",
      "\t\t ['Early Modern German']\n",
      "['phrase structure grmmmar'] \n",
      "\t\t ['a', 'as', 'a', 'phrase structure grmmmar']\n",
      "\t\t ['phrase structure grmmmar']\n",
      "['HOO shared task of 2012'] \n",
      "\t\t ['shared', 'HOO shared task of 2012', 'CoNLL-2013 shared task']\n",
      "\t\t ['HOO shared task of 2012', 'CoNLL-2013 shared task']\n",
      "['Probabilistic Latent Semantic Analysis', 'Canonical Correlation Analysis'] \n",
      "\t\t ['on', 'Canonical Correlation Analysis', 'Probabilistic Latent Semantic Analysis']\n",
      "\t\t ['Canonical Correlation Analysis', 'Probabilistic Latent Semantic Analysis']\n",
      "['relative clause', 'infinitival clause'] \n",
      "\t\t ['infinitival', 'clause', 'a', 'embedded relative clause']\n",
      "\t\t ['infinitival', 'embedded relative clause']\n",
      "['conditional random fields', 'support vector machines', 'hidden Markov models'] \n",
      "\t\t ['and', 'models', 'support vector machines', 'conditional random fields', 'and hidden Markov models']\n",
      "\t\t ['support vector machines', 'conditional random fields', 'and hidden Markov models']\n",
      "['Most Frequent Sense'] \n",
      "\t\t ['Most Frequent Sense']\n",
      "\t\t ['Most Frequent Sense']\n",
      "['Named Entity Recognition'] \n",
      "\t\t ['a Named Entity Recognition']\n",
      "\t\t ['a Named Entity Recognition']\n",
      "['term', 'intransitive verb'] \n",
      "\t\t ['a', 'verb phrase']\n",
      "\t\t ['verb phrase']\n",
      "['natural language processing'] \n",
      "\t\t ['a', 'in natural language processing']\n",
      "\t\t ['in natural language processing']\n",
      "['Language Resources'] \n",
      "\t\t ['Language Resources']\n",
      "\t\t ['Language Resources']\n",
      "['broadcast news'] \n",
      "\t\t ['a', 'broadcast news']\n",
      "\t\t ['broadcast news']\n",
      "['Detai l izat ion'] \n",
      "\t\t ['Detai l izat ion', 'a', 'i', 'ion', 'a', 'a', 's i']\n",
      "\t\t ['Detai l izat ion']\n",
      "[\"N='BYPASS':(SINGULAR\"] \n",
      "\t\t ['NPOS']\n",
      "\t\t ['NPOS']\n",
      "['Greedy String Tiling'] \n",
      "\t\t ['Greedy String Tiling']\n",
      "\t\t ['Greedy String Tiling']\n",
      "['California'] \n",
      "\t\t ['state', 'California : state']\n",
      "\t\t ['California : state']\n",
      "['support vector machine'] \n",
      "\t\t ['support vector machine']\n",
      "\t\t ['support vector machine']\n",
      "['Partial Least Squares Regression'] \n",
      "\t\t ['Partial Least Squares Regression', 'a']\n",
      "\t\t ['Partial Least Squares Regression']\n",
      "['Institute for Robotics and Intelligent Systems', 'Natural Sciences and Engineering Research Council'] \n",
      "\t\t ['is', 'a', 'Institute for Robotics and Intelligent Systems', 'and', 'e', 'Natural Sciences and Engineering Research']\n",
      "\t\t ['Institute for Robotics and Intelligent Systems', 'Natural Sciences and Engineering Research']\n",
      "['Chinese Treebank'] \n",
      "\t\t ['Chinese Treebank']\n",
      "\t\t ['Chinese Treebank']\n",
      "['Transactions on Information Systems'] \n",
      "\t\t ['a', 'Transactions on Information Systems']\n",
      "\t\t ['Transactions on Information Systems']\n",
      "['super abstract role value'] \n",
      "\t\t ['a', 'super abstract role value']\n",
      "\t\t ['super abstract role value']\n",
      "['Reduction Factor'] \n",
      "\t\t ['duction Factor', 'a', 'Reduction Factor', 'ion Factor', 'Reduction Factor', 'a', '( ss f', 'n (']\n",
      "\t\t ['Reduction Factor', 'Reduction Factor', '( ss f', 'n (']\n",
      "['training', 'training'] \n",
      "\t\t ['training corpus', 'training corpus']\n",
      "\t\t ['training corpus', 'training corpus']\n",
      "['Maschinelle Syntaxanalyse'] \n",
      "\t\t ['Maschinelle Syntaxanalyse', 'a']\n",
      "\t\t ['Maschinelle Syntaxanalyse']\n",
      "['argument structure'] \n",
      "\t\t ['argument structure']\n",
      "\t\t ['argument structure']\n",
      "['human effort'] \n",
      "\t\t ['human effort']\n",
      "\t\t ['human effort']\n",
      "['object'] \n",
      "\t\t ['focus']\n",
      "\t\t ['focus']\n",
      "['Named Entity Time'] \n",
      "\t\t ['a', 'it', 'a', 'Named Entity Time']\n",
      "\t\t ['Named Entity Time']\n",
      "['machine translation'] \n",
      "\t\t ['translation', 'on']\n",
      "\t\t ['translation']\n",
      "['Machine Translation', 'Information Retrieval', 'Natural Language Processing'] \n",
      "\t\t ['in', 'Information Retrieval', 'Natural Language Processing', 'in', 'in', 'n', 'al', 'In Machine Translation', 'at', 'in', 'a']\n",
      "\t\t ['Information Retrieval', 'Natural Language Processing', 'In Machine Translation']\n",
      "['BioNLP Shared Task'] \n",
      "\t\t ['a', 'as', 'BioNLP Shared Task 2013', 'BioNLP 2013', 'a']\n",
      "\t\t ['BioNLP Shared Task 2013', 'BioNLP 2013']\n",
      "['European Conference on Information Retrieval'] \n",
      "\t\t ['In', 'European Conference on Information Retrieval']\n",
      "\t\t ['European Conference on Information Retrieval']\n",
      "['machine translation'] \n",
      "\t\t ['translation', 'machine translation']\n",
      "\t\t ['machine translation']\n",
      "['Syntactic Tree Kernels', 'syntactic tree fragments', 'partial tree fragments'] \n",
      "\t\t ['syntactic', 'tree fragments', 'partial tree fragments', 'Syntactic Tree Kernels', 'a']\n",
      "\t\t ['syntactic', 'partial tree fragments', 'Syntactic Tree Kernels']\n",
      "['past tense'] \n",
      "\t\t ['Finite', 'in']\n",
      "\t\t ['Finite']\n",
      "['Gene Ontology'] \n",
      "\t\t ['Gene Ontology', 'to']\n",
      "\t\t ['Gene Ontology']\n",
      "['Minimum Bayes Risk'] \n",
      "\t\t ['Minimum Bayes Risk', 'in', 'in', 'a']\n",
      "\t\t ['Minimum Bayes Risk']\n",
      "['coreference resolution'] \n",
      "\t\t ['coreference resolution']\n",
      "\t\t ['coreference resolution']\n",
      "['Spontaneous  Scheduling Task'] \n",
      "\t\t ['Spontaneous Scheduling Task']\n",
      "\t\t ['Spontaneous Scheduling Task']\n",
      "['Wagner & Fischer'] \n",
      "\t\t ['Wagner & Fischer', '& F']\n",
      "\t\t ['Wagner & Fischer']\n",
      "['Longest Common Subsequenc'] \n",
      "\t\t ['Longest Common Subsequence']\n",
      "\t\t ['Longest Common Subsequence']\n",
      "['ocator'] \n",
      "\t\t ['locator', ', finder , location ,']\n",
      "\t\t ['locator', 'inde', 'ocatio']\n",
      "['Brown Laboratory for Linguistic Information Processing'] \n",
      "\t\t ['Laboratory for Linguistic Information Processing']\n",
      "\t\t ['Laboratory for Linguistic Information Processing']\n",
      "['2*P*R', 'precision', 'recall'] \n",
      "\t\t ['is precision', 'is recall', 'is', 'precision', 'a', 'a']\n",
      "\t\t ['is precision', 'is recall']\n",
      "['Similarity Core task'] \n",
      "\t\t ['Similarity', 'Semantic Textual Similarity Core']\n",
      "\t\t ['Semantic Textual Similarity Core']\n",
      "['broadcasting news', 'broadcasting conversation', 'magazine', 'newswire'] \n",
      "\t\t ['broadcasting conversation', 'broadcasting', 'news', 'Sinorama news magazine', 'newswire']\n",
      "\t\t ['broadcasting conversation', 'Sinorama news magazine', 'newswire']\n",
      "['Tree Adjoining Grammar'] \n",
      "\t\t ['Tree Adjoining Grammar', 'a Tree Adjoining Grammar']\n",
      "\t\t ['a Tree Adjoining Grammar']\n",
      "['language mode'] \n",
      "\t\t ['a', 'language model']\n",
      "\t\t ['language model']\n",
      "['Chinese Lexical Ontology'] \n",
      "\t\t ['Chinese', 'to', 'Chinese Lexical Ontology']\n",
      "\t\t ['Chinese Lexical Ontology']\n",
      "['Bernoulli Naive Bayes', 'Stochastic Gradient Descent'] \n",
      "\t\t ['Stochastic Gradient Descent', 'hinge loss Bernoulli Naive Bayes']\n",
      "\t\t ['Stochastic Gradient Descent', 'hinge loss Bernoulli Naive Bayes']\n",
      "['address changes to Betty Walker'] \n",
      "\t\t ['Betty Walker']\n",
      "\t\t ['Betty Walker']\n",
      "['nition'] \n",
      "\t\t ['named entity recognition']\n",
      "\t\t ['named entity recognition']\n",
      "['Warning Order - Method of Fire'] \n",
      "\t\t ['s', 'a Warning Order - Method of Fire', 'of']\n",
      "\t\t ['a Warning Order - Method of Fire']\n",
      "['CONTEXT SPACES'] \n",
      "\t\t ['CONTEXT SPACES']\n",
      "\t\t ['CONTEXT SPACES']\n",
      "['Maximum Entropy', 'Na??ve Bayes', 'Support Vector Machines'] \n",
      "\t\t ['Na ? ? ve Bayes', 'Maximum Entropy', 'Support Vector Machines']\n",
      "\t\t ['Na ? ? ve Bayes', 'Maximum Entropy', 'Support Vector Machines']\n",
      "['Basic Elements'] \n",
      "\t\t ['Basic Elements']\n",
      "\t\t ['Basic Elements']\n",
      "['Sistema'] \n",
      "\t\t ['Sistema de Escritura Alfab ? tica']\n",
      "\t\t ['Sistema de Escritura Alfab ? tica']\n",
      "['computing elements'] \n",
      "\t\t ['a', 'a', '8 computing elements', 'in']\n",
      "\t\t ['8 computing elements']\n",
      "['of Unithood'] \n",
      "\t\t ['Odds of Unithood', 'a']\n",
      "\t\t ['Odds of Unithood']\n",
      "['Word sense disambiguation'] \n",
      "\t\t ['sense disambiguation', 'is', 'at']\n",
      "\t\t ['sense disambiguation']\n",
      "['machine translation system'] \n",
      "\t\t ['a', 'system', 'a machine translation system', 'a']\n",
      "\t\t ['a machine translation system']\n",
      "['transcripts', 'text'] \n",
      "\t\t ['text', 'a scoring function']\n",
      "\t\t ['text', 'a scoring function']\n",
      "['linear precedence', 'domain'] \n",
      "\t\t ['a', 'a', 'linear precedence']\n",
      "\t\t ['linear precedence']\n",
      "['deterministic tree automaton'] \n",
      "\t\t ['i', 't ion', 'deterministic tree automaton', 'is a', 'is a']\n",
      "\t\t ['t ion', 'deterministic tree automaton']\n",
      "['Profile Hidden Markov Model'] \n",
      "\t\t ['Model', 'Profile Hidden Markov Model']\n",
      "\t\t ['Profile Hidden Markov Model']\n",
      "['linear precedenc'] \n",
      "\t\t ['linear precedence', 'immediate dominance']\n",
      "\t\t ['linear precedence', 'immediate dominance']\n",
      "['factorial CRF'] \n",
      "\t\t ['CRF']\n",
      "\t\t ['CRF']\n",
      "['Word sense disambiguation'] \n",
      "\t\t ['sense disambiguation', 'is a']\n",
      "\t\t ['sense disambiguation']\n",
      "['discourse units'] \n",
      "\t\t ['discourse units']\n",
      "\t\t ['discourse units']\n",
      "['bag of words'] \n",
      "\t\t ['a bag of words', 'of', 'of']\n",
      "\t\t ['a bag of words']\n",
      "['Natural Language Processing'] \n",
      "\t\t ['a', 'Natural Language Processing', 'in']\n",
      "\t\t ['Natural Language Processing']\n",
      "['Document Type Definition'] \n",
      "\t\t ['in', 'Document Type Definition']\n",
      "\t\t ['Document Type Definition']\n",
      "['syntactic structure'] \n",
      "\t\t ['a syntactic structure']\n",
      "\t\t ['a syntactic structure']\n",
      "['hashtag pattern', 'hashtag'] \n",
      "\t\t ['hashtag', 'hashtag pattern']\n",
      "\t\t ['hashtag pattern']\n",
      "['Document Understanding Conference'] \n",
      "\t\t ['on', 'in', 'Document Understanding Conference']\n",
      "\t\t ['Document Understanding Conference']\n",
      "['Information Retrieval'] \n",
      "\t\t ['Information Retrieval']\n",
      "\t\t ['Information Retrieval']\n",
      "['Independent Random Projections'] \n",
      "\t\t ['a', 'Independent Random Projections', 'In']\n",
      "\t\t ['Independent Random Projections']\n",
      "['restriction'] \n",
      "\t\t ['a', 'or is a quantifier whose', 'is']\n",
      "\t\t ['or is a quantifier whose']\n",
      "['wN'] \n",
      "\t\t []\n",
      "\t\t []\n",
      "['Multilingual Text'] \n",
      "\t\t ['Multilingual Text', 'Fools and Corpora', 'in']\n",
      "\t\t ['Multilingual Text', 'Fools and Corpora']\n",
      "['Computational Linguistics'] \n",
      "\t\t ['on Computational Linguistics']\n",
      "\t\t ['on Computational Linguistics']\n",
      "['Information Retrieval'] \n",
      "\t\t ['at', 'a', 'In', 'Information Retrieval']\n",
      "\t\t ['Information Retrieval']\n",
      "['amed Entity'] \n",
      "\t\t ['Entity Recognition']\n",
      "\t\t ['Entity Recognition']\n",
      "['correct BP'] \n",
      "\t\t ['precision']\n",
      "\t\t ['precision']\n",
      "['speaker independent', 'speaker adaptive'] \n",
      "\t\t ['a', 'in', 'speaker independent', 'speaker adaptive']\n",
      "\t\t ['speaker independent', 'speaker adaptive']\n",
      "['node link'] \n",
      "\t\t ['node link', 'node']\n",
      "\t\t ['node link']\n",
      "['statistical machine translation'] \n",
      "\t\t ['translation', 'translation', 'translation on', 'statistical machine translation']\n",
      "\t\t ['translation on', 'statistical machine translation']\n",
      "['named entity recognition'] \n",
      "\t\t ['named entity recognition']\n",
      "\t\t ['named entity recognition']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['target order', 'finally'] \n",
      "\t\t ['target order']\n",
      "\t\t ['target order']\n",
      "['rel loc'] \n",
      "\t\t ['prep rel', 'loc word', 'word', 'loc word']\n",
      "\t\t ['prep rel', 'loc word', 'loc word']\n",
      "['Oxford Pictorial English Dictionar'] \n",
      "\t\t ['o', 'Oxford Pictorial English Dictionary']\n",
      "\t\t ['Oxford Pictorial English Dictionary']\n",
      "['Domain Verb Association'] \n",
      "\t\t ['on', 'Domain Verb Association']\n",
      "\t\t ['Domain Verb Association']\n",
      "['Bhattacharyya coefficient'] \n",
      "\t\t ['Shannon divergence', 'Bhattacharyya coefficient']\n",
      "\t\t ['Shannon divergence', 'Bhattacharyya coefficient']\n",
      "['Words as Words'] \n",
      "\t\t ['Words as Words']\n",
      "\t\t ['Words as Words']\n",
      "['Arabic Language Technologies', 'Qatar Computing Research Institute'] \n",
      "\t\t ['Arabic Language Technologies', 'at Qatar Computing Research Institute', 'Qatar', 'in']\n",
      "\t\t ['Arabic Language Technologies', 'at Qatar Computing Research Institute']\n",
      "['Word Sense Disambiguatio'] \n",
      "\t\t ['s', 'a Word Sense Disambiguation']\n",
      "\t\t ['a Word Sense Disambiguation']\n",
      "['subject matter experts'] \n",
      "\t\t ['subject matter experts', 'a']\n",
      "\t\t ['subject matter experts']\n",
      "['development set'] \n",
      "\t\t ['development']\n",
      "\t\t ['development']\n",
      "['Compound nouns'] \n",
      "\t\t ['Compound', 'Compound nouns']\n",
      "\t\t ['Compound nouns']\n",
      "['dictionary'] \n",
      "\t\t []\n",
      "\t\t []\n",
      "['limited memory BFGS'] \n",
      "\t\t ['limited memory BFGS']\n",
      "\t\t ['limited memory BFGS']\n",
      "['Indirect Object', 'Direct Object', 'Subject', 'Verb', 'Ergative', 'Dative'] \n",
      "\t\t ['Object', 'Object']\n",
      "\t\t ['Object', 'Object']\n",
      "['Speaker', 'Friendship', 'Visibility', 'Route'] \n",
      "\t\t ['Speaker', 'Visibility', 'Route']\n",
      "\t\t ['Speaker', 'Visibility', 'Route']\n",
      "['Combinatory Categorial Grammar'] \n",
      "\t\t ['a', 'Combinatory Categorial Grammar', 'Grammar']\n",
      "\t\t ['Combinatory Categorial Grammar']\n",
      "['Pacific Asia  Conference on Language, Information and Com-  putation'] \n",
      "\t\t ['In', ',', 'on', ', Information and Com- putation', ',']\n",
      "\t\t ['In', 'nformation and Com- putation']\n",
      "[] \n",
      "\t\t []\n",
      "\t\t []\n",
      "['original candidate list'] \n",
      "\t\t ['original candidate list']\n",
      "\t\t ['original candidate list']\n",
      "['Subject', 'Object', 'Arguments', 'Indirect Object'] \n",
      "\t\t ['In', 'Arguments', 'Subject', 'Object', 'Indirect Object', 'Indirect']\n",
      "\t\t ['Arguments', 'Subject', 'Indirect Object']\n",
      "['Akaike Information Criterion'] \n",
      "\t\t ['a', 'In', 'Akaike Information Criterion', 'a', 'Akaike']\n",
      "\t\t ['Akaike Information Criterion']\n",
      "['Logical Graph'] \n",
      "\t\t ['Logical Graph', 'a']\n",
      "\t\t ['Logical Graph']\n",
      "['Abbreviation'] \n",
      "\t\t []\n",
      "\t\t []\n",
      "['language mode'] \n",
      "\t\t ['language model']\n",
      "\t\t ['language model']\n",
      "['linear order subgraph', 'parse structure subgraph'] \n",
      "\t\t ['a', 'structure subgraph', 'a', 'order subgraph']\n",
      "\t\t ['structure subgraph', 'order subgraph']\n",
      "['0fiice of Science and Technology Policy', 'Intergovernmental  Science, Engineering, and Technology Advisory Pane'] \n",
      "\t\t ['o f', 'w i', 't h i n', 'of Telecommmicatians Policy', 'of Science and Technology Policy', 'Science , Engineering , and Technology Advisory Panel']\n",
      "\t\t ['o f', 'w i', 't h i n', 'of Telecommmicatians Policy', 'of Science and Technology Policy', 'ngineerin', 'nd Technology Advisory Panel']\n",
      "['computing surveys'] \n",
      "\t\t ['in', 'computing surveys']\n",
      "\t\t ['computing surveys']\n",
      "['noun phrases'] \n",
      "\t\t ['noun phrases', 'pronouns', 'pronouns']\n",
      "\t\t ['noun phrases', 'pronouns', 'pronouns']\n",
      "['Web of Science'] \n",
      "\t\t ['s', 'Web of Science', 'of']\n",
      "\t\t ['Web of Science']\n",
      "['text mining', 'information extraction'] \n",
      "\t\t ['in', 'extraction', 'mining']\n",
      "\t\t ['extraction', 'mining']\n",
      "['Determiner', 'Preposition', 'Noun', 'Plural Noun', 'Possessive', 'Adjective'] \n",
      "\t\t ['Noun', 'Plural Noun', 'Determiner', 'Preposition', 'Possessive']\n",
      "\t\t ['Plural Noun', 'Determiner', 'Preposition', 'Possessive']\n",
      "['Computer Vision and Pattern Recognition'] \n",
      "\t\t ['Conference', 'on Computer Vision and Pattern Recognition']\n",
      "\t\t ['Conference', 'on Computer Vision and Pattern Recognition']\n",
      "['Microelectronics', 'F-Measure', 'Japanese', 'Spanish'] \n",
      "\t\t ['F', 'with Recall', 'Weighted Equally', 'Japanese', 'S', 'Spanish', 'Microelectronics', 't i l']\n",
      "\t\t ['F', 'with Recall', 'Weighted Equally', 'Japanese', 'Spanish', 'Microelectronics', 't i l']\n",
      "['GREC Named Entity Generation', 'Named Entity Reference Regeneration'] \n",
      "\t\t ['Generation', 'GREC', 'GREC Named Entity Generation', 'Named Entity Reference Detection', 'Named Entity Reference']\n",
      "\t\t ['GREC Named Entity Generation', 'Named Entity Reference Detection']\n",
      "['Selectional Preferences'] \n",
      "\t\t ['Selectional Preferences', 'in']\n",
      "\t\t ['Selectional Preferences']\n",
      "['lexical cohesion', 'repetition / content'] \n",
      "\t\t ['lexical cohesion', 'lexical cohesion', '/ content', 'repetition / content']\n",
      "\t\t ['lexical cohesion', 'lexical cohesion', 'repetition / content']\n",
      "['Empirical Methods in Natural Language Processing'] \n",
      "\t\t ['Methods in Natural Language Processing (']\n",
      "\t\t ['Methods in Natural Language Processing (']\n",
      "['Wathctower Society'] \n",
      "\t\t ['Wathctower Society']\n",
      "\t\t ['Wathctower Society']\n",
      "['deep averaging network'] \n",
      "\t\t ['an', 'deep averaging network', 'in']\n",
      "\t\t ['deep averaging network']\n",
      "['Web Person Search'] \n",
      "\t\t ['Web Person Search']\n",
      "\t\t ['Web Person Search']\n",
      "['independent verification and validation'] \n",
      "\t\t ['In', 'independent verification and validation', 'a']\n",
      "\t\t ['In', 'independent verification and validation']\n",
      "['machine translation'] \n",
      "\t\t ['a machine translation']\n",
      "\t\t ['a machine translation']\n",
      "['National Research Foundation'] \n",
      "\t\t ['a', 'Research Foundation']\n",
      "\t\t ['Research Foundation']\n",
      "['statistical machine translation'] \n",
      "\t\t ['a statistical machine translation', 'at', 'in']\n",
      "\t\t ['a statistical machine translation']\n",
      "['Log frequency', 'global entropy'] \n",
      "\t\t ['Log frequency', 'global entropy']\n",
      "\t\t ['Log frequency', 'global entropy']\n",
      "['agent semantic communications service'] \n",
      "\t\t ['agent semantic communications service']\n",
      "\t\t ['agent semantic communications service']\n",
      "['bag of words'] \n",
      "\t\t ['is', 'a', 'bag of words']\n",
      "\t\t ['bag of words']\n",
      "['same'] \n",
      "\t\t ['the', 'the', 'the', 'the', 'the']\n",
      "\t\t []\n",
      "['Index Thomisticus Treebank'] \n",
      "\t\t ['Index Thomisticus Treebank']\n",
      "\t\t ['Index Thomisticus Treebank']\n",
      "['Optimality Theory'] \n",
      "\t\t ['a', 'Optimality Theory', 'a']\n",
      "\t\t ['Optimality Theory']\n",
      "['True Negatives', 'False Negatives', 'True Positives', 'False Positives'] \n",
      "\t\t ['True Positives', 'False Positives', 'True Negatives', 'False Negatives', 'a']\n",
      "\t\t ['True Positives', 'False Positives', 'True Negatives', 'False Negatives']\n",
      "['Conditional Random Field'] \n",
      "\t\t ['Conditional Random Field']\n",
      "\t\t ['Conditional Random Field']\n",
      "['natural language', 'speech recognition', 'speech understanding'] \n",
      "\t\t ['in', 'speech recognition', 'natural language', 'or speech understanding']\n",
      "\t\t ['speech recognition', 'natural language', 'or speech understanding']\n",
      "['mean absolute difference'] \n",
      "\t\t ['man', 'mean absolute difference', 'a']\n",
      "\t\t ['man', 'mean absolute difference']\n",
      "['World Wide Web'] \n",
      "\t\t ['World Wide Web']\n",
      "\t\t ['World Wide Web']\n",
      "['Shakti Standard Format'] \n",
      "\t\t ['Standard Format']\n",
      "\t\t ['Standard Format']\n",
      "['Lexical Knowledge Bases'] \n",
      "\t\t ['a', 'Lexical Knowledge Bases']\n",
      "\t\t ['Lexical Knowledge Bases']\n",
      "['Simple recurrent networks'] \n",
      "\t\t ['networks', 'recurrent networks']\n",
      "\t\t ['recurrent networks']\n",
      "['machine translation'] \n",
      "\t\t ['in', 'machine translation']\n",
      "\t\t ['machine translation']\n",
      "['Document Input'] \n",
      "\t\t ['Input']\n",
      "\t\t ['Input']\n",
      "['Median Selection'] \n",
      "\t\t ['Median Selection', 'a']\n",
      "\t\t ['Median Selection']\n",
      "['dynamic programming'] \n",
      "\t\t ['in', 'dynamic programming']\n",
      "\t\t ['dynamic programming']\n",
      "['International Conference on Learning Representations'] \n",
      "\t\t ['In International Conference on Learning Representations']\n",
      "\t\t ['In International Conference on Learning Representations']\n",
      "['Discovering Inference Rules from Text'] \n",
      "\t\t ['Inference Rules from Text )', 'on']\n",
      "\t\t ['Inference Rules from Text )']\n",
      "['Conditional random field', 'Maximum Entropy Model'] \n",
      "\t\t ['Conditional', 'random field', 'an', 'Maximum Entropy Model']\n",
      "\t\t ['Conditional', 'random field', 'Maximum Entropy Model']\n",
      "['and potentially some'] \n",
      "\t\t []\n",
      "\t\t []\n",
      "['automatic speech recognition'] \n",
      "\t\t ['in automatic speech recognition']\n",
      "\t\t ['in automatic speech recognition']\n",
      "['Semantic Role Labeling'] \n",
      "\t\t ['in', 'a', 'Semantic Role Labeling', 'a', 'a']\n",
      "\t\t ['Semantic Role Labeling']\n",
      "['Main Verbs'] \n",
      "\t\t ['i', 'Main Verbs']\n",
      "\t\t ['Main Verbs']\n",
      "['Resource Description Framework'] \n",
      "\t\t ['Resource Description Framework']\n",
      "\t\t ['Resource Description Framework']\n",
      "['Background', 'Result', 'Objective', 'Method', 'Conclusion'] \n",
      "\t\t ['Results', 'is', 'Background', 'Objective', 'Method', 'Conclusion']\n",
      "\t\t ['Results', 'Background', 'Objective', 'Method', 'Conclusion']\n",
      "['Wall Street Journal'] \n",
      "\t\t ['Wall Street Journal']\n",
      "\t\t ['Wall Street Journal']\n",
      "['Gay', 'Obama', 'Abortion', 'Marijuana'] \n",
      "\t\t ['Abortion', 'Gay Rights', 'Obama', 'Marijuana']\n",
      "\t\t ['Abortion', 'Gay Rights', 'Obama', 'Marijuana']\n",
      "['ANTEST CALLED'] \n",
      "\t\t ['S', 'CALLED', \"1 I ANTEST CALLED FOR 4l ' I\"]\n",
      "\t\t [\"1 I ANTEST CALLED FOR 4l ' I\"]\n",
      "['Great Britain', 'British National Corpus', 'P,,nnsylvania'] \n",
      "\t\t ['Great Britain component', 'British National Corpus', 'in']\n",
      "\t\t ['Great Britain component', 'British National Corpus']\n",
      "['Beginning of a', 'Beginning of non committed belief chunk', 'Inside of a non committed belief chunk', 'Inside a not applicable'] \n",
      "\t\t ['Beginning of non committed belief', 'Inside of a non committed belief', 'Beginning of a not applicable']\n",
      "\t\t ['Beginning of non committed belief', 'Inside of a non committed belief', 'Beginning of a not applicable']\n",
      "['British National Corpus'] \n",
      "\t\t ['British National Corpus']\n",
      "\t\t ['British National Corpus']\n",
      "['Underspecified Segmented Discourse Representation Theory'] \n",
      "\t\t ['Segmented Discourse Representation Theory']\n",
      "\t\t ['Segmented Discourse Representation Theory']\n",
      "['Turkish Discourse Bank', 'Penn Discourse Tree Bank'] \n",
      "\t\t ['Turkish Discourse Bank', 'Penn Discourse Tree Bank', 'Turkish', 'a']\n",
      "\t\t ['Turkish Discourse Bank', 'Penn Discourse Tree Bank']\n",
      "['Natural Language Processing'] \n",
      "\t\t ['in', 'in', 'an', 'in a', 'Natural Language Processing']\n",
      "\t\t ['Natural Language Processing']\n",
      "['language model'] \n",
      "\t\t ['model', 'a', 'language model']\n",
      "\t\t ['language model']\n",
      "['language model'] \n",
      "\t\t ['language model', 'an', 'language model', 'a']\n",
      "\t\t ['language model', 'language model']\n",
      "['knowledge base'] \n",
      "\t\t ['a', 'a', 'a knowledge base', 'a morphological nalyzer', 'a']\n",
      "\t\t ['a knowledge base', 'a morphological nalyzer']\n",
      "['is worth noting'] \n",
      "\t\t ['worth noting']\n",
      "\t\t ['worth noting']\n",
      "['locus'] \n",
      "\t\t ['locus']\n",
      "\t\t ['locus']\n",
      "['NIF Standard'] \n",
      "\t\t ['and', 'a', 'and', 'NIF Standard', 'and', 'and']\n",
      "\t\t ['NIF Standard']\n",
      "['Same Sentence', 'Previous Sentence', 'precision'] \n",
      "\t\t ['Same', 'Sentence', 'Previous Sentence', 'precision']\n",
      "\t\t ['Same', 'Previous Sentence', 'precision']\n",
      "['noun phrase'] \n",
      "\t\t ['phrase', 'noun', 'noun phrase']\n",
      "\t\t ['noun phrase']\n",
      "['Minimum error rate training'] \n",
      "\t\t ['error rate training', 'in']\n",
      "\t\t ['error rate training']\n",
      "['temporal expression', 'trigger term', 'verb'] \n",
      "\t\t ['a', 'temporal expression', 'trigger term']\n",
      "\t\t ['temporal expression', 'trigger term']\n",
      "['Named Entities'] \n",
      "\t\t ['Entities', 'a']\n",
      "\t\t ['Entities']\n",
      "['language model'] \n",
      "\t\t ['a', 'an', 'a', 'a language model', 'a', 'a']\n",
      "\t\t ['a language model']\n",
      "['named entity', 'CoNLL'] \n",
      "\t\t ['named entity']\n",
      "\t\t ['named entity']\n",
      "['Princeton Wordnet'] \n",
      "\t\t ['in', 'Princeton Wordnet', 'n', 'or']\n",
      "\t\t ['Princeton Wordnet']\n",
      "['information retrieval', 'Question Answering'] \n",
      "\t\t ['Question Answering', 'or', 'information retrieval']\n",
      "\t\t ['Question Answering', 'information retrieval']\n",
      "['Prefix Counted'] \n",
      "\t\t ['Prefix Counted Rule']\n",
      "\t\t ['Prefix Counted Rule']\n",
      "['Segment frequency'] \n",
      "\t\t ['a', 'Segment frequency']\n",
      "\t\t ['Segment frequency']\n",
      "['latent semantic analysis'] \n",
      "\t\t ['latent semantic analysis', 'al']\n",
      "\t\t ['latent semantic analysis']\n",
      "['inflectional groups'] \n",
      "\t\t ['r', 'r', 'al', 'inflectional groups', 'a']\n",
      "\t\t ['inflectional groups']\n",
      "['Shallow Semantic Tree Kernel'] \n",
      "\t\t ['a', 'Shallow Semantic Tree Kernel']\n",
      "\t\t ['Shallow Semantic Tree Kernel']\n",
      "['interlingual index'] \n",
      "\t\t ['interlingual index']\n",
      "\t\t ['interlingual index']\n",
      "['Previous', 'Main verb', 'Boolean feature for MV'] \n",
      "\t\t ['Boolean', 'for MV', 'Previous', 'sentence', 'for']\n",
      "\t\t ['Boolean', 'for MV', 'Previous', 'sentence']\n",
      "['Generalized Expectation'] \n",
      "\t\t ['Generalized Expectation']\n",
      "\t\t ['Generalized Expectation']\n",
      "['itlll pluase eltil'] \n",
      "\t\t []\n",
      "\t\t []\n",
      "['United List of Artist Names)17'] \n",
      "\t\t ['United List of Artist', 'of']\n",
      "\t\t ['United List of Artist']\n",
      "['referential net'] \n",
      "\t\t ['a', 'referential net']\n",
      "\t\t ['referential net']\n",
      "[] \n",
      "\t\t []\n",
      "\t\t []\n",
      "['FARABUIDO MARTI NATIONAL LIBERATION'] \n",
      "\t\t ['A', 'MARTI NATIONAL']\n",
      "\t\t ['MARTI NATIONAL']\n",
      "['position independent'] \n",
      "\t\t ['error rate', 'independent']\n",
      "\t\t ['error rate', 'independent']\n",
      "['label propagation'] \n",
      "\t\t ['a label propagation']\n",
      "\t\t ['a label propagation']\n",
      "['Community question answering'] \n",
      "\t\t ['question answering', 'question']\n",
      "\t\t ['question answering']\n",
      "['newswire', 'broadcast news', 'broadcast conversation'] \n",
      "\t\t ['a', 'newswire', 'broadcast news', 'broadcast conversation']\n",
      "\t\t ['newswire', 'broadcast news', 'broadcast conversation']\n",
      "['viewpoint'] \n",
      "\t\t ['a', 'viewpoint']\n",
      "\t\t ['viewpoint']\n",
      "['anaphora resolution'] \n",
      "\t\t ['an', 'anaphora resolution']\n",
      "\t\t ['anaphora resolution']\n",
      "['FrameNet'] \n",
      "\t\t ['FrameNet']\n",
      "\t\t ['FrameNet']\n",
      "['part of speech'] \n",
      "\t\t ['part of speech']\n",
      "\t\t ['part of speech']\n",
      "['part of speech'] \n",
      "\t\t ['a', 'part of speech']\n",
      "\t\t ['part of speech']\n",
      "['Phonetic', 'Symbols', 'Spelling'] \n",
      "\t\t ['Phonetic/Sound', 'Spelling']\n",
      "\t\t ['Phonetic/Sound', 'Spelling']\n",
      "['Radiology and', 'Discharge Summary', 'Echocardiogram', 'Emergency Department', 'Gastrointestinal', 'Surgical Pathology'] \n",
      "\t\t ['Discharge Summary', 'Echo', 'Echocardiogram', 'Emergency Department', 'Operative', 'Gastrointestinal', 'Radiology', 'Surgical Pathology']\n",
      "\t\t ['Discharge Summary', 'Echocardiogram', 'Emergency Department', 'Operative', 'Gastrointestinal', 'Radiology', 'Surgical Pathology']\n",
      "['overt displays'] \n",
      "\t\t ['overt displays of power', 'in']\n",
      "\t\t ['overt displays of power']\n",
      "['facility', 'organization', 'geo-political entity', 'weapon', 'vehicle', 'location'] \n",
      "\t\t ['organization', 'geo-political entity', 'weapon', 'vehicle', 'location', 'facility']\n",
      "\t\t ['organization', 'geo-political entity', 'weapon', 'vehicle', 'location', 'facility']\n",
      "['machine translation'] \n",
      "\t\t ['a', 'machine translation', 'on', 'a']\n",
      "\t\t ['machine translation']\n",
      "['Double Levenshtein?s Edit Distance'] \n",
      "\t\t ['is a', 'Levenshtein ? s Edit Distance']\n",
      "\t\t ['Levenshtein ? s Edit Distance']\n",
      "['Modified Head Grammars'] \n",
      "\t\t ['s', 'Modified Head Grammars']\n",
      "\t\t ['Modified Head Grammars']\n",
      "['concept sequence instances'] \n",
      "\t\t ['concept sequence instances']\n",
      "\t\t ['concept sequence instances']\n",
      "['Transformation Based Learning'] \n",
      "\t\t ['Transformation Based Learning']\n",
      "\t\t ['Transformation Based Learning']\n",
      "['Maximum Entropy'] \n",
      "\t\t ['Maximum Entropy', 'a']\n",
      "\t\t ['Maximum Entropy']\n",
      "['Class Speaker HMM'] \n",
      "\t\t ['a', 'hidden Markov', 'HMM', 'Class Speaker HMM']\n",
      "\t\t ['hidden Markov', 'Class Speaker HMM']\n",
      "['Chieu and Ng', 'Florian'] \n",
      "\t\t ['Florian', 'and', 'Chieu and Ng']\n",
      "\t\t ['Florian', 'Chieu and Ng']\n",
      "['Question Answering'] \n",
      "\t\t ['Answering']\n",
      "\t\t ['Answering']\n",
      "['Empirical Methods in Natural Language Processing'] \n",
      "\t\t ['Empirical Methods in Natural Language Processing']\n",
      "\t\t ['Empirical Methods in Natural Language Processing']\n",
      "['Knowledge Base'] \n",
      "\t\t ['Knowledge Base', 'a']\n",
      "\t\t ['Knowledge Base']\n",
      "['abstracts', 'titles', 'authors', 'Journals'] \n",
      "\t\t ['th', 'representations abstracts', 'titles', 'authors', 'Journals']\n",
      "\t\t ['representations abstracts', 'titles', 'authors', 'Journals']\n",
      "['learning to rank'] \n",
      "\t\t ['a', 'to rank', 'in']\n",
      "\t\t ['to rank']\n",
      "['Topic models'] \n",
      "\t\t ['Topic models', 'a']\n",
      "\t\t ['Topic models']\n",
      "['Automatic Genre Classification'] \n",
      "\t\t ['a', 'Automatic Topic Classification', 'Automatic Genre Classification']\n",
      "\t\t ['Automatic Topic Classification', 'Automatic Genre Classification']\n",
      "['Omission Rate'] \n",
      "\t\t ['Omission Rate']\n",
      "\t\t ['Omission Rate']\n",
      "['noun', 'adjectives', 'name'] \n",
      "\t\t ['match', 'noun', 'noun', 'name']\n",
      "\t\t ['match', 'noun', 'noun', 'name']\n",
      "['Sentence Position Yield'] \n",
      "\t\t ['Sentence Position Yield']\n",
      "\t\t ['Sentence Position Yield']\n",
      "['inflectional property sets'] \n",
      "\t\t ['inflectional property sets', 'inflectional']\n",
      "\t\t ['inflectional property sets']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "en_stop_words = set(stopwords.words('english'))\n",
    "\n",
    "#df = pd.read_csv('eng_scientific_dev_xb_512.tsv', sep='\\t')\n",
    "\n",
    "def string_to_list(string):\n",
    "    return [e.strip()[1:-1] for e in string[1:-1].split(\",\")]\n",
    "\n",
    "def get_reduced_list(pred_list):\n",
    "    new_lf_pred = []\n",
    "   \n",
    "    for form1 in string_to_list(pred_list):        \n",
    "        flag = True                \n",
    "        \n",
    "        if not [x for x in form1.split() if x not in en_stop_words]: \n",
    "            continue\n",
    "        \n",
    "        for form2 in string_to_list(pred_list):            \n",
    "            if form1 == form2: \n",
    "                continue\n",
    "        \n",
    "            if form1 in form2:\n",
    "                flag = False\n",
    "                break\n",
    "                \n",
    "        if flag: \n",
    "            new_lf_pred.append(form1)\n",
    "        \n",
    "            \n",
    "            \n",
    "    return new_lf_pred\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    print(row[\"long-forms-text\"], \"\\n\\t\\t\", row[\"LF_Pred\"])\n",
    "    print(\"\\t\\t\", get_reduced_list(row[\"LF_Pred\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying function on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file cleaned_longform already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir cleaned_longform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sadan\\OneDrive\\GitHub\\PR-AAAI22-SDU-ST1-AE\\results\\finetuned_models\\model_all_xb_v1_512\\output\\cleaned_longform\n"
     ]
    }
   ],
   "source": [
    "cd cleaned_longform/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_leg = pd.read_csv('eng_legal_dev_xb_512.csv', sep='\\t')\n",
    "dan =  pd.read_csv('dan_dev_xb_512.csv', sep='\\t')\n",
    "esp =  pd.read_csv('esp_dev_xb_512.csv', sep='\\t')\n",
    "fre =  pd.read_csv('fre_dev_xb_512.csv', sep='\\t')\n",
    "per =  pd.read_csv('per_dev_xb_512.csv', sep='\\t')\n",
    "vie =  pd.read_csv('vie_dev_xb_512.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sadan\\OneDrive\\GitHub\\PR-AAAI22-SDU-ST1-AE\\results\\finetuned_models\\model_all_xb_v1_512\\output\\cleaned_longform\n"
     ]
    }
   ],
   "source": [
    "cd cleaned_longform/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df(eng_leg,'cl_eng_leg_dev')\n",
    "clean_df(dan,'cl_dan_dev')\n",
    "clean_df(esp,'cl_esp_dev')\n",
    "clean_df(fre,'cl_fre_dev')\n",
    "clean_df(per,'cl_per_dev')\n",
    "clean_df(vie,'cl_vie_dev')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating Jsons with the new indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>acronyms</th>\n",
       "      <th>long-forms</th>\n",
       "      <th>acronyms-text</th>\n",
       "      <th>long-forms-text</th>\n",
       "      <th>AN_Pred</th>\n",
       "      <th>LF_Pred</th>\n",
       "      <th>AN_Pred_idxs</th>\n",
       "      <th>LF_Pred_idxs</th>\n",
       "      <th>cl_lf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2 Related Work The availability of emotion-ric...</td>\n",
       "      <td>[[162, 165]]</td>\n",
       "      <td>[[144, 160]]</td>\n",
       "      <td>['TDM']</td>\n",
       "      <td>['Text Data Mining']</td>\n",
       "      <td>['TDM']</td>\n",
       "      <td>['a', 'Text Data Mining']</td>\n",
       "      <td>[[162, 165]]</td>\n",
       "      <td>[[5, 6], [144, 160]]</td>\n",
       "      <td>[Text Data Mining]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>WebDict 0.2919 Backoff 0.3282 Table 1: Mean Av...</td>\n",
       "      <td>[[63, 66]]</td>\n",
       "      <td>[[39, 61]]</td>\n",
       "      <td>['MAP']</td>\n",
       "      <td>['Mean Average Precision']</td>\n",
       "      <td>['MAP']</td>\n",
       "      <td>['Mean Average Precision']</td>\n",
       "      <td>[[63, 66]]</td>\n",
       "      <td>[[39, 61]]</td>\n",
       "      <td>[Mean Average Precision]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Baselines are a unigram query likelihood (QL) ...</td>\n",
       "      <td>[[113, 115], [42, 45], [153, 156]]</td>\n",
       "      <td>[[90, 111], [132, 151]]</td>\n",
       "      <td>['SD', 'QL)', 'MRF']</td>\n",
       "      <td>['sequential dependence', 'Markov random field']</td>\n",
       "      <td>['QL', 'SD', 'MRF']</td>\n",
       "      <td>['a', 'query likelihood', 'and a', 'sequential...</td>\n",
       "      <td>[[42, 44], [113, 115], [153, 156]]</td>\n",
       "      <td>[[1, 2], [24, 40], [67, 72], [90, 111], [132, ...</td>\n",
       "      <td>[query likelihood, sequential dependence, Mark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>tion. Then, we extract expansion terms from th...</td>\n",
       "      <td>[[92, 95]]</td>\n",
       "      <td>[[65, 90]]</td>\n",
       "      <td>['PRF']</td>\n",
       "      <td>['pseudo relevance feedback']</td>\n",
       "      <td>['PRF']</td>\n",
       "      <td>['pseudo relevance feedback', 'in']</td>\n",
       "      <td>[[92, 95]]</td>\n",
       "      <td>[[65, 90], [61, 63]]</td>\n",
       "      <td>[pseudo relevance feedback]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>person, mood, voice and case, CATiB uses 6 POS...</td>\n",
       "      <td>[[130, 134], [30, 35], [43, 46], [53, 56], [15...</td>\n",
       "      <td>[[136, 142], [156, 161]]</td>\n",
       "      <td>['PROP', 'CATiB', 'POS', 'NOM', 'VRB', 'VRB-PA...</td>\n",
       "      <td>['proper', 'verbs']</td>\n",
       "      <td>['CATiB', 'POS', 'NOM', 'PROP', 'VRB']</td>\n",
       "      <td>['non-proper', 'nouns', 'proper nouns', 'verbs']</td>\n",
       "      <td>[[30, 35], [43, 46], [53, 56], [130, 134], [15...</td>\n",
       "      <td>[[58, 68], [88, 93], [136, 148], [122, 127]]</td>\n",
       "      <td>[non-proper, proper nouns, verbs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>(LDA), Maximum Likelihood Linear Transform (ML...</td>\n",
       "      <td>[[115, 118], [44, 48], [87, 91]]</td>\n",
       "      <td>[[94, 113], [7, 42], [51, 85]]</td>\n",
       "      <td>['MPE', 'MLLT', 'BMMI']</td>\n",
       "      <td>['Minimum Phone Error', 'Maximum Likelihood Li...</td>\n",
       "      <td>['LDA', 'MLLT', 'BMMI', 'MPE']</td>\n",
       "      <td>['Maximum Likelihood Linear Transform', 'Boost...</td>\n",
       "      <td>[[1, 4], [44, 48], [87, 91], [115, 118]]</td>\n",
       "      <td>[[7, 42], [51, 85], [94, 113]]</td>\n",
       "      <td>[Maximum Likelihood Linear Transform, Boosted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>gold label (Section 3). Our algorithm is calle...</td>\n",
       "      <td>[[95, 99]]</td>\n",
       "      <td>[[52, 93]]</td>\n",
       "      <td>['SWVP']</td>\n",
       "      <td>['Structured Weighted Violations Perceptron']</td>\n",
       "      <td>['SWVP']</td>\n",
       "      <td>['Structured Weighted Violations Perceptron', ...</td>\n",
       "      <td>[[95, 99]]</td>\n",
       "      <td>[[52, 93], [129, 133]]</td>\n",
       "      <td>[Structured Weighted Violations Perceptron]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>phrase markers or words. For simplicity of man...</td>\n",
       "      <td>[[149, 152]]</td>\n",
       "      <td>[[128, 147]]</td>\n",
       "      <td>['CNF']</td>\n",
       "      <td>['Chomsky Normal Form']</td>\n",
       "      <td>['CNF']</td>\n",
       "      <td>['or', 'Chomsky Normal Form']</td>\n",
       "      <td>[[149, 152]]</td>\n",
       "      <td>[[15, 17], [128, 147]]</td>\n",
       "      <td>[Chomsky Normal Form]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>When a CFG is associated with probabilistic i...</td>\n",
       "      <td>[[85, 89], [8, 11]]</td>\n",
       "      <td>[[66, 83]]</td>\n",
       "      <td>['PCFG', 'CFG']</td>\n",
       "      <td>['Probabilistic CFG']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['a CFG is', 'a Probabilistic CFG', 'n']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[5, 13], [63, 82], [3, 4]]</td>\n",
       "      <td>[Probabilistic CFG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1] proposed a language-neutral framework for r...</td>\n",
       "      <td>[[128, 131]]</td>\n",
       "      <td>[[103, 126]]</td>\n",
       "      <td>['LNS']</td>\n",
       "      <td>['Language Neutral Syntax']</td>\n",
       "      <td>['LNS']</td>\n",
       "      <td>['a', 'Language Neutral Syntax']</td>\n",
       "      <td>[[128, 131]]</td>\n",
       "      <td>[[12, 13], [103, 126]]</td>\n",
       "      <td>[Language Neutral Syntax]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               text  \\\n",
       "0   1  2 Related Work The availability of emotion-ric...   \n",
       "1   2  WebDict 0.2919 Backoff 0.3282 Table 1: Mean Av...   \n",
       "2   3  Baselines are a unigram query likelihood (QL) ...   \n",
       "3   4  tion. Then, we extract expansion terms from th...   \n",
       "4   5  person, mood, voice and case, CATiB uses 6 POS...   \n",
       "5   6  (LDA), Maximum Likelihood Linear Transform (ML...   \n",
       "6   7  gold label (Section 3). Our algorithm is calle...   \n",
       "7   8  phrase markers or words. For simplicity of man...   \n",
       "8   9   When a CFG is associated with probabilistic i...   \n",
       "9  10  1] proposed a language-neutral framework for r...   \n",
       "\n",
       "                                            acronyms  \\\n",
       "0                                       [[162, 165]]   \n",
       "1                                         [[63, 66]]   \n",
       "2                 [[113, 115], [42, 45], [153, 156]]   \n",
       "3                                         [[92, 95]]   \n",
       "4  [[130, 134], [30, 35], [43, 46], [53, 56], [15...   \n",
       "5                   [[115, 118], [44, 48], [87, 91]]   \n",
       "6                                         [[95, 99]]   \n",
       "7                                       [[149, 152]]   \n",
       "8                                [[85, 89], [8, 11]]   \n",
       "9                                       [[128, 131]]   \n",
       "\n",
       "                       long-forms  \\\n",
       "0                    [[144, 160]]   \n",
       "1                      [[39, 61]]   \n",
       "2         [[90, 111], [132, 151]]   \n",
       "3                      [[65, 90]]   \n",
       "4        [[136, 142], [156, 161]]   \n",
       "5  [[94, 113], [7, 42], [51, 85]]   \n",
       "6                      [[52, 93]]   \n",
       "7                    [[128, 147]]   \n",
       "8                      [[66, 83]]   \n",
       "9                    [[103, 126]]   \n",
       "\n",
       "                                       acronyms-text  \\\n",
       "0                                            ['TDM']   \n",
       "1                                            ['MAP']   \n",
       "2                               ['SD', 'QL)', 'MRF']   \n",
       "3                                            ['PRF']   \n",
       "4  ['PROP', 'CATiB', 'POS', 'NOM', 'VRB', 'VRB-PA...   \n",
       "5                            ['MPE', 'MLLT', 'BMMI']   \n",
       "6                                           ['SWVP']   \n",
       "7                                            ['CNF']   \n",
       "8                                    ['PCFG', 'CFG']   \n",
       "9                                            ['LNS']   \n",
       "\n",
       "                                     long-forms-text  \\\n",
       "0                               ['Text Data Mining']   \n",
       "1                         ['Mean Average Precision']   \n",
       "2   ['sequential dependence', 'Markov random field']   \n",
       "3                      ['pseudo relevance feedback']   \n",
       "4                                ['proper', 'verbs']   \n",
       "5  ['Minimum Phone Error', 'Maximum Likelihood Li...   \n",
       "6      ['Structured Weighted Violations Perceptron']   \n",
       "7                            ['Chomsky Normal Form']   \n",
       "8                              ['Probabilistic CFG']   \n",
       "9                        ['Language Neutral Syntax']   \n",
       "\n",
       "                                  AN_Pred  \\\n",
       "0                                 ['TDM']   \n",
       "1                                 ['MAP']   \n",
       "2                     ['QL', 'SD', 'MRF']   \n",
       "3                                 ['PRF']   \n",
       "4  ['CATiB', 'POS', 'NOM', 'PROP', 'VRB']   \n",
       "5          ['LDA', 'MLLT', 'BMMI', 'MPE']   \n",
       "6                                ['SWVP']   \n",
       "7                                 ['CNF']   \n",
       "8                                      []   \n",
       "9                                 ['LNS']   \n",
       "\n",
       "                                             LF_Pred  \\\n",
       "0                          ['a', 'Text Data Mining']   \n",
       "1                         ['Mean Average Precision']   \n",
       "2  ['a', 'query likelihood', 'and a', 'sequential...   \n",
       "3                ['pseudo relevance feedback', 'in']   \n",
       "4   ['non-proper', 'nouns', 'proper nouns', 'verbs']   \n",
       "5  ['Maximum Likelihood Linear Transform', 'Boost...   \n",
       "6  ['Structured Weighted Violations Perceptron', ...   \n",
       "7                      ['or', 'Chomsky Normal Form']   \n",
       "8           ['a CFG is', 'a Probabilistic CFG', 'n']   \n",
       "9                   ['a', 'Language Neutral Syntax']   \n",
       "\n",
       "                                        AN_Pred_idxs  \\\n",
       "0                                       [[162, 165]]   \n",
       "1                                         [[63, 66]]   \n",
       "2                 [[42, 44], [113, 115], [153, 156]]   \n",
       "3                                         [[92, 95]]   \n",
       "4  [[30, 35], [43, 46], [53, 56], [130, 134], [15...   \n",
       "5           [[1, 4], [44, 48], [87, 91], [115, 118]]   \n",
       "6                                         [[95, 99]]   \n",
       "7                                       [[149, 152]]   \n",
       "8                                                 []   \n",
       "9                                       [[128, 131]]   \n",
       "\n",
       "                                        LF_Pred_idxs  \\\n",
       "0                               [[5, 6], [144, 160]]   \n",
       "1                                         [[39, 61]]   \n",
       "2  [[1, 2], [24, 40], [67, 72], [90, 111], [132, ...   \n",
       "3                               [[65, 90], [61, 63]]   \n",
       "4       [[58, 68], [88, 93], [136, 148], [122, 127]]   \n",
       "5                     [[7, 42], [51, 85], [94, 113]]   \n",
       "6                             [[52, 93], [129, 133]]   \n",
       "7                             [[15, 17], [128, 147]]   \n",
       "8                        [[5, 13], [63, 82], [3, 4]]   \n",
       "9                             [[12, 13], [103, 126]]   \n",
       "\n",
       "                                               cl_lf  \n",
       "0                                 [Text Data Mining]  \n",
       "1                           [Mean Average Precision]  \n",
       "2  [query likelihood, sequential dependence, Mark...  \n",
       "3                        [pseudo relevance feedback]  \n",
       "4                  [non-proper, proper nouns, verbs]  \n",
       "5  [Maximum Likelihood Linear Transform, Boosted ...  \n",
       "6        [Structured Weighted Violations Perceptron]  \n",
       "7                              [Chomsky Normal Form]  \n",
       "8                                [Probabilistic CFG]  \n",
       "9                          [Language Neutral Syntax]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cl_lf'] = data['LF_Pred'].apply(get_reduced_list)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get indices for long froms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(keywords,texts):\n",
    " \n",
    "    TRAIN_DATA = []\n",
    "\n",
    "    for text in texts:\n",
    "        entities = []\n",
    "        t_low = text.lower()\n",
    "        for keyword in keywords:\n",
    "            k_low = keyword.lower()\n",
    "            begin = t_low.find(k_low) # index if substring found and -1 otherwise\n",
    "            if begin != -1:\n",
    "                end = begin + len(keyword)\n",
    "                entities.append([begin, end])\n",
    "        TRAIN_DATA.extend(entities)\n",
    "        return TRAIN_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = [[t] for t in data.text.to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12 Base+FrameNet (FN) 61.8 71.9 66.5 59.8 69.3 64.2 53.5 60.0 56.6 51.1 57.9 54.3 13 Base+Verb Pairs (VP) 62.1 72.2 66.8 60.1 69.3 64.4 54.4 60.1 57.1 51.9 58.2 54.9 14 Base+Appositives (AP) 63.1 71.7 67.1 60.5 69.4 64.6 54.1 60.1 56.9 51.9 57.8 54.7 Table 1: Results obtained by applying different types of features in isolation to the Baseline system.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = data.cl_lf.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "indeces = []\n",
    "\n",
    "for l , t in zip(lf,tx):\n",
    "    indeces.append(get_index(l,t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>acronyms</th>\n",
       "      <th>long-forms</th>\n",
       "      <th>acronyms-text</th>\n",
       "      <th>long-forms-text</th>\n",
       "      <th>AN_Pred</th>\n",
       "      <th>LF_Pred</th>\n",
       "      <th>AN_Pred_idxs</th>\n",
       "      <th>LF_Pred_idxs</th>\n",
       "      <th>cl_lf</th>\n",
       "      <th>cl_lf_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2 Related Work The availability of emotion-ric...</td>\n",
       "      <td>[[162, 165]]</td>\n",
       "      <td>[[144, 160]]</td>\n",
       "      <td>['TDM']</td>\n",
       "      <td>['Text Data Mining']</td>\n",
       "      <td>['TDM']</td>\n",
       "      <td>['a', 'Text Data Mining']</td>\n",
       "      <td>[[162, 165]]</td>\n",
       "      <td>[[5, 6], [144, 160]]</td>\n",
       "      <td>[Text Data Mining]</td>\n",
       "      <td>[[144, 160]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>WebDict 0.2919 Backoff 0.3282 Table 1: Mean Av...</td>\n",
       "      <td>[[63, 66]]</td>\n",
       "      <td>[[39, 61]]</td>\n",
       "      <td>['MAP']</td>\n",
       "      <td>['Mean Average Precision']</td>\n",
       "      <td>['MAP']</td>\n",
       "      <td>['Mean Average Precision']</td>\n",
       "      <td>[[63, 66]]</td>\n",
       "      <td>[[39, 61]]</td>\n",
       "      <td>[Mean Average Precision]</td>\n",
       "      <td>[[39, 61]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Baselines are a unigram query likelihood (QL) ...</td>\n",
       "      <td>[[113, 115], [42, 45], [153, 156]]</td>\n",
       "      <td>[[90, 111], [132, 151]]</td>\n",
       "      <td>['SD', 'QL)', 'MRF']</td>\n",
       "      <td>['sequential dependence', 'Markov random field']</td>\n",
       "      <td>['QL', 'SD', 'MRF']</td>\n",
       "      <td>['a', 'query likelihood', 'and a', 'sequential...</td>\n",
       "      <td>[[42, 44], [113, 115], [153, 156]]</td>\n",
       "      <td>[[1, 2], [24, 40], [67, 72], [90, 111], [132, ...</td>\n",
       "      <td>[query likelihood, sequential dependence, Mark...</td>\n",
       "      <td>[[24, 40], [90, 111], [132, 151]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>tion. Then, we extract expansion terms from th...</td>\n",
       "      <td>[[92, 95]]</td>\n",
       "      <td>[[65, 90]]</td>\n",
       "      <td>['PRF']</td>\n",
       "      <td>['pseudo relevance feedback']</td>\n",
       "      <td>['PRF']</td>\n",
       "      <td>['pseudo relevance feedback', 'in']</td>\n",
       "      <td>[[92, 95]]</td>\n",
       "      <td>[[65, 90], [61, 63]]</td>\n",
       "      <td>[pseudo relevance feedback]</td>\n",
       "      <td>[[65, 90]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>person, mood, voice and case, CATiB uses 6 POS...</td>\n",
       "      <td>[[130, 134], [30, 35], [43, 46], [53, 56], [15...</td>\n",
       "      <td>[[136, 142], [156, 161]]</td>\n",
       "      <td>['PROP', 'CATiB', 'POS', 'NOM', 'VRB', 'VRB-PA...</td>\n",
       "      <td>['proper', 'verbs']</td>\n",
       "      <td>['CATiB', 'POS', 'NOM', 'PROP', 'VRB']</td>\n",
       "      <td>['non-proper', 'nouns', 'proper nouns', 'verbs']</td>\n",
       "      <td>[[30, 35], [43, 46], [53, 56], [130, 134], [15...</td>\n",
       "      <td>[[58, 68], [88, 93], [136, 148], [122, 127]]</td>\n",
       "      <td>[non-proper, proper nouns, verbs]</td>\n",
       "      <td>[[58, 68], [136, 148], [122, 127]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>(LDA), Maximum Likelihood Linear Transform (ML...</td>\n",
       "      <td>[[115, 118], [44, 48], [87, 91]]</td>\n",
       "      <td>[[94, 113], [7, 42], [51, 85]]</td>\n",
       "      <td>['MPE', 'MLLT', 'BMMI']</td>\n",
       "      <td>['Minimum Phone Error', 'Maximum Likelihood Li...</td>\n",
       "      <td>['LDA', 'MLLT', 'BMMI', 'MPE']</td>\n",
       "      <td>['Maximum Likelihood Linear Transform', 'Boost...</td>\n",
       "      <td>[[1, 4], [44, 48], [87, 91], [115, 118]]</td>\n",
       "      <td>[[7, 42], [51, 85], [94, 113]]</td>\n",
       "      <td>[Maximum Likelihood Linear Transform, Boosted ...</td>\n",
       "      <td>[[7, 42], [51, 85], [94, 113]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>gold label (Section 3). Our algorithm is calle...</td>\n",
       "      <td>[[95, 99]]</td>\n",
       "      <td>[[52, 93]]</td>\n",
       "      <td>['SWVP']</td>\n",
       "      <td>['Structured Weighted Violations Perceptron']</td>\n",
       "      <td>['SWVP']</td>\n",
       "      <td>['Structured Weighted Violations Perceptron', ...</td>\n",
       "      <td>[[95, 99]]</td>\n",
       "      <td>[[52, 93], [129, 133]]</td>\n",
       "      <td>[Structured Weighted Violations Perceptron]</td>\n",
       "      <td>[[52, 93]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>phrase markers or words. For simplicity of man...</td>\n",
       "      <td>[[149, 152]]</td>\n",
       "      <td>[[128, 147]]</td>\n",
       "      <td>['CNF']</td>\n",
       "      <td>['Chomsky Normal Form']</td>\n",
       "      <td>['CNF']</td>\n",
       "      <td>['or', 'Chomsky Normal Form']</td>\n",
       "      <td>[[149, 152]]</td>\n",
       "      <td>[[15, 17], [128, 147]]</td>\n",
       "      <td>[Chomsky Normal Form]</td>\n",
       "      <td>[[128, 147]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>When a CFG is associated with probabilistic i...</td>\n",
       "      <td>[[85, 89], [8, 11]]</td>\n",
       "      <td>[[66, 83]]</td>\n",
       "      <td>['PCFG', 'CFG']</td>\n",
       "      <td>['Probabilistic CFG']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['a CFG is', 'a Probabilistic CFG', 'n']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[5, 13], [63, 82], [3, 4]]</td>\n",
       "      <td>[Probabilistic CFG]</td>\n",
       "      <td>[[66, 83]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1] proposed a language-neutral framework for r...</td>\n",
       "      <td>[[128, 131]]</td>\n",
       "      <td>[[103, 126]]</td>\n",
       "      <td>['LNS']</td>\n",
       "      <td>['Language Neutral Syntax']</td>\n",
       "      <td>['LNS']</td>\n",
       "      <td>['a', 'Language Neutral Syntax']</td>\n",
       "      <td>[[128, 131]]</td>\n",
       "      <td>[[12, 13], [103, 126]]</td>\n",
       "      <td>[Language Neutral Syntax]</td>\n",
       "      <td>[[103, 126]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               text  \\\n",
       "0   1  2 Related Work The availability of emotion-ric...   \n",
       "1   2  WebDict 0.2919 Backoff 0.3282 Table 1: Mean Av...   \n",
       "2   3  Baselines are a unigram query likelihood (QL) ...   \n",
       "3   4  tion. Then, we extract expansion terms from th...   \n",
       "4   5  person, mood, voice and case, CATiB uses 6 POS...   \n",
       "5   6  (LDA), Maximum Likelihood Linear Transform (ML...   \n",
       "6   7  gold label (Section 3). Our algorithm is calle...   \n",
       "7   8  phrase markers or words. For simplicity of man...   \n",
       "8   9   When a CFG is associated with probabilistic i...   \n",
       "9  10  1] proposed a language-neutral framework for r...   \n",
       "\n",
       "                                            acronyms  \\\n",
       "0                                       [[162, 165]]   \n",
       "1                                         [[63, 66]]   \n",
       "2                 [[113, 115], [42, 45], [153, 156]]   \n",
       "3                                         [[92, 95]]   \n",
       "4  [[130, 134], [30, 35], [43, 46], [53, 56], [15...   \n",
       "5                   [[115, 118], [44, 48], [87, 91]]   \n",
       "6                                         [[95, 99]]   \n",
       "7                                       [[149, 152]]   \n",
       "8                                [[85, 89], [8, 11]]   \n",
       "9                                       [[128, 131]]   \n",
       "\n",
       "                       long-forms  \\\n",
       "0                    [[144, 160]]   \n",
       "1                      [[39, 61]]   \n",
       "2         [[90, 111], [132, 151]]   \n",
       "3                      [[65, 90]]   \n",
       "4        [[136, 142], [156, 161]]   \n",
       "5  [[94, 113], [7, 42], [51, 85]]   \n",
       "6                      [[52, 93]]   \n",
       "7                    [[128, 147]]   \n",
       "8                      [[66, 83]]   \n",
       "9                    [[103, 126]]   \n",
       "\n",
       "                                       acronyms-text  \\\n",
       "0                                            ['TDM']   \n",
       "1                                            ['MAP']   \n",
       "2                               ['SD', 'QL)', 'MRF']   \n",
       "3                                            ['PRF']   \n",
       "4  ['PROP', 'CATiB', 'POS', 'NOM', 'VRB', 'VRB-PA...   \n",
       "5                            ['MPE', 'MLLT', 'BMMI']   \n",
       "6                                           ['SWVP']   \n",
       "7                                            ['CNF']   \n",
       "8                                    ['PCFG', 'CFG']   \n",
       "9                                            ['LNS']   \n",
       "\n",
       "                                     long-forms-text  \\\n",
       "0                               ['Text Data Mining']   \n",
       "1                         ['Mean Average Precision']   \n",
       "2   ['sequential dependence', 'Markov random field']   \n",
       "3                      ['pseudo relevance feedback']   \n",
       "4                                ['proper', 'verbs']   \n",
       "5  ['Minimum Phone Error', 'Maximum Likelihood Li...   \n",
       "6      ['Structured Weighted Violations Perceptron']   \n",
       "7                            ['Chomsky Normal Form']   \n",
       "8                              ['Probabilistic CFG']   \n",
       "9                        ['Language Neutral Syntax']   \n",
       "\n",
       "                                  AN_Pred  \\\n",
       "0                                 ['TDM']   \n",
       "1                                 ['MAP']   \n",
       "2                     ['QL', 'SD', 'MRF']   \n",
       "3                                 ['PRF']   \n",
       "4  ['CATiB', 'POS', 'NOM', 'PROP', 'VRB']   \n",
       "5          ['LDA', 'MLLT', 'BMMI', 'MPE']   \n",
       "6                                ['SWVP']   \n",
       "7                                 ['CNF']   \n",
       "8                                      []   \n",
       "9                                 ['LNS']   \n",
       "\n",
       "                                             LF_Pred  \\\n",
       "0                          ['a', 'Text Data Mining']   \n",
       "1                         ['Mean Average Precision']   \n",
       "2  ['a', 'query likelihood', 'and a', 'sequential...   \n",
       "3                ['pseudo relevance feedback', 'in']   \n",
       "4   ['non-proper', 'nouns', 'proper nouns', 'verbs']   \n",
       "5  ['Maximum Likelihood Linear Transform', 'Boost...   \n",
       "6  ['Structured Weighted Violations Perceptron', ...   \n",
       "7                      ['or', 'Chomsky Normal Form']   \n",
       "8           ['a CFG is', 'a Probabilistic CFG', 'n']   \n",
       "9                   ['a', 'Language Neutral Syntax']   \n",
       "\n",
       "                                        AN_Pred_idxs  \\\n",
       "0                                       [[162, 165]]   \n",
       "1                                         [[63, 66]]   \n",
       "2                 [[42, 44], [113, 115], [153, 156]]   \n",
       "3                                         [[92, 95]]   \n",
       "4  [[30, 35], [43, 46], [53, 56], [130, 134], [15...   \n",
       "5           [[1, 4], [44, 48], [87, 91], [115, 118]]   \n",
       "6                                         [[95, 99]]   \n",
       "7                                       [[149, 152]]   \n",
       "8                                                 []   \n",
       "9                                       [[128, 131]]   \n",
       "\n",
       "                                        LF_Pred_idxs  \\\n",
       "0                               [[5, 6], [144, 160]]   \n",
       "1                                         [[39, 61]]   \n",
       "2  [[1, 2], [24, 40], [67, 72], [90, 111], [132, ...   \n",
       "3                               [[65, 90], [61, 63]]   \n",
       "4       [[58, 68], [88, 93], [136, 148], [122, 127]]   \n",
       "5                     [[7, 42], [51, 85], [94, 113]]   \n",
       "6                             [[52, 93], [129, 133]]   \n",
       "7                             [[15, 17], [128, 147]]   \n",
       "8                        [[5, 13], [63, 82], [3, 4]]   \n",
       "9                             [[12, 13], [103, 126]]   \n",
       "\n",
       "                                               cl_lf  \\\n",
       "0                                 [Text Data Mining]   \n",
       "1                           [Mean Average Precision]   \n",
       "2  [query likelihood, sequential dependence, Mark...   \n",
       "3                        [pseudo relevance feedback]   \n",
       "4                  [non-proper, proper nouns, verbs]   \n",
       "5  [Maximum Likelihood Linear Transform, Boosted ...   \n",
       "6        [Structured Weighted Violations Perceptron]   \n",
       "7                              [Chomsky Normal Form]   \n",
       "8                                [Probabilistic CFG]   \n",
       "9                          [Language Neutral Syntax]   \n",
       "\n",
       "                            cl_lf_ind  \n",
       "0                        [[144, 160]]  \n",
       "1                          [[39, 61]]  \n",
       "2   [[24, 40], [90, 111], [132, 151]]  \n",
       "3                          [[65, 90]]  \n",
       "4  [[58, 68], [136, 148], [122, 127]]  \n",
       "5      [[7, 42], [51, 85], [94, 113]]  \n",
       "6                          [[52, 93]]  \n",
       "7                        [[128, 147]]  \n",
       "8                          [[66, 83]]  \n",
       "9                        [[103, 126]]  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cl_lf_ind'] = indeces\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ID']= data['ID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata = data[['text','AN_Pred_idxs','cl_lf_ind','ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sadan\\AppData\\Local\\Continuum\\anaconda3\\envs\\old_env\\lib\\site-packages\\pandas\\core\\frame.py:4133: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>acronyms</th>\n",
       "      <th>long-forms</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 Related Work The availability of emotion-ric...</td>\n",
       "      <td>[[162, 165]]</td>\n",
       "      <td>[[144, 160]]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WebDict 0.2919 Backoff 0.3282 Table 1: Mean Av...</td>\n",
       "      <td>[[63, 66]]</td>\n",
       "      <td>[[39, 61]]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baselines are a unigram query likelihood (QL) ...</td>\n",
       "      <td>[[42, 44], [113, 115], [153, 156]]</td>\n",
       "      <td>[[24, 40], [90, 111], [132, 151]]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tion. Then, we extract expansion terms from th...</td>\n",
       "      <td>[[92, 95]]</td>\n",
       "      <td>[[65, 90]]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>person, mood, voice and case, CATiB uses 6 POS...</td>\n",
       "      <td>[[30, 35], [43, 46], [53, 56], [130, 134], [15...</td>\n",
       "      <td>[[58, 68], [136, 148], [122, 127]]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  2 Related Work The availability of emotion-ric...   \n",
       "1  WebDict 0.2919 Backoff 0.3282 Table 1: Mean Av...   \n",
       "2  Baselines are a unigram query likelihood (QL) ...   \n",
       "3  tion. Then, we extract expansion terms from th...   \n",
       "4  person, mood, voice and case, CATiB uses 6 POS...   \n",
       "\n",
       "                                            acronyms  \\\n",
       "0                                       [[162, 165]]   \n",
       "1                                         [[63, 66]]   \n",
       "2                 [[42, 44], [113, 115], [153, 156]]   \n",
       "3                                         [[92, 95]]   \n",
       "4  [[30, 35], [43, 46], [53, 56], [130, 134], [15...   \n",
       "\n",
       "                           long-forms ID  \n",
       "0                        [[144, 160]]  1  \n",
       "1                          [[39, 61]]  2  \n",
       "2   [[24, 40], [90, 111], [132, 151]]  3  \n",
       "3                          [[65, 90]]  4  \n",
       "4  [[58, 68], [136, 148], [122, 127]]  5  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdata.rename(columns={'AN_Pred_idxs':'acronyms', 'cl_lf_ind':'long-forms'}, inplace=True)\n",
    "newdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sadan\\AppData\\Local\\Continuum\\anaconda3\\envs\\old_env\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "newdata['acronyms'] = newdata['acronyms'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and then parse and then save\n",
    "import json\n",
    "jsond = newdata.to_json( orient='records', indent=4)\n",
    "parsed = json.loads(jsond)\n",
    "# parsed\n",
    "with open('cleaneng_sciwithnewind.json', 'w') as fout:\n",
    "    json.dump(parsed ,  fout,indent=4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sadan\\OneDrive\\GitHub\\PR-AAAI22-SDU-ST1-AE\n"
     ]
    }
   ],
   "source": [
    "cd OneDrive/GitHub/PR-AAAI22-SDU-ST1-AE/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is BE49-6290\n",
      "\n",
      " Directory of C:\\Users\\sadan\\OneDrive\\GitHub\\PR-AAAI22-SDU-ST1-AE\n",
      "\n",
      "01-Nov-21  02:22 PM    <DIR>          .\n",
      "01-Nov-21  02:22 PM    <DIR>          ..\n",
      "29-Oct-21  03:08 PM               211 .gitignore\n",
      "31-Oct-21  08:36 AM           253,095 cleaneng_sci.json\n",
      "01-Nov-21  07:55 AM           252,919 cleaneng_sci2.json\n",
      "29-Oct-21  03:08 PM    <DIR>          code\n",
      "29-Oct-21  03:08 PM    <DIR>          data\n",
      "01-Nov-21  02:26 PM    <DIR>          data_tsvs\n",
      "29-Oct-21  03:08 PM    <DIR>          data_xlsx\n",
      "01-Nov-21  02:22 PM           119,054 eng_sci_myind.xlsx\n",
      "29-Oct-21  07:59 PM           247,740 eng_scientific_dev_test2.json\n",
      "29-Oct-21  03:08 PM               670 gitpush.sh\n",
      "29-Oct-21  03:08 PM           228,859 infer.json\n",
      "29-Oct-21  03:08 PM             1,107 LICENSE\n",
      "29-Oct-21  03:08 PM             9,832 main.py\n",
      "29-Oct-21  03:08 PM    <DIR>          model\n",
      "01-Nov-21  02:26 PM    <DIR>          nbs\n",
      "29-Oct-21  03:08 PM             5,417 NERCodeREADME.md\n",
      "29-Oct-21  03:08 PM    <DIR>          pretrained_models\n",
      "01-Nov-21  02:26 PM    <DIR>          processed\n",
      "29-Oct-21  03:08 PM             5,557 README.md\n",
      "29-Oct-21  03:08 PM                60 requirements.txt\n",
      "29-Oct-21  03:08 PM    <DIR>          results\n",
      "29-Oct-21  03:08 PM            10,150 run_all_acronym.sh\n",
      "29-Oct-21  03:08 PM             3,136 scorer.py\n",
      "29-Oct-21  03:08 PM               287 test.py\n",
      "31-Oct-21  08:06 PM           187,324 test_acr.csv\n",
      "29-Oct-21  03:08 PM             2,275 test_all_acronym_extraction.sh\n",
      "29-Oct-21  03:08 PM    <DIR>          trial_results\n",
      "29-Oct-21  03:08 PM    <DIR>          utils\n",
      "              17 File(s)      1,327,693 bytes\n",
      "              13 Dir(s)  68,995,956,736 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shorts: P: 78.81%, R: 64.02%, F1: 70.65%\n",
      "Longs: P: 65.73%, R: 61.81%, F1: 63.71%\n",
      "micro scores: P: 73.02%, R: 63.25%, F1: 67.79%\n",
      "macro scores: P: 72.27%, R: 62.91%, F1: 67.27%\n",
      "Official Scores:\n",
      "P: 72.27%, R: 62.91%, F1: 67.27%\n"
     ]
    }
   ],
   "source": [
    "!python scorer.py -g \"data/english/scientific/dev.json\" -p cleaneng_sciwithnewind.json -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JASON FOR OTHER FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sadan\\OneDrive\\GitHub\\PR-AAAI22-SDU-ST1-AE\\results\\finetuned_models\\model_all_xb_v1_512\\output\\cleaned_longform\n"
     ]
    }
   ],
   "source": [
    "cd results/finetuned_models/model_all_xb_v1_512/output/cleaned_longform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_leg = pd.read_csv('cl_eng_leg_dev.csv')\n",
    "dan =  pd.read_csv('cl_dan_dev.csv')\n",
    "esp =  pd.read_csv('cl_esp_dev.csv')\n",
    "fre =  pd.read_csv('cl_fre_dev.csv')\n",
    "per =  pd.read_csv('cl_per_dev.csv')\n",
    "vie =  pd.read_csv('cl_vie_dev.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure how the cleaning went with other languages needs checking\n",
    "# not sure about the indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>acronyms</th>\n",
       "      <th>long-forms</th>\n",
       "      <th>acronyms-text</th>\n",
       "      <th>long-forms-text</th>\n",
       "      <th>AN_Pred</th>\n",
       "      <th>LF_Pred</th>\n",
       "      <th>AN_Pred_idxs</th>\n",
       "      <th>LF_Pred_idxs</th>\n",
       "      <th>lf_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>the World Food Programme 1. In its decision 20...</td>\n",
       "      <td>[[136, 140], [185, 190]]</td>\n",
       "      <td>[[98, 134]]</td>\n",
       "      <td>['UNDP', 'UNFPA']</td>\n",
       "      <td>['United Nations Development Programme']</td>\n",
       "      <td>['UNDP', 'UNFPA']</td>\n",
       "      <td>['Programme', 'United Nations Development Prog...</td>\n",
       "      <td>[[136, 140], [185, 190]]</td>\n",
       "      <td>[[15, 24], [98, 134], [153, 183]]</td>\n",
       "      <td>['United Nations Development Programme', 'Unit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>These legal transport systems in Europe consti...</td>\n",
       "      <td>[[170, 175], [302, 307], [222, 228], [229, 232...</td>\n",
       "      <td>[[113, 168], [245, 300]]</td>\n",
       "      <td>['ECLAC', 'ECLAC', 'UNCTAD', 'LDC', 'Misc']</td>\n",
       "      <td>['Economic Commission for Latin America and th...</td>\n",
       "      <td>['.', 'ECLAC']</td>\n",
       "      <td>['Economic Commission for Latin America and th...</td>\n",
       "      <td>[[110, 111], [170, 175]]</td>\n",
       "      <td>[[113, 168], [155, 158], [113, 168], [143, 150...</td>\n",
       "      <td>['Economic Commission for Latin America and th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>As a final word of caution against approaches ...</td>\n",
       "      <td>[[411, 419]]</td>\n",
       "      <td>[[339, 409]]</td>\n",
       "      <td>['UN-Women']</td>\n",
       "      <td>['United Nations Entity for Gender Equality an...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['a', 'of', 'the', 'at', 'the', 'the', 'the', ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[3, 4], [16, 18], [73, 76], [48, 50], [73, 76...</td>\n",
       "      <td>['of the United Nations Entity for Gender Equa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Calls upon Governments, civil society, includi...</td>\n",
       "      <td>[[878, 885]]</td>\n",
       "      <td>[[806, 876]]</td>\n",
       "      <td>['UNWomen']</td>\n",
       "      <td>['United Nations Entity for Gender Equality an...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['the', 'and', 'and', 'for and the', 'of the',...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[49, 52], [60, 63], [60, 63], [145, 156], [16...</td>\n",
       "      <td>['of the United Nations', 'of the United Natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Grand total 30 320a Abbreviations: AOS = admin...</td>\n",
       "      <td>[[35, 38], [82, 85], [117, 121], [170, 173], [...</td>\n",
       "      <td>[[41, 80], [88, 115], [176, 206], [215, 259], ...</td>\n",
       "      <td>['AOS', 'GEF', 'SPPD', 'STS', 'TRAC', 'UNCDF']</td>\n",
       "      <td>['administrative and operational services', 'G...</td>\n",
       "      <td>['AOS', 'GEF', 'SPPD', 'STS', 'TRAC', 'UNCDF']</td>\n",
       "      <td>['administrative', 'and operational', 'service...</td>\n",
       "      <td>[[35, 38], [82, 85], [117, 121], [170, 173], [...</td>\n",
       "      <td>[[41, 55], [56, 71], [72, 80], [88, 115], [124...</td>\n",
       "      <td>['administrative', 'and operational', 'Global ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ID                                               text  \\\n",
       "0           0   1  the World Food Programme 1. In its decision 20...   \n",
       "1           1   2  These legal transport systems in Europe consti...   \n",
       "2           2   3  As a final word of caution against approaches ...   \n",
       "3           3   4  Calls upon Governments, civil society, includi...   \n",
       "4           4   5  Grand total 30 320a Abbreviations: AOS = admin...   \n",
       "\n",
       "                                            acronyms  \\\n",
       "0                           [[136, 140], [185, 190]]   \n",
       "1  [[170, 175], [302, 307], [222, 228], [229, 232...   \n",
       "2                                       [[411, 419]]   \n",
       "3                                       [[878, 885]]   \n",
       "4  [[35, 38], [82, 85], [117, 121], [170, 173], [...   \n",
       "\n",
       "                                          long-forms  \\\n",
       "0                                        [[98, 134]]   \n",
       "1                           [[113, 168], [245, 300]]   \n",
       "2                                       [[339, 409]]   \n",
       "3                                       [[806, 876]]   \n",
       "4  [[41, 80], [88, 115], [176, 206], [215, 259], ...   \n",
       "\n",
       "                                    acronyms-text  \\\n",
       "0                               ['UNDP', 'UNFPA']   \n",
       "1     ['ECLAC', 'ECLAC', 'UNCTAD', 'LDC', 'Misc']   \n",
       "2                                    ['UN-Women']   \n",
       "3                                     ['UNWomen']   \n",
       "4  ['AOS', 'GEF', 'SPPD', 'STS', 'TRAC', 'UNCDF']   \n",
       "\n",
       "                                     long-forms-text  \\\n",
       "0           ['United Nations Development Programme']   \n",
       "1  ['Economic Commission for Latin America and th...   \n",
       "2  ['United Nations Entity for Gender Equality an...   \n",
       "3  ['United Nations Entity for Gender Equality an...   \n",
       "4  ['administrative and operational services', 'G...   \n",
       "\n",
       "                                          AN_Pred  \\\n",
       "0                               ['UNDP', 'UNFPA']   \n",
       "1                                  ['.', 'ECLAC']   \n",
       "2                                              []   \n",
       "3                                              []   \n",
       "4  ['AOS', 'GEF', 'SPPD', 'STS', 'TRAC', 'UNCDF']   \n",
       "\n",
       "                                             LF_Pred  \\\n",
       "0  ['Programme', 'United Nations Development Prog...   \n",
       "1  ['Economic Commission for Latin America and th...   \n",
       "2  ['a', 'of', 'the', 'at', 'the', 'the', 'the', ...   \n",
       "3  ['the', 'and', 'and', 'for and the', 'of the',...   \n",
       "4  ['administrative', 'and operational', 'service...   \n",
       "\n",
       "                                        AN_Pred_idxs  \\\n",
       "0                           [[136, 140], [185, 190]]   \n",
       "1                           [[110, 111], [170, 175]]   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4  [[35, 38], [82, 85], [117, 121], [170, 173], [...   \n",
       "\n",
       "                                        LF_Pred_idxs  \\\n",
       "0                  [[15, 24], [98, 134], [153, 183]]   \n",
       "1  [[113, 168], [155, 158], [113, 168], [143, 150...   \n",
       "2  [[3, 4], [16, 18], [73, 76], [48, 50], [73, 76...   \n",
       "3  [[49, 52], [60, 63], [60, 63], [145, 156], [16...   \n",
       "4  [[41, 55], [56, 71], [72, 80], [88, 115], [124...   \n",
       "\n",
       "                                          lf_cleaned  \n",
       "0  ['United Nations Development Programme', 'Unit...  \n",
       "1  ['Economic Commission for Latin America and th...  \n",
       "2  ['of the United Nations Entity for Gender Equa...  \n",
       "3  ['of the United Nations', 'of the United Natio...  \n",
       "4  ['administrative', 'and operational', 'Global ...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_leg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df (df):\n",
    "    df['lf_cleaned'] = df['lf_cleaned'].apply(literal_eval)\n",
    "    df['AN_Pred_idxs'] = df['AN_Pred_idxs'].apply(literal_eval)\n",
    "    df['ID'] = df['ID'].astype(str)\n",
    "    tx = [[t] for t in df.text.to_list()]\n",
    "    lf = df.lf_cleaned.tolist()\n",
    "    indeces = []\n",
    "    for l , t in zip(lf,tx):\n",
    "        indeces.append(get_index(l,t))\n",
    "    df['cl_lf_ind'] = indeces\n",
    "    newdf = df[['text','AN_Pred_idxs','cl_lf_ind','ID']]\n",
    "    newdf.rename(columns={'AN_Pred_idxs':'acronyms', 'cl_lf_ind':'long-forms'}, inplace=True)\n",
    "#     newdf['acronyms'] = newdf['acronyms'].apply(literal_eval)\n",
    "#     newdf['long-forms'] = newdf['long-forms'].apply(literal_eval)\n",
    "#     newdf['ID'] = newdf['ID'].astype(str)\n",
    "    return newdf\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sadan\\AppData\\Local\\Continuum\\anaconda3\\envs\\old_env\\lib\\site-packages\\pandas\\core\\frame.py:4133: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "eng_leg_dfn = process_df(eng_leg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>acronyms</th>\n",
       "      <th>long-forms</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the World Food Programme 1. In its decision 20...</td>\n",
       "      <td>[[136, 140], [185, 190]]</td>\n",
       "      <td>[[98, 134], [153, 183]]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>These legal transport systems in Europe consti...</td>\n",
       "      <td>[[110, 111], [170, 175]]</td>\n",
       "      <td>[[113, 168], [113, 168]]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a final word of caution against approaches ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[332, 409]]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Calls upon Governments, civil society, includi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[445, 466], [445, 466], [802, 876], [445, 466]]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grand total 30 320a Abbreviations: AOS = admin...</td>\n",
       "      <td>[[35, 38], [82, 85], [117, 121], [170, 173], [...</td>\n",
       "      <td>[[41, 55], [56, 71], [88, 115], [124, 168], [1...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  the World Food Programme 1. In its decision 20...   \n",
       "1  These legal transport systems in Europe consti...   \n",
       "2  As a final word of caution against approaches ...   \n",
       "3  Calls upon Governments, civil society, includi...   \n",
       "4  Grand total 30 320a Abbreviations: AOS = admin...   \n",
       "\n",
       "                                            acronyms  \\\n",
       "0                           [[136, 140], [185, 190]]   \n",
       "1                           [[110, 111], [170, 175]]   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4  [[35, 38], [82, 85], [117, 121], [170, 173], [...   \n",
       "\n",
       "                                          long-forms ID  \n",
       "0                            [[98, 134], [153, 183]]  1  \n",
       "1                           [[113, 168], [113, 168]]  2  \n",
       "2                                       [[332, 409]]  3  \n",
       "3   [[445, 466], [445, 466], [802, 876], [445, 466]]  4  \n",
       "4  [[41, 55], [56, 71], [88, 115], [124, 168], [1...  5  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_leg_dfn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 445 entries, 0 to 444\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   text        445 non-null    object\n",
      " 1   acronyms    445 non-null    object\n",
      " 2   long-forms  445 non-null    object\n",
      " 3   ID          445 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 14.0+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sadan\\AppData\\Local\\Continuum\\anaconda3\\envs\\old_env\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "eng_leg_dfn['ID']=eng_leg_dfn['ID'].astype(str)\n",
    "eng_leg_dfn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsond = eng_leg_dfn.to_json( orient='records', indent=4)\n",
    "parsed = json.loads(jsond)\n",
    "# parsed\n",
    "with open('test_legal2.json', 'w') as fout:\n",
    "    json.dump(parsed ,  fout,indent=4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\sadan\\\\OneDrive\\\\GitHub\\\\PR-AAAI22-SDU-ST1-AE\\\\results\\\\finetuned_models\\\\model_all_xb_v1_512\\\\output\\\\cleaned_longform'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sadan\\OneDrive\\GitHub\\PR-AAAI22-SDU-ST1-AE\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shorts: P: 73.57%, R: 46.58%, F1: 57.04%\n",
      "Longs: P: 48.34%, R: 49.93%, F1: 49.12%\n",
      "micro scores: P: 61.69%, R: 47.82%, F1: 53.88%\n",
      "macro scores: P: 60.95%, R: 48.25%, F1: 53.86%\n",
      "Official Scores:\n",
      "P: 60.95%, R: 48.25%, F1: 53.86%\n"
     ]
    }
   ],
   "source": [
    "!python scorer.py -g \"data/english/legal/dev.json\" -p test_legal2.json -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sadan\\AppData\\Local\\Continuum\\anaconda3\\envs\\old_env\\lib\\site-packages\\pandas\\core\\frame.py:4133: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "dan_df = process_df(dan)\n",
    "esp_df = process_df(esp)\n",
    "fre_df = process_df(fre)\n",
    "per_df = process_df(per)\n",
    "vie_df = process_df(vie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sadan\\OneDrive\\GitHub\\PR-AAAI22-SDU-ST1-AE\\results\\finetuned_models\\model_all_xb_v1_512\\output\\cleaned_longform\n"
     ]
    }
   ],
   "source": [
    "cd results/finetuned_models/model_all_xb_v1_512/output/cleaned_longform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsond = vie_df.to_json( orient='records', indent=4)\n",
    "parsed = json.loads(jsond)\n",
    "# parsed\n",
    "with open('cl_vie_dev.json', 'w') as fout:\n",
    "    json.dump(parsed ,  fout,indent=4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is BE49-6290\n",
      "\n",
      " Directory of C:\\Users\\sadan\\OneDrive\\GitHub\\PR-AAAI22-SDU-ST1-AE\\results\\finetuned_models\\model_all_xb_v1_512\\output\\cleaned_longform\n",
      "\n",
      "02-Nov-21  02:36 PM    <DIR>          .\n",
      "02-Nov-21  02:36 PM    <DIR>          ..\n",
      "01-Nov-21  02:21 PM           244,253 cl_dan_dev.csv\n",
      "02-Nov-21  02:35 PM           271,235 cl_dan_dev.json\n",
      "01-Nov-21  02:21 PM           370,015 cl_eng_leg_dev.csv\n",
      "02-Nov-21  02:27 PM           338,107 cl_eng_leg_dev.json\n",
      "01-Nov-21  02:14 PM           194,036 cl_eng_sci_dev.csv\n",
      "02-Nov-21  01:44 PM           245,413 cl_eng_sci_dev.json\n",
      "01-Nov-21  02:21 PM           764,396 cl_esp_dev.csv\n",
      "02-Nov-21  02:35 PM           679,117 cl_esp_dev.json\n",
      "01-Nov-21  02:21 PM           978,756 cl_fre_dev.csv\n",
      "02-Nov-21  02:36 PM           922,566 cl_fre_dev.json\n",
      "01-Nov-21  02:21 PM            82,036 cl_per_dev.csv\n",
      "02-Nov-21  02:36 PM           198,073 cl_per_dev.json\n",
      "01-Nov-21  02:21 PM            39,095 cl_vie_dev.csv\n",
      "02-Nov-21  02:36 PM            68,044 cl_vie_dev.json\n",
      "              14 File(s)      5,395,142 bytes\n",
      "               2 Dir(s)  68,976,967,680 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:old_env]",
   "language": "python",
   "name": "conda-env-old_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
