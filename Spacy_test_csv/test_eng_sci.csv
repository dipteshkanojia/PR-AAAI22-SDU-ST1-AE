,Unnamed: 0,text,ID,AN_Pred,LF_Pred,AN_Pred_idxs,LF_Pred_idxs,lf_cleaned,an_cleaned,cl_lf_ind,acronyms_prediction,indexes_predicted
0,0,The label restricted means the model is restricted to recovering rules that have been seen in training data. LR = labeled recall. LP = labeled,1,"['LR', 'LP']","['label', 'labeled recall']","[[109, 111], [130, 132]]","[[4, 9], [114, 128]]",['labeled recall'],"['LR', 'LP']","[[114, 128]]","['LR', 'LP']","[[109, 111], [130, 132]]"
1,1,"We have followed their methodology as best as we could, using the same WordNet (WN) categories and the same corpora.",2,['WN'],['WordNet'],"[[80, 82]]","[[71, 78]]",['WordNet'],['WN'],"[[71, 78]]",['WN'],"[[80, 82]]"
2,2,adaptation scenario. Duan et al (2009) proposed a Domain Adaptation Machine (DAM) method to learn a Least-Squares SVM classifier for target do-,3,"['DAM', 'SVM']","['a Domain Adaptation Machine', 'a']","[[77, 80], [114, 117]]","[[48, 75], [0, 1]]",['Domain Adaptation Machine'],"['DAM', 'SVM']","[[50, 75]]","['DAM', 'SVM']","[[77, 80], [114, 117]]"
3,3," Actes de la 13e Confe?rence sur le Traitement Automatique des Langues Naturelles (TALN), pages 20?42.",4,[')'],"['de la', 'le', 'Automatique des Langues Naturelles']","[[86, 87]]","[[6, 11], [32, 34], [46, 80]]",['Automatique des Langues Naturelles'],[')'],"[[47, 81]]",['TALN'],"[[83, 87]]"
4,4,"TGTM P=p,pk ,b   TGTM PR=pr ,  pkr ,  b r   TGTM PL =p l ,  ph l ,  b l   TGTM PW=pw, pkw, bw ",5,['=p'],"[',', ',', ',', ',', 'l ,', 'l ,', 'l', ',', ',']","[[6, 8]]","[[8, 9], [8, 9], [8, 9], [8, 9], [55, 58], [55, 58], [55, 56], [8, 9], [8, 9]]",[],['=p'],[],"['TGTM', 'TGTM', 'PR', 'TGTM', 'PL', 'TGTM', 'PW']","[[0, 4], [0, 4], [22, 24], [0, 4], [49, 51], [0, 4], [79, 81]]"
5,5,"MIRA/AROW requires selecting the loss function `(w) so that wt can be solved in closed-form, by a quadratic program (QP), or in some other way that is better than linearizing.",6,"['w', 'QP']",['a quadratic program'],"[[49, 50], [117, 119]]","[[96, 115]]",['quadratic program'],"['w', 'QP']","[[98, 115]]","['MIRA', 'AROW', 'QP']","[[0, 4], [5, 9], [117, 119]]"
6,6," 1 Introduction Information extraction (IE) systems generally consist of multiple interdependent components, e.g., en-",7,[')'],['extraction'],"[[41, 42]]","[[27, 37]]",['extraction'],[')'],"[[28, 38]]",['IE'],"[[40, 42]]"
7,7,"117 d?eriv?es) (AP (ADJ thiazidiques) (COORD (PONCT ,) (NP (DET les) (ADV plus) (ADJ accessibles)) (PONCT ,) (AP (ADJ disponibles)))) (PP (P sous forme de) (NP (NC m?edicaments) (AP (ADJ g?en?eriques)))))))))",8,"['AP', 'COORD', 'PONCT', 'NP', 'PP']","['d', '? eriv ? es', 'ADJ thiazidiques', 'DET', 'ADV', 'ADJ accessibles', 'ADJ', 'P sous forme de', 'm ? edicaments', 'ADJ g ? en ? eriques']","[[16, 18], [39, 44], [46, 51], [56, 58], [135, 137]]","[[4, 5], [-1, 10], [20, 36], [60, 63], [70, 73], [81, 96], [20, 23], [139, 154], [-1, 13], [-1, 19]]","['? eriv ? es', 'ADJ thiazidiques', 'ADJ accessibles', 'P sous forme de', 'm ? edicaments', 'ADJ g ? en ? eriques']","['AP', 'COORD', 'PONCT', 'NP', 'PP']","[[20, 36], [81, 96], [139, 154]]","['AP', 'ADJ', 'COORD', 'PONCT', 'NP', 'ADV', 'ADJ accessibles', 'PONCT', 'AP', 'ADJ', 'PP', 'NP', 'NC', 'AP', 'ADJ g?en?eriques']","[[16, 18], [20, 23], [39, 44], [46, 51], [56, 58], [70, 73], [81, 96], [46, 51], [16, 18], [20, 23], [135, 137], [56, 58], [48, 50], [16, 18], [183, 199]]"
8,8,2002. The concaveconvex procedure (CCCP). In Proc.,9,[')'],['procedure'],"[[39, 40]]","[[24, 33]]",['procedure'],[')'],"[[24, 33]]",['CCCP'],"[[35, 39]]"
9,9,"most related words pop-up. Then the documents are re-ranked about their term frequency (TF) values (G. Salton and C. Buckley, 1988) and contextual infor-",10,['TF'],['term frequency'],"[[88, 90]]","[[72, 86]]",['term frequency'],['TF'],"[[72, 86]]",['TF'],"[[88, 90]]"
10,10,"in part by ONR grant number N00014-95-1-1164,  and has been done in collaboration with the US  Navy's NCCOSC RDT&E Division (NRaD), Ascent  Technologies, Mitre Corp., MRJ Corp., and SRI In- ",11,"['ONR', 'US']","['NCCOSC', 'RDT & E']","[[11, 14], [91, 93]]","[[102, 108], [-1, 6]]",['NCCOSC'],"['ONR', 'US']","[[102, 108]]","['ONR', 'US', 'NRaD', 'MRJ', 'SRI']","[[11, 14], [91, 93], [125, 129], [167, 170], [182, 185]]"
11,11,approach.  The Minimum Token Margin (MTM) strategy is a variant of the margin sampling strategy introduced,12,['MTM'],"['Minimum Token Margin', 'a']","[[37, 40]]","[[15, 35], [0, 1]]",['Minimum Token Margin'],['MTM'],"[[15, 35]]",['MTM'],"[[37, 40]]"
12,12,food(FOOD) artifact(AFT) article(ART)  location(LOC) psych_feature(PSY)  cognition(COG) feeling(FEEL)  motivation(MOT) abstraction(ABS) ,13,"['FOOD', 'AFT', 'ART', 'LOC', 'PSY', 'COG', 'FEEL', 'MOT', 'ABS']","['food', 'artifact', 'article', 'location', 'psych_feature', 'cognition', 'feeling', 'abstraction']","[[5, 9], [20, 23], [33, 36], [48, 51], [67, 70], [83, 86], [96, 100], [114, 117], [131, 134]]","[[0, 4], [11, 19], [25, 32], [39, 47], [53, 66], [73, 82], [88, 95], [119, 130]]","['artifact', 'article', 'location', 'psych_feature', 'cognition', 'feeling', 'abstraction']","['FOOD', 'AFT', 'ART', 'LOC', 'PSY', 'COG', 'FEEL', 'MOT', 'ABS']","[[11, 19], [25, 32], [39, 47], [53, 66], [73, 82], [88, 95], [119, 130]]",[],[]
13,13,"m } using standard support vector machine (SVM) training (holding A fixed), and then make a simple",14,['SVM'],"['m', 'support vector machine', 'a']","[[43, 46]]","[[0, 1], [19, 41], [12, 13]]",['support vector machine'],['SVM'],"[[19, 41]]",['SVM'],"[[43, 46]]"
14,14,son. One is based on chi-square value and the other is based on Pointwise Mutual Information (PMI). ,15,['PMI'],"['on', 'on Pointwise Mutual Information']","[[94, 97]]","[[1, 3], [61, 92]]",['on Pointwise Mutual Information'],['PMI'],"[[61, 92]]",['PMI'],"[[94, 97]]"
15,15,concerned with video lecture viewing only) before 11 Figure 4: Variation of Average Information Processing Indices(IPI) for Video 4-6 Figure 5: Variation of Average Information Processing Indices(IPI) for the full course,16,['IPI'],"['Information Processing Indices', 'for', 'Information Processing Indices', 'for']","[[115, 118]]","[[84, 114], [45, 48], [84, 114], [45, 48]]","['Information Processing Indices', 'Information Processing Indices']",['IPI'],"[[84, 114], [84, 114]]",[],[]
16,16,Figure 1. Annotated Syntax Tree  (AST) and Phrase Levels (PL). ,17,[')'],"['Syntax Tree', 'Levels']","[[37, 38]]","[[20, 31], [50, 56]]","['Syntax Tree', 'Levels']",[')'],"[[20, 31], [50, 56]]","['AST', 'PL']","[[34, 37], [58, 60]]"
17,17,Num. of Friendships 265 Average Clustering Coefficient (ACC) 0.42 Diameter 12 Table 1: Statistical information of our Foursquare dataset.,18,['ACC'],['Average Clustering Coefficient'],"[[56, 59]]","[[24, 54]]",['Average Clustering Coefficient'],['ACC'],"[[24, 54]]",['ACC'],"[[56, 59]]"
18,18,number of phrase pairs that can be extracted. We observe that it (OEF) is able to find more than 14% more phrase pairs than heuristic methods and,19,['OEF'],['observe'],"[[66, 69]]","[[49, 56]]",['observe'],['OEF'],"[[49, 56]]",['OEF'],"[[66, 69]]"
19,19,"? Frequency-based: LUHN (Luhn, 1958) score(S) = maxci?{clusters(S)}{csi}, where",20,[],[],[],[],[],[''],[],['LUHN'],"[[19, 23]]"
20,20,"resource presented here implements formal semantic descriptions of verbs in the Web Ontology Language (OWL) and exploits its reasoning potential based on Description Logics (DL) for the disambiguation of verbs in context, since before the correct sense of a verb can be reliably",21,"['OWL', 'DL']","['Web Ontology Language', 'on Description Logics', 'a']","[[103, 106], [174, 176]]","[[80, 101], [151, 172], [39, 40]]","['Web Ontology Language', 'on Description Logics']","['OWL', 'DL']","[[80, 101], [151, 172]]","['OWL', 'DL']","[[103, 106], [174, 176]]"
21,21,"the noun phrase (NP) rule, a top-down parser is delaying making any commitments about the category following the determiner (DT). This delay in predic-",22,"['NP', 'DT']","['noun phrase', 'a', 'determiner', 'in']","[[17, 19], [125, 127]]","[[4, 15], [12, 13], [113, 123], [53, 55]]","['noun phrase', 'determiner']","['NP', 'DT']","[[4, 15], [113, 123]]","['NP', 'DT']","[[17, 19], [125, 127]]"
22,22,"for test year 2010 (train on 2009), polarity task.  SemTree combined with FWD (SemTreeFWD) generally gives the best performance in both",23,[],"['SemTree combined with FWD', 'in']",[],"[[52, 77], [23, 25]]",['SemTree combined with FWD'],[''],"[[52, 77]]",['FWD'],"[[74, 77]]"
23,23,Marcu (2007) note that none of the tens of papers published over the last five years has shown that significant decreases in alignment error rate (AER) result in significant increases in translation perfor-,24,['AER'],['alignment error rate'],"[[147, 150]]","[[125, 145]]",['alignment error rate'],['AER'],"[[125, 145]]",['AER'],"[[147, 150]]"
24,24,"""bridge"" between this bilingual word pair. This  leads us to use the term frequency(TF) mea-  sure.",25,['TF'],['term frequency'],"[[84, 86]]","[[69, 83]]",['term frequency'],['TF'],"[[69, 83]]",[],[]
25,25, 4 Evaluation and Experiments We use the General Inquirer (GI)8 data for evaluation.,26,['GI'],['General Inquirer'],"[[58, 60]]","[[40, 56]]",['General Inquirer'],['GI'],"[[41, 57]]",[],[]
26,26,"We ran our experiments with three corpora in different languages and representing different textual typologies: the British National Corpus (BNC), a ? bal-",27,['BNC'],"['British National Corpus', 'a']","[[141, 144]]","[[116, 139], [4, 5]]",['British National Corpus'],['BNC'],"[[116, 139]]",['BNC'],"[[141, 144]]"
27,27,the same discourse relation annotation style over different domain corpora: PDTB is annotated on top of Wall Street Journal (WSJ) corpus (financial news-wire domain); and it is aligned with Penn,28,"['PDTB', 'WSJ']",['Wall Street Journal'],"[[76, 80], [125, 128]]","[[104, 123]]",['Wall Street Journal'],"['PDTB', 'WSJ']","[[104, 123]]","['PDTB', 'WSJ']","[[76, 80], [125, 128]]"
28,28, 6 Related Work  Boosting is a machine learning (ML) method that  has been well studied in the ML community ,29,[')'],"['a', 'learning', 'in']","[[50, 51]]","[[5, 6], [38, 46], [21, 23]]",['learning'],[')'],"[[39, 47]]","['ML', 'ML']","[[49, 51], [49, 51]]"
29,29,"MOVE is a label for complex events that con-  sists o f  maximal ly  three sub-events,  namely  START, CHPOS (CHANGE OF POSITION), and STOP,  where the first and the last sub-event are optional ",30,['CHPOS'],['CHANGE OF POSITION'],"[[103, 108]]","[[110, 128]]",['CHANGE OF POSITION'],['CHPOS'],"[[110, 128]]","['MOVE', 'START', 'CHPOS', 'POSITION', 'STOP']","[[0, 4], [96, 101], [103, 108], [120, 128], [135, 139]]"
30,30,>puncS Hertz equipment is a major supplier of rental equipment N/N N S\N (S\S)/N N/N N (N\N)/N N/N N > >,31,"['N/NNS\\N', 'S\\S']","[')', ')']","[[-1, 6], [74, 77]]","[[77, 78], [77, 78]]",[],"['N/NNS\\\\N', 'S\\\\S']",[],['N/N'],"[[63, 66]]"
31,31, Several algorithms have been evaluated using 80 multiple-choice synonym questions taken from the Test of English as a Foreign Language (TOEFL). An example of,32,['TOEFL'],['Test of English as a Foreign Language'],"[[136, 141]]","[[97, 134]]",['Test of English as a Foreign Language'],['TOEFL'],"[[98, 135]]",['TOEFL'],"[[137, 142]]"
32,32,"halcea and Nataste (2012)). In our framework, we train a Neural Language Model (NLM) on yearly corpora to obtain word vectors for each year",33,['NLM'],['a Neural Language Model'],"[[80, 83]]","[[55, 78]]",['Neural Language Model'],['NLM'],"[[57, 78]]",['NLM'],"[[80, 83]]"
33,33,"summarizing the work of the Corpora and Performance  Evaluation Committee (CPEC) of the DARPA Spoken Language  Systems (SLS) Program, with specific reports from several  working groups which have been dealing with various aspects ",34,"['CPEC', 'DARPA', 'SLS']","['Corpora and Performance Evaluation Committee', 'Spoken Language Systems']","[[75, 79], [88, 93], [120, 123]]","[[-1, 43], [-1, 22]]","['Corpora and Performance Evaluation Committee', 'Spoken Language Systems']","['CPEC', 'DARPA', 'SLS']",[],"['CPEC', 'DARPA', 'SLS']","[[75, 79], [88, 93], [120, 123]]"
34,34,"robust and the failure of matching produces no results.  On the other hand, statistical learning model (SLM) can  deal with unexpected cases during designing and ",35,['SLM'],['statistical learning model'],"[[104, 107]]","[[76, 102]]",['statistical learning model'],['SLM'],"[[76, 102]]",['SLM'],"[[104, 107]]"
35,35,Statistical model (S) O O O O O O O O  Cooperative(CPR)  O   O O  O  Corrective(COR)   O  O  O O  Self-directing(SFD)    O  O O O ,36,"['S', 'CPR']","['Statistical model', 'Cooperative', 'Corrective', 'Self-directing']","[[0, 1], [51, 54]]","[[0, 17], [39, 50], [69, 79], [98, 112]]","['Statistical model', 'Cooperative', 'Corrective', 'Self-directing']","['S', 'CPR']","[[0, 17], [39, 50], [69, 79], [98, 112]]",[],[]
36,36,"Among  three state-of-the-art systems we have, the best Fscores of single character location (SCL) and single character person (SCP) are 43.63% and 43.48% ",37,"['SCL', 'SCP']","['single character location', 'single character person']","[[94, 97], [128, 131]]","[[67, 92], [103, 126]]","['single character location', 'single character person']","['SCL', 'SCP']","[[67, 92], [103, 126]]","['SCL', 'SCP']","[[94, 97], [128, 131]]"
37,37,5. Introducing background knowledge via CCMs [30 min]   We will look at ways in which Constrained Conditional Models (CCMs)can be used to  augment probabilistic models with declarative constraints in order to support decisions ,38,['CCMs'],"['at', 'in', 'Constrained Conditional Models', 'in']","[[40, 44]]","[[69, 71], [11, 13], [86, 116], [11, 13]]",['Constrained Conditional Models'],['CCMs'],"[[86, 116]]",['CCMs'],"[[40, 44]]"
38,38,bor.hodoscek@gmail.com Abstract Regarding the construction of an ontology of Japanese lexical properties (JLP-O) as fundamental in terms of establishing a conceptual framework to guide and facilitate the construction of a large-scale,39,['JLP-O'],"['Japanese lexical properties', 'a', 'a']","[[106, 111]]","[[77, 104], [15, 16], [15, 16]]",['Japanese lexical properties'],['JLP-O'],"[[77, 104]]",['JLP-O'],"[[106, 111]]"
39,39,Abstract  This paper presents a new approach  based on Equivalent Pseudowords (EPs)  to tackle Word Sense Disambiguation ,40,['EPs'],['Equivalent Pseudowords'],"[[79, 82]]","[[55, 77]]",['Equivalent Pseudowords'],['EPs'],"[[55, 77]]",['EPs'],"[[79, 82]]"
40,40,"phrase-based decoder that has been augmented to translate ambiguous input given in the form of a confusion network (CN), a weighted finite state representation of a",41,['CN'],['confusion network'],"[[116, 118]]","[[97, 114]]",['confusion network'],['CN'],"[[97, 114]]",['CN'],"[[116, 118]]"
41,41,"BACKGROUN D The LOLITA (Large-scale, Object-based, Linguistic Interactor, Translator, and Analyser) system is de signed as a general purpose Natural Language Processing (NLP) system and has been under development a t the University of Durham since 1986 .",42,['NLP'],"['a', 'Natural Language Processing', 'a t']","[[170, 173]]","[[25, 26], [141, 168], [213, 216]]",['Natural Language Processing'],['NLP'],"[[141, 168]]","['LOLITA', 'NLP']","[[16, 22], [170, 173]]"
42,42,"al. ( 2008), on the other hand, include features from the grammar in a maximum entropy (ME) classifier to predict new lexical entries for the",43,['ME'],['a maximum entropy'],"[[88, 90]]","[[69, 86]]",['maximum entropy'],['ME'],"[[71, 86]]",['ME'],"[[88, 90]]"
43,43," select_id_schema(Sign,Sit,Phrase,NewSit) :-  id_schema(ID),  extend~sit (Sit,NewS\]l), ",44,['ID'],['id_schema'],"[[55, 57]]","[[7, 16]]",['id_schema'],['ID'],"[[8, 17]]",['NewSit'],"[[34, 40]]"
44,44,"different tags: B-L (Beginning of a literal chunk), I-L (Inside of a literal chunk), B-I (Beginning an Idiomatic chunk), I-I (Inside an Idiomatic chunk), O (Outside a chunk).",45,"['B-L', 'I-L', 'B-I', 'I-I']","['Beginning of a literal', 'Inside of a literal', 'Beginning an Idiomatic', 'Inside an Idiomatic', 'a']","[[16, 19], [52, 55], [85, 88], [121, 124]]","[[21, 43], [57, 76], [90, 112], [126, 145], [11, 12]]","['Beginning of a literal', 'Inside of a literal', 'Beginning an Idiomatic', 'Inside an Idiomatic']","['B-L', 'I-L', 'B-I', 'I-I']","[[21, 43], [57, 76], [90, 112], [126, 145]]","['B-L', 'I-L', 'B-I', 'I-I']","[[16, 19], [52, 55], [85, 88], [121, 124]]"
45,45,"Besides, other tools such as ELAN2 or Anvil3 are available as well, as are tool kits such as the Annotation Graph Toolkit (AGTK)4 or the NITE XML Toolkit.5 While multimodal annotation",46,"['ELAN2', 'AGTK']",['Annotation Graph Toolkit'],"[[29, 34], [123, 127]]","[[97, 121]]",['Annotation Graph Toolkit'],"['ELAN2', 'AGTK']","[[97, 121]]","['ELAN2', 'NITE']","[[29, 34], [137, 141]]"
46,46,Eparl+NC no 29.28 (0.11) 55.28 (0.13) Eparl+NC yes 29.26 (0.10) 55.44 (0.29) Table 1: Results of the study on number translation (NT) from English to French,47,['NT'],"['no', 'on number translation']","[[130, 132]]","[[9, 11], [107, 128]]",['on number translation'],['NT'],"[[107, 128]]",['NT'],"[[130, 132]]"
47,47,"Xue and Palmer, 2005). The present version  PCTB5 (PCTB Version 5), contains 18,782 sentences, 507,222 words, 824,983 Hanzi and 890 ",48,['PCTB5'],['PCTB Version 5'],"[[44, 49]]","[[51, 65]]",['PCTB Version 5'],['PCTB5'],"[[51, 65]]",['PCTB5'],"[[44, 49]]"
48,48,Proper noun (PropN): yes when the description has a capitalized initial.  Restrictive postmodification (RPostm): yes if the definite description is modified by relative or associative clauses.,49,"['PropN', 'RPostm']","['Proper noun', 'a', 'Restrictive postmodification']","[[13, 18], [104, 110]]","[[0, 11], [47, 48], [74, 102]]","['Proper noun', 'Restrictive postmodification']","['PropN', 'RPostm']","[[0, 11], [74, 102]]","['PropN', 'RPostm']","[[13, 18], [104, 110]]"
49,49,"ply it on substrings of names. In the English to Russian task, we report ACC (Accuracy in top-1) of 0.545,  Mean F-score of 0.917, and MRR (Mean Reciprocal  ",50,"['ACC', 'MRR']","['Accuracy', 'Mean']","[[73, 76], [135, 138]]","[[78, 86], [108, 112]]",['Accuracy'],"['ACC', 'MRR']","[[78, 86]]","['ACC', 'MRR']","[[73, 76], [135, 138]]"
50,50,"Lexico-syntactic properties of English Non-Deverbal Event Nouns (NDV E N),  Process Nouns (PR-N) and Result Nouns (RESN) and Non Event Nouns (NEN).",51,['NDV'],"['Event', 'Nouns', 'E N', 'Process Nouns', 'Result Nouns', 'Non Event Nouns']","[[65, 68]]","[[52, 57], [58, 63], [69, 72], [76, 89], [101, 113], [125, 140]]","['Process Nouns', 'Result Nouns', 'Non Event Nouns']",['NDV'],"[[76, 89], [101, 113], [125, 140]]","['NDV E N', 'PR-N', 'RESN', 'NEN']","[[65, 72], [91, 95], [115, 119], [142, 145]]"
51,51,"dimensionality reduction. NG = ngrams, E = emoticon replacement, IR = informal register replacement, TL = tweet length, RT = retweet count, SVO = subject-verb-",52,"['NG', 'IR', 'TL', 'RT', 'SVO']","['ngrams', 'emoticon', 'informal register', 'tweet length', 'retweet']","[[26, 28], [65, 67], [101, 103], [120, 122], [140, 143]]","[[31, 37], [43, 51], [70, 87], [106, 118], [125, 132]]","['ngrams', 'emoticon', 'informal register', 'tweet length', 'retweet']","['NG', 'IR', 'TL', 'RT', 'SVO']","[[31, 37], [43, 51], [70, 87], [106, 118], [125, 132]]","['NG', 'IR', 'TL', 'RT', 'SVO']","[[26, 28], [65, 67], [101, 103], [120, 122], [140, 143]]"
52,52,"levels of the discourse tree. Segmented Discourse  Structure Theory (SDRT) is introduced (Asher,  1993) and the predictions of this theory are dis- ",53,['SDRT'],"['Segmented Discourse Structure Theory', 'is']","[[69, 73]]","[[-1, 35], [15, 17]]",['Segmented Discourse Structure Theory'],['SDRT'],[],['SDRT'],"[[69, 73]]"
53,53,We describe two classifiers we have built for relevance. A Naive Bayes classifier (NB) was used as the baseline.,54,['NB'],['Naive Bayes classifier'],"[[83, 85]]","[[59, 81]]",['Naive Bayes classifier'],['NB'],"[[59, 81]]",['NB'],"[[83, 85]]"
54,54,"On all test sets, and for both the evaluation metrics used, the results achieved by the classifier built from the automatically annotated training set (AA) produces lower error rates (Weighted FPR-FDR)",55,['AA'],['annotated'],"[[152, 154]]","[[128, 137]]",['annotated'],['AA'],"[[128, 137]]","['AA', 'FPR-FDR']","[[152, 154], [193, 200]]"
55,55,Figure 1: The system combination architecture.  system prior weights and a language model (LM). ,56,['LM'],['a language model'],"[[91, 93]]","[[73, 89]]",['language model'],['LM'],"[[75, 89]]",['LM'],"[[91, 93]]"
56,56,and its too slowly paced to be a thriller.  Question Classification (QC)What is the temperature at the center of the earth? numberWhat state did the Battle of Bighorn take place in?,57,['QC'],"['a', 'Question Classification', 'at']","[[69, 71]]","[[0, 1], [44, 67], [62, 64]]",['Question Classification'],['QC'],"[[44, 67]]",[],[]
57,57,"Table 3: AMT evaluation results. Numbers are percentages or counts. BL = baseline, SY = system, N-D = no decision, B=S = same sentence selected by baseline and system",58,"['AMT', 'BL', 'SY', 'N-D']","['baseline', 'system', 'no decision', 'same', 'sentence', 'baseline']","[[9, 12], [68, 70], [83, 85], [96, 99]]","[[73, 81], [88, 94], [102, 113], [121, 125], [126, 134], [73, 81]]","['baseline', 'system', 'no decision', 'sentence', 'baseline']","['AMT', 'BL', 'SY', 'N-D']","[[73, 81], [88, 94], [102, 113], [126, 134], [73, 81]]","['AMT', 'BL', 'SY', 'N-D']","[[9, 12], [68, 70], [83, 85], [96, 99]]"
58,58, From the annotation pipeline we extracted as features: the polar words (PolW) and their basic polarity (Pol); the sentiment annotations from LIWC,59,"['PolW', ')']","['polar', 'words']","[[72, 76], [76, 77]]","[[59, 64], [65, 70]]",[],"['PolW', ')']",[],"['PolW', 'Pol', 'LIWC']","[[73, 77], [73, 76], [142, 146]]"
59,59,"There-fore, the end for the tram was sealed in the 1970s.] As an application example, a small corpus consisting of 21 newspaper articles is analyzed. The corpus belongs to the interdisciplinary pro-ject Future Mobility (FuMob), which is funded by the Excellent Initiative of the German federal and state governments. The methodological ap-proach consists of three steps, which are per-formed iteratively: (1) manual discourse-linguistic argumentation analysis, (2) semi-automatic Text Mining (PoS-tagging and linguis-tic multi-level annotation), and (3) data merge.",60,"['a', 'FuMob']","['in', 'Future Mobility', 'Mining']","[[30, 31], [220, 225]]","[[44, 46], [203, 218], [485, 491]]","['Future Mobility', 'Mining']","['a', 'FuMob']","[[203, 218], [485, 491]]",['FuMob'],"[[220, 225]]"
60,60,"~21   Proceedings of the Workshop on Discourse in Machine Translation (DiscoMT), pages 10?18, Sofia, Bulgaria, August 9, 2013.",61,['DiscoMT'],['on Discourse in Machine Translation'],"[[71, 78]]","[[34, 69]]",['on Discourse in Machine Translation'],['DiscoMT'],"[[34, 69]]",['DiscoMT'],"[[71, 78]]"
61,61,"For instance, in (def4) a polar interrogative clauses  (I'olS) is detined as a verb-first clause (V1S), which  in (def3) is deiined as a main clause (MainS), which  in turn is defined as a clause (S).",62,[],"['in', 'a', 'clauses', 'a verb-first clause', 'in', 'a', 'clause', 'in', 'a clause']",[],"[[4, 6], [8, 9], [46, 53], [77, 96], [4, 6], [8, 9], [46, 52], [4, 6], [187, 195]]","['clauses', 'verb-first clause', 'clause']",[''],"[[46, 53], [79, 96], [46, 52]]","['V1S', 'MainS']","[[98, 101], [150, 155]]"
62,62,number of correct matched constituents in proposed parse  number of constituents in treebank parse  3) Crossing Brackets(CBs) ffinumber of constituents which violate constituent boundaries with a  constituent inthe treebank parse.,63,[],"['in', 'in', 'Crossing', 'a']",[],"[[39, 41], [39, 41], [103, 111], [19, 20]]",['Crossing'],[''],"[[103, 111]]",[],[]
63,63, 1 Introduction Word Sense Disambiguation (WSD) is the process of resolving the meaning of a word unambiguously,64,[')'],"['Sense Disambiguation', 'is', 'a']","[[45, 46]]","[[20, 40], [27, 29], [29, 30]]",['Sense Disambiguation'],[')'],"[[21, 41]]",['WSD'],"[[43, 46]]"
64,64,"In order to represent gram-  mar rules distributively, we adopt categorial unifi-  cAtion grammar (CUG) Where eaclh category owns  its functional type.",65,[')'],['grammar'],"[[102, 103]]","[[90, 97]]",['grammar'],[')'],"[[90, 97]]",['CUG'],"[[99, 102]]"
65,65,Translate has achieved very good results on the  Chinese-to-English translation tracks of NIST open  machine translation test (MT)5 and it ranks the first  on most tracks.,66,"['NIST', 'MT']","['on', 'translation', 'machine translation test', 'on']","[[90, 94], [127, 129]]","[[41, 43], [68, 79], [101, 125], [41, 43]]",['machine translation test'],"['NIST', 'MT']","[[101, 125]]",['NIST'],"[[90, 94]]"
66,66," In earlier topic modeling work such as latent Dirichlet alocation (LDA) (Blei et al, 2003; Griffiths and Steyvers, 2004), documents are treated as bags of",67,['LDA'],"['latent Dirichlet alocation', 'et al']","[[67, 70]]","[[39, 65], [53, 58]]",['latent Dirichlet alocation'],['LDA'],"[[40, 66]]",['LDA'],"[[68, 71]]"
67,67,"Apart from  other features, each modifier should be anno/atecl  with a pragmatic function feature (PRAGM), which  specifies why a modifier is used it: an NP.",68,['PRAGM'],"['a pragmatic function feature', 'a']","[[99, 104]]","[[69, 97], [2, 3]]",['pragmatic function feature'],['PRAGM'],"[[71, 97]]","['PRAGM', 'NP']","[[99, 104], [154, 156]]"
68,68,"way as the above feature.  The Acoustic Features (AF) were extracted directly from the wave files using SoX: Minimum,",69,['AF'],['Acoustic Features'],"[[50, 52]]","[[31, 48]]",['Acoustic Features'],['AF'],"[[31, 48]]","['AF', 'SoX']","[[50, 52], [104, 107]]"
69,69,"factfinding? technology, Information Extraction (IE), to determine exactly what happened in each article:",70,['IE'],['Information Extraction'],"[[49, 51]]","[[25, 47]]",['Information Extraction'],['IE'],"[[25, 47]]",['IE'],"[[49, 51]]"
70,70," Relations between function words and content words (e.g. specifier (SPR), marker complement (CMP), infinitival zu marker (PM)) are frequent and",71,"['SPR', 'CMP', 'PM']","['specifier', 'marker', 'complement', 'infinitival zu marker']","[[68, 71], [93, 96], [122, 124]]","[[57, 66], [74, 80], [81, 91], [99, 120]]","['specifier', 'complement', 'infinitival zu marker']","['SPR', 'CMP', 'PM']","[[58, 67], [82, 92], [100, 121]]","['SPR', 'CMP', 'PM']","[[69, 72], [94, 97], [123, 125]]"
71,71,name along the path ? LCA (Lowest Common Ancestor) path that is from ORG name to its lowest common ancestor with PRO name,72,"['LCA', 'ORG']","['Lowest Common Ancestor', 'to']","[[22, 25], [69, 72]]","[[27, 49], [46, 48]]",['Lowest Common Ancestor'],"['LCA', 'ORG']","[[27, 49]]","['LCA', 'ORG', 'PRO']","[[22, 25], [69, 72], [113, 116]]"
72,72,1 The following abbreviations are used POSS = possessive prefix/suffix; LOC = locative suffix; OBV = obviative suffix; DIM = diminutive suffix; NUM = number marking suffix; IN,73,[],[],[],[],[],[''],[],"['POSS', 'LOC', 'OBV', 'DIM', 'NUM']","[[39, 43], [72, 75], [95, 98], [119, 122], [144, 147]]"
73,73,"the Brill tagger.  NNP = proper noun, CD = cardinal number,  CC = coordinating conjunction, JJ = adjective, VBG = verb,  gerund/present participle ",74,"['CD', 'CC', 'JJ', 'VBG']","['noun', ',', 'cardinal', ',', 'coordinating conjunction ,', 'adjective ,']","[[38, 40], [61, 63], [92, 94], [108, 111]]","[[32, 36], [36, 37], [43, 51], [36, 37], [-1, 25], [-1, 10]]","['cardinal', 'coordinating conjunctio', 'adjectiv']","['CD', 'CC', 'JJ', 'VBG']","[[43, 51], [66, 89], [97, 105]]","['NNP', 'CD', 'CC', 'JJ', 'VBG']","[[19, 22], [38, 40], [61, 63], [92, 94], [108, 111]]"
74,74,natural_object(NOBJ) substance(SUB)  food(FOOD) artifact(AFT) article(ART)  location(LOC) psych_feature(PSY)  cognition(COG) feeling(FEEL) ,75,"['NOBJ', 'SUB', 'FOOD', 'AFT', 'ART', 'LOC', 'PSY', 'COG', 'FEEL']","['substance', 'food', 'artifact', 'article', 'location', 'psych_feature', 'cognition', 'feeling']","[[15, 19], [31, 34], [42, 46], [57, 60], [70, 73], [85, 88], [104, 107], [120, 123], [133, 137]]","[[21, 30], [37, 41], [48, 56], [62, 69], [76, 84], [90, 103], [110, 119], [125, 132]]","['substance', 'artifact', 'article', 'location', 'psych_feature', 'cognition', 'feeling']","['NOBJ', 'SUB', 'FOOD', 'AFT', 'ART', 'LOC', 'PSY', 'COG', 'FEEL']","[[21, 30], [48, 56], [62, 69], [76, 84], [90, 103], [110, 119], [125, 132]]",[],[]
75,75,the increase is.  Table 2 shows the average solve time (ST) for sentences with respect to the number of tokens in,76,['ST'],['solve time'],"[[56, 58]]","[[44, 54]]",['solve time'],['ST'],"[[44, 54]]",['ST'],"[[56, 58]]"
76,76,"language processing. Specifically, stochastic finitestate transducers (SFSTs) have proved to be useful for machine translation tasks within restricted do-",77,['SFSTs'],"['stochastic finitestate transducers', 'to']","[[71, 76]]","[[35, 69], [36, 38]]",['stochastic finitestate transducers'],['SFSTs'],"[[35, 69]]",['SFSTs'],"[[71, 76]]"
77,77,"Inspired by our experience of dealing with different text classification problems, we decide to  employ a linear support vector machine (SVM) in  our NLI2013 system.",78,"['SVM', 'NLI2013']","['to', 'a', 'support vector machine', 'in']","[[137, 140], [150, 157]]","[[93, 95], [32, 33], [113, 135], [34, 36]]",['support vector machine'],"['SVM', 'NLI2013']","[[113, 135]]",['SVM'],"[[137, 140]]"
78,78, The transformation phase is done by applying singular value decomposition (SVD) to the initial term-by-sentence matrix defined as A = U?V T .,79,['SVD'],['singular value decomposition'],"[[75, 78]]","[[45, 73]]",['singular value decomposition'],['SVD'],"[[46, 74]]",['SVD'],"[[76, 79]]"
79,79,"Abstract WordNet, a widely used sense inventory for Word Sense Disambiguation(WSD), is often too fine-grained for many Natural Language",80,['WSD'],"['a', 'Word Sense Disambiguation', 'is']","[[78, 81]]","[[5, 6], [52, 77], [64, 66]]",['Word Sense Disambiguation'],['WSD'],"[[52, 77]]",[],[]
80,80,"Mihael Arcan and Paul Buitelaar Unit for Natural Language Processing, Digital Enterprise Research Institute (DERI) National University of Ireland Galway (NUIG)",81,"['DERI', 'NUIG']","['Unit', 'Digital Enterprise Research Institute', 'National University of Ireland']","[[109, 113], [154, 158]]","[[32, 36], [70, 107], [115, 145]]","['Digital Enterprise Research Institute', 'National University of Ireland']","['DERI', 'NUIG']","[[70, 107], [115, 145]]","['DERI', 'NUIG']","[[109, 113], [154, 158]]"
81,81," For French, the main problem was to retrieve MWEs (Multi Word Expression) in pred data mode.",82,['MWEs'],['Multi Word Expression'],"[[45, 49]]","[[51, 72]]",['Multi Word Expression'],['MWEs'],"[[52, 73]]",['MWEs'],"[[46, 50]]"
82,82,General-type: region Specific type: RCC Spatial value: PP (proper part) Dynamic,83,"['RCC', 'PP']",['proper part'],"[[36, 39], [55, 57]]","[[59, 70]]",['proper part'],"['RCC', 'PP']","[[59, 70]]","['RCC', 'PP']","[[36, 39], [55, 57]]"
83,83,system of Conceptual Dependency (Schank 1975). Some of the  Conceptual Dependency (CD) s t r u c t u r e s  are passed on to a program  which expresses them in E n g l i s h .,84,['CD'],"['Conceptual Dependency', 'Conceptual Dependency', 't r u c t u', 'e', 'a', 'n', 'l']","[[83, 85]]","[[10, 31], [10, 31], [89, 100], [4, 5], [18, 19], [12, 13], [19, 20]]","['Conceptual Dependency', 'Conceptual Dependency']",['CD'],"[[10, 31], [10, 31]]",['CD'],"[[83, 85]]"
84,84,"60  Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 118?125, Seoul, South Korea, 5-6 July 2012.",85,['SIGDIAL'],['Special Interest Group on Discourse and Dialogue'],"[[100, 107]]","[[50, 98]]",['Special Interest Group on Discourse and Dialogue'],['SIGDIAL'],"[[50, 98]]",['SIGDIAL'],"[[100, 107]]"
85,85," Chapter 1 has the lowest pi?S score in the table, and also the highest bias (BS). One of the reasons for",86,['S'],['highest bias'],"[[28, 29]]","[[63, 75]]",['highest bias'],['S'],"[[64, 76]]",['BS'],"[[78, 80]]"
86,86,order to adapt them to process dialects. This paper adopts this general framework: we propose a method to build a lexicon of deverbal nouns for Tunisian (TUN) using MSA tools and resources as starting material.,87,"['TUN', 'MSA']","['a', 'a', 'Tunisian']","[[154, 157], [165, 168]]","[[9, 10], [9, 10], [144, 152]]",['Tunisian'],"['TUN', 'MSA']","[[144, 152]]","['TUN', 'MSA']","[[154, 157], [165, 168]]"
87,87,"3 Approach Following this intuition, we fit a directed Gaussian graphical model (GGM) that simultaneously considers (i) each word?s embedding (obtained from",88,['GGM'],"['a', 'Gaussian graphical model', 'i', 's']","[[81, 84]]","[[7, 8], [55, 79], [17, 18], [24, 25]]",['Gaussian graphical model'],['GGM'],"[[55, 79]]",['GGM'],"[[81, 84]]"
88,88,In Proc. of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL). ,89,['ACL'],['Association for Computational Linguistics'],"[[86, 89]]","[[43, 84]]",['Association for Computational Linguistics'],['ACL'],"[[43, 84]]",['ACL'],"[[86, 89]]"
89,89,teacher for advice.  ,90,[],[],[],[],[],[''],[],[],[]
90,90,"models. Among stochastic models, bi-gram and  tri-gram Hidden Markov Model (HMM) are  quite popular.",91,['HMM'],['Hidden Markov Model'],"[[76, 79]]","[[55, 74]]",['Hidden Markov Model'],['HMM'],"[[55, 74]]",['HMM'],"[[76, 79]]"
91,91,"els, which seamlessly incorporates graphbased and more general supervision by extending the posterior regularization (PR) framework.",92,['PR'],['posterior regularization'],"[[118, 120]]","[[92, 116]]",['posterior regularization'],['PR'],"[[92, 116]]",['PR'],"[[118, 120]]"
92,92,"{alexispalmer,ponvert,jbaldrid,carlotasmith}@mail.utexas.edu Abstract Situation entities (SEs) are the events, states, generic statements, and embedded facts and",93,['SEs'],['Situation entities'],"[[90, 93]]","[[70, 88]]",['Situation entities'],['SEs'],"[[70, 88]]",['SEs'],"[[90, 93]]"
93,93," Conf. Computational Linguistics (COLING), pages 89?97.",94,[')'],['Linguistics'],"[[39, 40]]","[[20, 31]]",['Linguistics'],[')'],"[[21, 32]]",['COLING'],"[[34, 40]]"
94,94,"TO-DEATH).  VAg and related NPs/PPs (VAgRel) This is similar to VPa above, but for VAg.",95,"['TO-DEATH', 'VAg', 'VPa']",[],"[[0, 8], [12, 15], [64, 67]]",[],[],"['TO-DEATH', 'VAg', 'VPa']",[],"['TO-DEATH', 'VAg', 'NPs', 'PPs', 'VPa', 'VAg']","[[0, 8], [12, 15], [28, 31], [32, 35], [64, 67], [12, 15]]"
95,95,"Reduced Sentences 0.121 0.055 4.89 0.027* 1.129 1.01 to 1.26 Constant 5.23 1.18 19.67 <0.000* 187.25 ADAG, n=242; HAG, n = 242; S.E = standard error; OR = Odds ratio or Exp(?); CI = confidence Interval.",96,"['HAG', 'OR', 'CI']","['n', 'Odds ratio', 'confidence Interval']","[[114, 117], [150, 152], [177, 179]]","[[10, 11], [155, 165], [182, 201]]","['Odds ratio', 'confidence Interval']","['HAG', 'OR', 'CI']","[[155, 165], [182, 201]]","['HAG', 'OR', 'CI']","[[114, 117], [150, 152], [177, 179]]"
96,96,"to learn coherent topics. To solve this problem, we build a Markov Random Field (MRF) regularized Latent Dirichlet Allocation (LDA)",97,"['MRF', 'LDA']","['a Markov Random Field', 'Latent Dirichlet Allocation']","[[81, 84], [127, 130]]","[[58, 79], [98, 125]]","['Markov Random Field', 'Latent Dirichlet Allocation']","['MRF', 'LDA']","[[60, 79], [98, 125]]","['MRF', 'LDA']","[[81, 84], [127, 130]]"
97,97,"mensions. The counts were then transformed into Local Mutual Information (LMI) scores, an association measure that closely approximates the com-",98,['LMI'],['Local Mutual Information'],"[[74, 77]]","[[48, 72]]",['Local Mutual Information'],['LMI'],"[[48, 72]]",['LMI'],"[[74, 77]]"
98,98,bringert@chalmers.se Abstract Grammatical Framework (GF) is a grammar formalism which supports interlingua-,99,['GF'],"['Grammatical Framework', 'a']","[[53, 55]]","[[30, 51], [11, 12]]",['Grammatical Framework'],['GF'],"[[30, 51]]",['GF'],"[[53, 55]]"
99,99," Conf. on Language Resources and Evaluation (LREC), pages 697?702, Genoa, Italy, May.",100,[')'],['Resources'],"[[48, 49]]","[[18, 27]]",['Resources'],[')'],"[[19, 28]]",['LREC'],"[[45, 49]]"
100,100,"stantin, Evan Herbst, Moses: Open Source Toolkit for Statistical Machine Translation, Annual Meeting of the Association for Computational Linguistics (ACL), demonstration session, Prague, Czech Republic, June",101,['ACL'],"['for', 'Association for Computational Linguistics']","[[151, 154]]","[[49, 52], [108, 149]]",['Association for Computational Linguistics'],['ACL'],"[[108, 149]]",['ACL'],"[[151, 154]]"
101,101," In an effort to apply such models to noisy optical character recognition (OCR) text output, we endeavor to understand the effect",102,['OCR'],['optical character recognition'],"[[74, 77]]","[[43, 72]]",['optical character recognition'],['OCR'],"[[44, 73]]",['OCR'],"[[75, 78]]"
102,102,the fragment space that can describe all the trees in Ms. Fragment Mining and Indexing (FMI) In Equation 1 it is possible to isolate the gradient ~w =?,103,['FMI'],"['in', 'Fragment Mining and Indexing', 'In']","[[88, 91]]","[[51, 53], [58, 86], [78, 80]]",['Fragment Mining and Indexing'],['FMI'],"[[58, 86]]",['FMI'],"[[88, 91]]"
103,103,"Section 3 for exact criteria), reporting  approximately 40% precision and 45% recall for  transitional probability (TP) and 50% precision and  53% recall for mutual information (MI) on the first ",104,"['TP', 'MI']","['for', 'for', 'transitional probability', 'for mutual information', 'on']","[[116, 118], [178, 180]]","[[10, 13], [10, 13], [90, 114], [154, 176], [5, 7]]","['transitional probability', 'for mutual information']","['TP', 'MI']","[[90, 114], [154, 176]]","['TP', 'MI']","[[116, 118], [178, 180]]"
104,104,"are at least four candidates: less studied (LS) languages, resource scarce (RS) languages, less computerized (LC) languages, and less privileged (LP) languages.",105,"['LS', 'RS', 'LC', 'LP']","['less studied', 'resource scarce', 'less', 'computerized', 'less privileged']","[[44, 46], [76, 78], [110, 112], [146, 148]]","[[30, 42], [59, 74], [30, 34], [96, 108], [129, 144]]","['less studied', 'resource scarce', 'computerized', 'less privileged']","['LS', 'RS', 'LC', 'LP']","[[30, 42], [59, 74], [96, 108], [129, 144]]","['LS', 'RS', 'LC', 'LP']","[[44, 46], [76, 78], [110, 112], [146, 148]]"
105,105,"thesauri: Macquarie, Moby, Oxford and Roget?s.  The inverse rank (InvR) metric allows a comparison to be made between the extracted rank list",106,['InvR'],"['s', 'inverse rank', 'a', 'rank']","[[66, 70]]","[[3, 4], [52, 64], [4, 5], [60, 64]]",['inverse rank'],['InvR'],"[[52, 64]]",['InvR'],"[[66, 70]]"
106,106,  1 Introduction  Word Sense Disambiguation (WSD) is wellknown as one of the more difficult problems in ,107,[')'],"['Sense Disambiguation', 'is']","[[46, 47]]","[[21, 41], [28, 30]]",['Sense Disambiguation'],[')'],"[[23, 43]]",['WSD'],"[[45, 48]]"
107,107,FF-AUTO-NONE Fullform Auto None FF-DEFAULT-GRAM Fullform Default Auto (GRAM) FF-AUTO-GRAM Fullform Auto Auto (GRAM) FF-DEFAULT-SAO* Fullform Default Auto (SAO),108,"['GRAM', 'SAO']","['Fullform Auto', 'Fullform Default Auto', 'Fullform Auto Auto', 'Fullform Default Auto']","[[43, 47], [127, 130]]","[[13, 26], [48, 69], [90, 108], [48, 69]]","['Fullform Default Auto', 'Fullform Auto Auto', 'Fullform Default Auto']","['GRAM', 'SAO']","[[48, 69], [90, 108], [48, 69]]","['FF-AUTO-NONE', 'FF-DEFAULT-GRAM', 'GRAM', 'FF-AUTO-GRAM', 'GRAM', 'FF-DEFAULT-SAO', 'SAO']","[[0, 12], [32, 47], [43, 47], [77, 89], [43, 47], [116, 130], [127, 130]]"
108,108,"The parameters are trained using the 764 Margin Infused Relaxed Algorithm (MIRA) (Crammer et al, 2006).",109,[')'],['Infused Relaxed Algorithm'],"[[79, 80]]","[[48, 73]]",['Infused Relaxed Algorithm'],[')'],"[[48, 73]]",['MIRA'],"[[75, 79]]"
109,109," ? Activity Tree (AT): a tree-structure representing the current, past, and planned activities that",110,[')'],"['Tree', 'a']","[[19, 20]]","[[11, 15], [22, 23]]",[],[')'],[],['AT'],"[[18, 20]]"
110,110,ging from Merialdo (1994). The approach involved training a standard Hidden Markov Model (HMM) using the Expectation Maximization (EM) algo-,111,"['HMM', 'EM']","['a', 'Hidden Markov Model', 'Expectation Maximization']","[[90, 93], [131, 133]]","[[14, 15], [69, 88], [105, 129]]","['Hidden Markov Model', 'Expectation Maximization']","['HMM', 'EM']","[[69, 88], [105, 129]]","['HMM', 'EM']","[[90, 93], [131, 133]]"
111,111,"email: {firstname.lastname} @itri.bton.ac.uk  Introduction ~,  WYSIWYM (What You See Is What You Meant) is a user interface technique which allows anauthor to create  and edit in a natural and simple way the knowledge contained in a generated document.",112,['WYSIWYM'],"['What You See Is What You Meant', 'a', 'a', 'a']","[[63, 70]]","[[72, 102], [2, 3], [2, 3], [2, 3]]",['What You See Is What You Meant'],['WYSIWYM'],"[[72, 102]]",['WYSIWYM'],"[[63, 70]]"
112,112,"and beyond, in several AI applications. Neel and Garzon (2010) show that the quality of a knowledge resource like WN affects the performance in recognizing textual entailment (RTE) and word-sense disambiguation (WSD) tasks.",113,"['AI', 'RTE', 'WSD']","['a', 'textual', 'word-sense disambiguation']","[[23, 25], [176, 179], [212, 215]]","[[0, 1], [156, 163], [185, 210]]","['textual', 'word-sense disambiguation']","['AI', 'RTE', 'WSD']","[[156, 163], [185, 210]]","['AI', 'WN', 'RTE', 'WSD']","[[23, 25], [114, 116], [176, 179], [212, 215]]"
113,113,"This measure combines two metrics. The first metric, predicted frequency (PF), estimates the degree to which a word appears to be used consis-",114,['PF'],['predicted frequency'],"[[74, 76]]","[[53, 72]]",['predicted frequency'],['PF'],"[[53, 72]]",['PF'],"[[74, 76]]"
114,114,"Table 5: Participating teams and references to system descriptions. Abbreviations: BI=Bioinformatician, NLP=Natural Language Processing researcher, CS=Computer Scientist, LI=Linguist, ML=Machine Learning researcher.",115,[],"['Language Processing', 'Scientist', 'Learning']",[],"[[116, 135], [160, 169], [195, 203]]","['Language Processing', 'Scientist', 'Learning']",[''],"[[116, 135], [160, 169], [195, 203]]","['BI', 'NLP', 'CS', 'LI', 'ML']","[[83, 85], [104, 107], [148, 150], [171, 173], [184, 186]]"
115,115,predictive ones among all our features. We used the Correlation based Feature Subset (CFS) selection method in WEKA for this purpose.,116,"['CFS', 'WEKA']",['Correlation based Feature Subset'],"[[86, 89], [111, 115]]","[[52, 84]]",['Correlation based Feature Subset'],"['CFS', 'WEKA']","[[52, 84]]","['CFS', 'WEKA']","[[86, 89], [111, 115]]"
116,116,"In Ellen M. Voorhees and Donna K. Harman, editors, The Seventh Text Retrieval Conference (TREC-7), volume 7.",117,['TREC-7'],['Seventh Text Retrieval Conference'],"[[90, 96]]","[[55, 88]]",['Seventh Text Retrieval Conference'],['TREC-7'],"[[55, 88]]",['TREC-7'],"[[90, 96]]"
117,117,"currently concerns include Chinese personal  names( CN), transliterated foreign personal names( TFN)  and Chinese place names(CPN). They can not be ",118,"['CN', 'TFN']","['Chinese personal names', 'transliterated foreign personal names', 'Chinese place names']","[[52, 54], [96, 99]]","[[-1, 21], [57, 94], [106, 125]]","['Chinese personal names', 'transliterated foreign personal names', 'Chinese place names']","['CN', 'TFN']","[[57, 94], [106, 125]]","['CN', 'TFN']","[[52, 54], [96, 99]]"
118,118,"The results are reported for Same Sentence (SS) and Previous Sentence (PS) models, and the joined results for each of the arguments (ALL) as average",119,"['SS', 'PS', 'ALL']","['Same', 'Sentence', 'Previous Sentence', 'arguments']","[[44, 46], [71, 73], [133, 136]]","[[29, 33], [34, 42], [52, 69], [122, 131]]","['Previous Sentence', 'arguments']","['SS', 'PS', 'ALL']","[[52, 69], [122, 131]]","['SS', 'PS', 'ALL']","[[44, 46], [71, 73], [133, 136]]"
119,119,some structural constraints which are mostly prag-  matic in natnre:  2based on PVM (parallel virtual madfine)  semRnb~ ,120,['PVM'],"['in', 'parallel virtual madfine']","[[80, 83]]","[[23, 25], [85, 109]]",['parallel virtual madfine'],['PVM'],"[[85, 109]]",['PVM'],"[[80, 83]]"
120,120, and Iryna Gurevych Ubiquitous Knowledge Processing (UKP) Lab Computer Science Department,121,['UKP'],['Ubiquitous Knowledge Processing'],"[[52, 55]]","[[19, 50]]",['Ubiquitous Knowledge Processing'],['UKP'],"[[20, 51]]",['UKP'],"[[53, 56]]"
121,121,"This paper describes the Universal Decompositional Semantics (Decomp) project, which aims to augments Universal Dependencies (UD) data sets with robust, scalable semantic annotations based in lin-",122,['UD'],"['Universal Decompositional Semantics', 'Universal Dependencies']","[[126, 128]]","[[25, 60], [102, 124]]","['Universal Decompositional Semantics', 'Universal Dependencies']",['UD'],"[[25, 60], [102, 124]]",['UD'],"[[126, 128]]"
122,122,of National Intelligence (ODNI) and the Intelligence Advanced Research Projects Activity (IARPA) via the Air Force Research Laboratory (AFRL) contract number FA8750-16-C-0114.,123,"['ODNI', 'IARPA', 'AFRL']","['Intelligence', 'Intelligence Advanced Research Projects Activity', 'Air Force Research Laboratory']","[[26, 30], [90, 95], [136, 140]]","[[12, 24], [40, 88], [105, 134]]","['Intelligence Advanced Research Projects Activity', 'Air Force Research Laboratory']","['ODNI', 'IARPA', 'AFRL']","[[40, 88], [105, 134]]","['ODNI', 'IARPA', 'AFRL']","[[26, 30], [90, 95], [136, 140]]"
123,123,"nominal elements. For German, we see confusions with the object functions (accusative OA and dative objects DA), predicates (PD), and the EP function marking expletive pronouns in subject position.",124,"['OA', 'DA', 'PD', 'EP']","['object', 'dative objects', 'predicates']","[[86, 88], [108, 110], [125, 127], [138, 140]]","[[57, 63], [93, 107], [113, 123]]","['dative objects', 'predicates']","['OA', 'DA', 'PD', 'EP']","[[93, 107], [113, 123]]","['OA', 'DA', 'PD', 'EP']","[[86, 88], [108, 110], [125, 127], [138, 140]]"
124,124,"trated in Figure 1. At the outset, the table (T1), the  pump (PU), the apprentice (you) and the compressor  (COMP) are in ""primary focus"".",125,"['1', 'PU', 'COMP']","['pump', 'compressor']","[[17, 18], [62, 64], [109, 113]]","[[56, 60], [96, 106]]",['compressor'],"['1', 'PU', 'COMP']","[[96, 106]]","['T1', 'PU', 'COMP']","[[46, 48], [62, 64], [109, 113]]"
125,125," Thirdly, most PROLOG implementations include a  version of metamorphosis grammars (MGs), a logic-  based formalism useful in particular for describing NL ",126,['PROLOG'],"['a', 'metamorphosis grammars', 'a']","[[14, 20]]","[[30, 31], [59, 81], [30, 31]]",['metamorphosis grammars'],['PROLOG'],"[[60, 82]]","['PROLOG', 'MGs', 'NL']","[[15, 21], [84, 87], [152, 154]]"
126,126,"  Machine Translation (prototype phase)  The machine translation (MT) sub-component  implements the hybrid MT paradigm, combining ",127,[')'],['translation'],"[[36, 37]]","[[51, 62]]",['translation'],[')'],"[[10, 21]]","['MT', 'MT']","[[66, 68], [66, 68]]"
127,127,"for 4 of the 9 classes, and was usually competitive on the remaining 5 classes. WordNet (W.Net) consistently produced high precision, but with compar-",128,['.'],['WordNet'],"[[78, 79]]","[[80, 87]]",['WordNet'],['.'],"[[80, 87]]",[],[]
128,128,"as dependants. Dependency structures are suit-  ably depicted as a directed acyclic graph(DAG),  where arrows direct from dependants to gover- ",129,['DAG'],"['a directed acyclic graph', 'direct']","[[90, 93]]","[[65, 89], [67, 73]]",['directed acyclic graph'],['DAG'],"[[67, 89]]",[],[]
129,129,"These derivations were induced using a collapsed Gibbs sampler, which sampled from the posterior of a Dirichlet process (DP) defined over the subtree rewrites of each nonterminal.",130,['DP'],['Dirichlet process'],"[[121, 123]]","[[102, 119]]",['Dirichlet process'],['DP'],"[[102, 119]]",['DP'],"[[121, 123]]"
130,130," For both these models, we use cost sensitive LibSVM with radial basis kernel function (RBF) as the learning algorithm (Hsu et al.,",131,['RBF'],"['radial basis kernel function', 'as']","[[87, 90]]","[[57, 85], [65, 67]]",['radial basis kernel function'],['RBF'],"[[58, 86]]","['LibSVM', 'RBF']","[[46, 52], [88, 91]]"
131,131,is also significant that this model?s paraphraser can be employed not only for MT but also for most natural language processing (NLP) applications.,132,"['MT', 'NLP']","['s', 'natural language processing']","[[79, 81], [129, 132]]","[[1, 2], [100, 127]]",['natural language processing'],"['MT', 'NLP']","[[100, 127]]","['MT', 'NLP']","[[79, 81], [129, 132]]"
132,132,"6.2 Methodology We conducted experiments on MUC-6, ACE-2004, and ACE Phrase-2 (ACE-2). We evaluated our sys-",133,[],['ACE Phrase-2'],[],"[[65, 77]]",['ACE Phrase-2'],[''],"[[65, 77]]","['MUC-6', 'ACE', 'ACE-2']","[[44, 49], [51, 54], [51, 56]]"
133,133,"ALCOGRAM. ? P2E5N5S1, C T W D A I Common Logic Controlled English (CLCE) (Sowa 2004) is a language that can be translated into first-order logic with equality in the form of the Conceptual Graph",134,[],"['C', 'Common Logic Controlled English', 'is']",[],"[[2, 3], [34, 65], [62, 64]]",['Common Logic Controlled English'],[''],"[[34, 65]]","['ALCOGRAM', 'P2E5N5S1', 'CLCE']","[[0, 8], [12, 20], [67, 71]]"
134,134,"text categorization tasks. The newer method of Latent Semantic Indexing (LSI) 3 (Deerwester et al.,",135,['LSI'],['Latent Semantic Indexing'],"[[73, 76]]","[[47, 71]]",['Latent Semantic Indexing'],['LSI'],"[[47, 71]]",['LSI'],"[[73, 76]]"
135,135,"non-terminals is extended by means of conditional and additive categories according to Combinatory Categorical Grammar (CCG) (Steedman, 1999). ",136,['CCG'],['to Combinatory Categorical Grammar'],"[[120, 123]]","[[84, 118]]",['to Combinatory Categorical Grammar'],['CCG'],"[[84, 118]]",['CCG'],"[[120, 123]]"
136,136, These models are trained only using negative entities which we refer to as Negative Entity (NE) objective. ,137,['NE'],['Negative Entity'],"[[92, 94]]","[[75, 90]]",['Negative Entity'],['NE'],"[[76, 91]]",['NE'],"[[93, 95]]"
137,137,"main line of the narrative. This move is signaled  by the temporal focus (TF), and the entire deictic  center, returning to an established node in the ",138,['TF'],['temporal focus'],"[[74, 76]]","[[58, 72]]",['temporal focus'],['TF'],"[[58, 72]]",['TF'],"[[74, 76]]"
138,138, 4.1 Task  The Spontaneous Scheduling Task (SST) databases  are a collection of dialogues in which two speak- ,139,[')'],"['Task', 'Scheduling Task', 'a', 'in']","[[46, 47]]","[[4, 8], [26, 41], [5, 6], [33, 35]]",['Scheduling Task'],[')'],"[[27, 42]]",['SST'],"[[44, 47]]"
139,139,The Chinese text is segmented with a segmenter trained on CTB data using conditional random fields (CRF). Language models,140,"['CTB', 'CRF']","['a', 'on', 'conditional random fields']","[[58, 61], [100, 103]]","[[35, 36], [55, 57], [73, 98]]",['conditional random fields'],"['CTB', 'CRF']","[[73, 98]]","['CTB', 'CRF']","[[58, 61], [100, 103]]"
140,140,retrieval effectiveness. The following figure  shows the change of average precision (AvgP)  using CDQE (Model 2) along with the change of ,141,"['AvgP', 'CDQE']",['average precision'],"[[86, 90], [99, 103]]","[[67, 84]]",['average precision'],"['AvgP', 'CDQE']","[[67, 84]]","['AvgP', 'CDQE']","[[86, 90], [99, 103]]"
141,141,"level-2 domains) yet still did not sufficiently cover relevant subject fields identified by our users, such as IT, medicine and mechanical engineering. The Internal Classification for Standards (ICS) scheme was considered next, as it covers technical subject fields, but it was lacking with respect to legal and",142,"['IT', 'ICS']","['as', 'and', 'Internal Classification for Standards', 'as']","[[111, 113], [195, 198]]","[[108, 110], [124, 127], [156, 193], [108, 110]]",['Internal Classification for Standards'],"['IT', 'ICS']","[[156, 193]]","['IT', 'ICS']","[[111, 113], [195, 198]]"
142,142,"logical subject/object and its verb governor, General  Event (GE) on who did what when and where and  Predefined Event (PE) such as Management  Succession and Company Acquisition.",143,"['GE', 'PE']","['General', 'Event', 'Predefined Event']","[[62, 64], [120, 122]]","[[46, 53], [55, 60], [102, 118]]","['General', 'Predefined Event']","['GE', 'PE']","[[46, 53], [102, 118]]","['GE', 'PE']","[[62, 64], [120, 122]]"
143,143," We cover two main thrusts: (i) a black-box evaluation of several NE taggers (commercial and research systems); and (ii) an error analysis of system performance. 2.1 Evaluation data Our evaluation data set contains three distinct sec-tions.  The largest component consists of publicly-available financial reports filed with the Securities and Exchange Commission (SEC), in particular the 2003 forms 10-K filed by eight Fortune 500 com-panies.  These corporate annual reports share the same subject matter as much business news: sales, profits, acquisitions, business strategies and the like.",144,"['NE', 'SEC']","['i', 'a', 'and', 'and', 'an', 'Securities and Exchange Commission', 'and']","[[65, 67], [363, 366]]","[[15, 16], [14, 15], [88, 91], [88, 91], [88, 90], [327, 361], [88, 91]]",['Securities and Exchange Commission'],"['NE', 'SEC']","[[328, 362]]","['NE', 'SEC']","[[66, 68], [364, 367]]"
144,144,@math.canterbury.ac.nz Abstract We introduce Peripheral Diversity (PD) as a knowledge-based approach to achieve multi-,145,['PD'],"['Peripheral Diversity', 'a']","[[67, 69]]","[[45, 65], [2, 3]]",['Peripheral Diversity'],['PD'],"[[45, 65]]",['PD'],"[[67, 69]]"
145,145,"SS 0.47 5.1 100 times faster than that of Tree Kernel, and the retrieval speed of Subpath Set (SS) is about 1,000 times faster than that of Tree Kernel.",146,['SS'],['Subpath Set'],"[[0, 2]]","[[82, 93]]",['Subpath Set'],['SS'],"[[82, 93]]","['SS', 'SS']","[[0, 2], [0, 2]]"
146,146,"grammar (LTAG) (Bangalore and Joshi, 1999) and then extended to other lexicalized grammars, such as combinatory categorial grammar (CCG) (Clark, 2002) and Head-driven phrase structure grammar",147,"['LTAG', 'CCG']","['grammar', 'to', 'combinatory categorial grammar']","[[9, 13], [132, 135]]","[[0, 7], [61, 63], [100, 130]]",['combinatory categorial grammar'],"['LTAG', 'CCG']","[[100, 130]]","['LTAG', 'CCG']","[[9, 13], [132, 135]]"
147,147,"embeddings from the Neural Language Model of Collobert and Weston [2008] and word representations from random indexing (RI)1. These, however, were",148,['RI'],"['and', 'and', 'random indexing']","[[120, 122]]","[[55, 58], [55, 58], [103, 118]]",['random indexing'],['RI'],"[[103, 118]]",[],[]
148,148,"Finally, some Wikipages are redirections to other pages, e.g. SODA (SODIUM CARBONATE) redirects to SODIUM CARBONATE.",149,['SODA'],"['SODIUM CARBONATE', 'SODIUM CARBONATE']","[[62, 66]]","[[68, 84], [68, 84]]","['SODIUM CARBONATE', 'SODIUM CARBONATE']",['SODA'],"[[68, 84], [68, 84]]","['SODA', 'SODIUM', 'CARBONATE', 'SODIUM', 'CARBONATE']","[[62, 66], [68, 74], [75, 84], [68, 74], [75, 84]]"
149,149," : : , .  :~..~. NAT =nat iona =ty .:~:~',,~,.~ . .:.-,~.~;~ SRC~.;ob I .~concrete-:,~ ",150,['NAT'],[],"[[16, 19]]",[],[],['NAT'],[],['NAT'],"[[17, 20]]"
150,150,"+ BD 67.4 67.0 67.2 + NEG + BD 67.4 67.1 67.3 Table 1: Results on development corpus: LP = labeled precision, LR = labeled recall, F1 = balanced F-measure",151,"['BD', 'NEG', '1', 'LP', 'LR']","['on', 'labeled precision', 'labeled recall']","[[2, 4], [22, 25], [39, 40], [86, 88], [110, 112]]","[[63, 65], [91, 108], [115, 129]]","['labeled precision', 'labeled recall']","['BD', 'NEG', '1', 'LP', 'LR']","[[91, 108], [115, 129]]","['BD', 'NEG', 'BD', 'LP', 'LR', 'F1']","[[2, 4], [22, 25], [2, 4], [86, 88], [110, 112], [131, 133]]"
151,151,"Machine Translation. In 41st Annual Meeting of the Association for Computational Linguistics (ACL), pages 192?202, Sapporo, Japan.",152,['ACL'],['Association for Computational Linguistics'],"[[94, 97]]","[[51, 92]]",['Association for Computational Linguistics'],['ACL'],"[[51, 92]]",['ACL'],"[[94, 97]]"
152,152,against three baselines. The first baseline was based on the minimum overlap (MinOv) of characters in consecutive scenes and corresponds closely to the,153,['MinOv'],"['minimum overlap', 'in']","[[78, 83]]","[[61, 76], [3, 5]]",['minimum overlap'],['MinOv'],"[[61, 76]]",['MinOv'],"[[78, 83]]"
153,153,"by a rhetorical relation R, Triple=verb pair associated with a relation R in V 2 R, BG = Background, cont.=continuation, elab.=elaboration.",154,['BG'],"['a', 'a', 'Background']","[[84, 86]]","[[3, 4], [3, 4], [89, 99]]",['Background'],['BG'],"[[89, 99]]",['BG'],"[[84, 86]]"
154,154,"contains two data sets, training and devtest, which were used for training and testing, respectively. Each of these sets is further divided into three domains: newswire (NWire), newspaper (NPaper), and broadcast news (BNews).",155,['BNews'],['broadcast news'],"[[218, 223]]","[[202, 216]]",['broadcast news'],['BNews'],"[[202, 216]]","['NWire', 'BNews']","[[170, 175], [218, 223]]"
155,155,"Allocation (LDA), but using linguistic dependency information in place of simple features from bag of words (BOW) representations.",156,['BOW'],"['of', 'bag of words']","[[109, 112]]","[[71, 73], [95, 107]]",['bag of words'],['BOW'],"[[95, 107]]","['LDA', 'BOW']","[[12, 15], [109, 112]]"
156,156,"Pseudo-disambiguation results for inverse selectional preferences (BNC as primary and secondary corpus, DISCR weighting). ER = Error rate; Cov = Coverage. ",157,"['BNC', 'DISCR', 'ER']","['Error rate', 'Coverage']","[[67, 70], [104, 109], [122, 124]]","[[127, 137], [145, 153]]","['Error rate', 'Coverage']","['BNC', 'DISCR', 'ER']","[[127, 137], [145, 153]]","['BNC', 'DISCR', 'ER']","[[67, 70], [104, 109], [122, 124]]"
157,157, Results and Analysis  A finite state machine (FSM) description of user be-  havior was used to analyze session data.,158,['FSM'],['finite state machine'],"[[46, 49]]","[[24, 44]]",['finite state machine'],['FSM'],"[[25, 45]]",['FSM'],"[[47, 50]]"
158,158,"is used to generate ground truth answers).  The Children?s Book Test (CBT) dataset, created by Hill et al (2016), contains 113,719 cloze-style",159,['CBT'],['Children ? s Book Test'],"[[70, 73]]","[[-1, 21]]",['Children ? s Book Test'],['CBT'],[],['CBT'],"[[70, 73]]"
159,159,"ipants represent cognitive scenarios as schematic representations of events, objects, situations, or states of affairs. The participants are called frame elements (FEs) and are described in terms of semantic roles such as AGENT, LOCATION, or MANNER.",160,"['FEs', 'AGENT', 'MANNER']",['frame elements'],"[[164, 167], [222, 227], [242, 248]]","[[148, 162]]",['frame elements'],"['FEs', 'AGENT', 'MANNER']","[[148, 162]]","['FEs', 'AGENT', 'MANNER']","[[164, 167], [222, 227], [242, 248]]"
160,160,do you have? for taskswitching (SWT) and poker-playing (PKR) respectively.,161,"['SWT', 'PKR']",['taskswitching'],"[[32, 35], [56, 59]]","[[17, 30]]",['taskswitching'],"['SWT', 'PKR']","[[17, 30]]","['SWT', 'PKR']","[[32, 35], [56, 59]]"
161,161,"Conjoined noun phrases are required to all  be members of the same semantic  class, which may be one of the set PERSON, PHYSOB (physical object), LOCNAME  (location name), ATTRNAME (attribute name), or MEASU (measurement unit). ",162,"['PHYSOB', 'LOCNAME', 'MEASU']","['location', 'name', 'measurement unit']","[[120, 126], [146, 153], [202, 207]]","[[156, 164], [165, 169], [209, 225]]","['location', 'measurement unit']","['PHYSOB', 'LOCNAME', 'MEASU']","[[156, 164], [209, 225]]","['PHYSOB', 'LOCNAME', 'ATTRNAME', 'MEASU']","[[120, 126], [146, 153], [172, 180], [202, 207]]"
162,162,"mation is likely to be found). This is similar to  tasks such as named entity recognition (NER) or  part-of-speech tagging, where sequence modeling ",163,['NER'],['named entity recognition'],"[[91, 94]]","[[65, 89]]",['named entity recognition'],['NER'],"[[65, 89]]",['NER'],"[[91, 94]]"
163,163,"this assumption.  In a synchronous TAG (STAG) the elementary structures are ordered pairs of TAG trees, with a",164,[],"['a synchronous TAG', 'TAG']",[],"[[21, 38], [35, 38]]",['synchronous TAG'],[''],"[[23, 38]]","['STAG', 'TAG']","[[40, 44], [35, 38]]"
164,164,3.2 Graph-based Approaches Laparra et al(2010) utilize the SSI-Dijkstra+ algorithm to align FN lexical units (LUs) with WN synsets.,165,"['FN', 'LUs', 'WN']","['al', 'lexical units']","[[92, 94], [110, 113], [120, 122]]","[[38, 40], [95, 108]]",['lexical units'],"['FN', 'LUs', 'WN']","[[95, 108]]","['SSI', 'FN', 'LUs', 'WN']","[[59, 62], [92, 94], [110, 113], [120, 122]]"
165,165, 2.1 Multilingual Central Repository The Multilingual Central Repository (MCR)2 follows the model proposed by the EuroWordNet,166,[')'],"['Central Repository', 'Central Repository']","[[76, 77]]","[[17, 35], [17, 35]]","['Central Repository', 'Central Repository']",[')'],"[[18, 36], [18, 36]]",[],[]
166,166,POL (politics) Belgium elections 2003 16 15107 15.4 SPO (sports) Kim Clijsters 9 9713 11.1 HIS (history) History of Belgium 3 8396 17.9 BUS (business) Belgium Labour Federation 9 4440 11.0,167,"['POL', 'SPO', 'HIS', 'BUS']","['politics', 'sports', 'history', 'business']","[[0, 3], [52, 55], [91, 94], [136, 139]]","[[5, 13], [57, 63], [96, 103], [141, 149]]","['politics', 'sports', 'history', 'business']","['POL', 'SPO', 'HIS', 'BUS']","[[5, 13], [57, 63], [96, 103], [141, 149]]","['POL', 'SPO', 'HIS', 'BUS']","[[0, 3], [52, 55], [91, 94], [136, 139]]"
167,167,study (usually as an elective) or not at all. At the  City University of New York (CUNY)?s Graduate  Center (the primary Ph.,168,['CUNY'],"['or', 'City University of New York']","[[83, 87]]","[[31, 33], [54, 81]]",['City University of New York'],['CUNY'],"[[54, 81]]",[],[]
168,168,1992. Proceedings of the Fourth  Message Understanding Conference (MUC-$). Mor- ,169,['MUC-$'],['Message Understanding Conference'],"[[67, 72]]","[[33, 65]]",['Message Understanding Conference'],['MUC-$'],"[[33, 65]]",['MUC-$'],"[[67, 72]]"
169,169,lemma(L)? and ? nonlem(NL)? systems for ran-,170,['L'],"['lemma', 'nonlem']","[[6, 7]]","[[0, 5], [16, 22]]",['nonlem'],['L'],"[[16, 22]]",[],[]
170,170,to analyse the eects of applying pronominal anaphora resolution to Question Answering (QA) systems. ,171,['QA'],"['e', 'Question Answering']","[[88, 90]]","[[9, 10], [68, 86]]",['Question Answering'],['QA'],"[[68, 86]]",['QA'],"[[88, 90]]"
171,171," To evaluate feature effectiveness, we group the features into seven groups: textual features (TX), utterance features (UT), pointing gesture fea-",172,"['TX', 'UT']","['textual', 'utterance']","[[94, 96], [119, 121]]","[[76, 83], [99, 108]]","['textual', 'utterance']","['TX', 'UT']","[[77, 84], [100, 109]]","['TX', 'UT']","[[95, 97], [120, 122]]"
172,172,"number of bilingual term pairs)  We compare our model with IBM Model 2  (IBM-2), and IBM Model 4 (IBM-4) implemented by GIZA++ (Och et al, 2003).",173,['GIZA++'],"['IBM Model', 'IBM Model 4']","[[120, 126]]","[[59, 68], [85, 96]]",['IBM Model 4'],['GIZA++'],"[[85, 96]]","['IBM', 'IBM-2', 'IBM', 'IBM-4', 'GIZA++']","[[59, 62], [73, 78], [59, 62], [98, 103], [120, 126]]"
173,173,"predicted this outcome correctly in 70.37% of the cases (upper left cell). However,  IBL also predicted the outcome penultimate stress (PEN) in 25.26% of the words and  440 ",174,"['IBL', 'PEN']",['penultimate stress'],"[[85, 88], [136, 139]]","[[116, 134]]",['penultimate stress'],"['IBL', 'PEN']","[[116, 134]]","['IBL', 'PEN']","[[85, 88], [136, 139]]"
174,174,"It is not useful to exploit latent  semantic analysis directly on the user-topic matrix  UR = UQ * QR , where UR represents how many  times each user is diffused for existing topic R (R ",175,"['UR', 'UQ']","['to', 'user', 'R']","[[89, 91], [94, 96]]","[[17, 19], [70, 74], [90, 91]]",[],"['UR', 'UQ']",[],"['UR', 'UQ', 'QR', 'UR']","[[89, 91], [94, 96], [99, 101], [89, 91]]"
175,175, Thus the determination of lexical scopes of  Complex Predicates (CPs) from a long consecutive sequence is indeed a crucial task.,176,['CPs'],"['Complex Predicates', 'a', 'a']","[[65, 68]]","[[45, 63], [17, 18], [17, 18]]",['Complex Predicates'],['CPs'],"[[46, 64]]",['CPs'],"[[66, 69]]"
176,176,baseline adapted language model.  The Table 2 shows the word error rates (WERs) of experiments on the code switching lecture,177,['WERs'],['word error rates'],"[[74, 78]]","[[56, 72]]",['word error rates'],['WERs'],"[[56, 72]]",['WERs'],"[[74, 78]]"
177,177,This section describes the two evaluation methods we employed ? average precision (AP) and correlation coefficient (CC).,178,"['AP', 'CC']","['average precision', 'correlation coefficient']","[[83, 85], [116, 118]]","[[64, 81], [91, 114]]","['average precision', 'correlation coefficient']","['AP', 'CC']","[[64, 81], [91, 114]]","['AP', 'CC']","[[83, 85], [116, 118]]"
178,178,A block ?[] invokes both the inner and outer generations simultaneously in Bracket Model A (BM-A). ,179,[],"['A', 'Bracket Model A']",[],"[[0, 1], [75, 90]]",['Bracket Model A'],[''],"[[75, 90]]",['BM-A'],"[[92, 96]]"
179,179,"In a third stage, they are put in a Multilingual Polyphraz Memory (MPM). A ""polyphrase"" is a structure",180,[')'],"['a', 'in a', 'Polyphraz Memory', 'a']","[[70, 71]]","[[3, 4], [31, 35], [49, 65], [3, 4]]",['Polyphraz Memory'],[')'],"[[49, 65]]",['MPM'],"[[67, 70]]"
180,180,Semantic Information Retrieval (SIR) AQUA Sentiment Analysis in User Generated Discourse (SentAL) Internet der Dienste (THESEUS) ?,181,"['SIR', 'AQUA', 'SentAL', 'THESEUS']","['Semantic Information Retrieval', 'Sentiment Analysis in User Generated Discourse', 'Internet der Dienste']","[[32, 35], [37, 41], [90, 96], [120, 127]]","[[0, 30], [42, 88], [98, 118]]","['Semantic Information Retrieval', 'Sentiment Analysis in User Generated Discourse', 'Internet der Dienste']","['SIR', 'AQUA', 'SentAL', 'THESEUS']","[[0, 30], [42, 88], [98, 118]]","['SIR', 'AQUA', 'SentAL', 'THESEUS']","[[32, 35], [37, 41], [90, 96], [120, 127]]"
181,181,"6 Event Ordering TimeML defines three different types of links: subordinate (SLINK), temporal (TLINK), and aspectual (ALINK).",182,"['SLINK', 'TLINK', 'ALINK']","['temporal', 'aspectual']","[[77, 82], [95, 100], [118, 123]]","[[85, 93], [107, 116]]","['temporal', 'aspectual']","['SLINK', 'TLINK', 'ALINK']","[[85, 93], [107, 116]]","['SLINK', 'TLINK', 'ALINK']","[[77, 82], [95, 100], [118, 123]]"
182,182,"Lapata, 2006). All systems were controlled to produce similar compression ratios (CR) for fair comparison.",183,['CR'],['compression ratios'],"[[82, 84]]","[[62, 80]]",['compression ratios'],['CR'],"[[62, 80]]",['CR'],"[[82, 84]]"
183,183,idealistic) practice of balancing and purging quirks.  6.2 Lexicography and Exploratory Data Analysis (EDA)  Statistics can be used for many different purposes.,184,['EDA'],['Exploratory Data Analysis'],"[[103, 106]]","[[76, 101]]",['Exploratory Data Analysis'],['EDA'],"[[76, 101]]",['EDA'],"[[103, 106]]"
184,184,"4 Experimental Setup 4.1 Corpus and Experimental Expressions We use the British National Corpus (BNC),4 automatically parsed using the Collins parser (Collins,",185,['BNC'],"['Corpus', 'British National Corpus']","[[97, 100]]","[[25, 31], [72, 95]]",['British National Corpus'],['BNC'],"[[72, 95]]",[],[]
185,185,redefined  While politicians all over the world want to  make Information Society Technologies (IST)  available and accessible in the language and locale ,186,['IST'],['Information Society Technologies'],"[[96, 99]]","[[62, 94]]",['Information Society Technologies'],['IST'],"[[62, 94]]",['IST'],"[[96, 99]]"
186,186,"method to train large neural networks. We use mini-batch version RPROP (RMSPROP) (Hinton, 2012) to minimize the loss function.",187,[],['version RPROP'],[],"[[57, 70]]",['version RPROP'],[''],"[[57, 70]]","['RPROP', 'RMSPROP']","[[65, 70], [72, 79]]"
187,187,"words not found in the dictionary, a Markov grammar that  computes the optimal ordering of the possible classes of all  words and a Wild Card Parser (WPC), i.e., a deterministic parser  based on a Context Free Grammar.",188,['WPC'],"['a', 'a Wild Card Parser', 'a', 'a']","[[150, 153]]","[[30, 31], [130, 148], [30, 31], [30, 31]]",['Wild Card Parser'],['WPC'],"[[132, 148]]",['WPC'],"[[150, 153]]"
188,188," ? Conditional Random Fields (CRF) is the state  of art for named entity extraction, in the ",189,[')'],['Random Fields'],"[[32, 33]]","[[14, 27]]",['Random Fields'],[')'],"[[15, 28]]",['CRF'],"[[30, 33]]"
189,189,Our Chinese  word segmentation system is based on three models: (a) word boundary token (WBT) model and (b)  triple context matching model for unknown word ,190,[')'],"['word', 'a', 'boundary token', 'b']","[[66, 67]]","[[13, 17], [25, 26], [73, 87], [41, 42]]",['boundary token'],[')'],"[[73, 87]]",['WBT'],"[[89, 92]]"
190,190," With the availability of Chinese Gigaword Corpus (CGC) and Word Sketch Engine (WSE) Tools (Kilgarriff, 2004).",191,[')'],"['Gigaword Corpus', 'Sketch Engine']","[[53, 54]]","[[33, 48], [64, 77]]","['Gigaword Corpus', 'Sketch Engine']",[')'],"[[34, 49], [65, 78]]","['CGC', 'WSE']","[[51, 54], [80, 83]]"
191,191,"features are chosen due to their effectiveness and availability for on-line detection.  They are independent word probability (IWP), anti-word pair (AWP), word formation analogy Table 8",192,"['IWP', 'AWP']","['independent', 'word probability', 'anti-word pair', 'word']","[[127, 130], [149, 152]]","[[97, 108], [109, 125], [133, 147], [109, 113]]","['independent', 'word probability', 'anti-word pair']","['IWP', 'AWP']","[[97, 108], [109, 125], [133, 147]]","['IWP', 'AWP']","[[127, 130], [149, 152]]"
192,192,1 Introduction RWTH?s main approach to System Combination (SC) for Machine Translation (MT) is a refined version of the ROVER approach in Automatic,193,"['RWTH', 'SC', 'MT']","['s', 'System Combination', 'Machine Translation', 'a', 'in']","[[15, 19], [59, 61], [88, 90]]","[[20, 21], [39, 57], [67, 86], [23, 24], [24, 26]]","['System Combination', 'Machine Translation']","['RWTH', 'SC', 'MT']","[[39, 57], [67, 86]]","['SC', 'MT', 'ROVER']","[[59, 61], [88, 90], [120, 125]]"
193,193,"This is called empirical Bayesian estimation. Our approach differs from maximum a posteriori (MAP) estimation, since we re-estimate the parameters of",194,['MAP'],['maximum a posteriori'],"[[94, 97]]","[[72, 92]]",['maximum a posteriori'],['MAP'],"[[72, 92]]",['MAP'],"[[94, 97]]"
194,194,"1 Introduction Statistical machine translation (MT) uses large target language models (LMs) to improve the fluency of generated texts, and it is commonly",195,[')'],"['translation', 'models']","[[50, 51]]","[[35, 46], [79, 85]]","['translation', 'models']",[')'],"[[35, 46], [79, 85]]","['MT', 'LMs']","[[48, 50], [87, 90]]"
195,195,"Our approach to this problem is influenced by the named entity annotation in the Automatic Content Extraction (ACE) project (Consortium, 2002), in which ?",196,"['ACE', ')']","['to', 'Automatic Content Extraction']","[[111, 114], [114, 115]]","[[13, 15], [81, 109]]",['Automatic Content Extraction'],"['ACE', ')']","[[81, 109]]",['ACE'],"[[111, 114]]"
196,196," It is used for many natural language tasks, such as part of speech (POS) and named entity tagging (Toutanova and others, 2003; Carreras et al.,",197,[')'],['of speech'],"[[71, 72]]","[[57, 66]]",['speech'],[')'],"[[61, 67]]",['POS'],"[[69, 72]]"
197,197,"NC 91.0 99.1 89.5 92.1 99.7 90.7 Table 2: Attachment score for Java and the lexical feature set, where CO = convertible and NC = nonconvertible dependency trees.",198,"['NC', 'CO']","['convertible', 'nonconvertible dependency']","[[0, 2], [103, 105]]","[[108, 119], [129, 154]]",['nonconvertible dependency'],"['NC', 'CO']","[[129, 154]]","['NC', 'CO', 'NC']","[[0, 2], [103, 105], [0, 2]]"
198,198,"precisely the issue we address in this article. We concentrate on the task of automatically classifying NSUs, which we approach using machine learning (ML) techniques. Our aim",199,"['NSUs', 'ML']","['in', 'machine learning']","[[104, 108], [152, 154]]","[[31, 33], [134, 150]]",['machine learning'],"['NSUs', 'ML']","[[134, 150]]","['NSUs', 'ML']","[[104, 108], [152, 154]]"
199,199,ABSTRACT  French auxilliaries and clitics have been analysed  in the flame of U.C.G. (Unification Categorial Grammar). ,200,['U.C.G.'],['Unification Categorial Grammar'],"[[78, 84]]","[[86, 116]]",['Unification Categorial Grammar'],['U.C.G.'],"[[86, 116]]",[],[]
200,200, ? Word translation features (WT): ?,201,[')'],['translation'],"[[31, 32]]","[[7, 18]]",['translation'],[')'],"[[8, 19]]",['WT'],"[[30, 32]]"
201,201,"(e.g. adjective bivs?i, which means former in both languages), (b) the term partial false friends (PFF) describes pairs that are polysemous and",202,['PFF'],"['i', 'partial false friends']","[[99, 102]]","[[12, 13], [76, 97]]",['partial false friends'],['PFF'],"[[76, 97]]",['PFF'],"[[99, 102]]"
202,202,"2 VIP targeted technologies  Current products for VIP such as screen readers mainly depend on speech synthesis or Braille solutions, e.g. ChromeVox [3], Windows-Eyes [4], or JAWS (Job Access With Speech) [5]. Braille displays ",203,"['VIP', 'JAWS']",['Job Access With Speech'],"[[2, 5], [174, 178]]","[[180, 202]]",['Job Access With Speech'],"['VIP', 'JAWS']","[[180, 202]]","['VIP', 'VIP', 'JAWS']","[[2, 5], [2, 5], [174, 178]]"
203,203,Peter Robinson; Philip Tuddenham; 3 Visualisation Scalable Vector Graphics (SVG)1 is a language for describing two-dimensional graphics and graphical,204,['SVG'],"['Scalable Vector Graphics', 'a']","[[76, 79]]","[[50, 74], [30, 31]]",['Scalable Vector Graphics'],['SVG'],"[[50, 74]]",[],[]
204,204,"Subset of significant adjacency pairs CORRECTTASKACTION?CORRECTTASKACTION;??EXTRADOMAINS?EXTRADOMAINT;?GROUNDINGS?GROUNDINGT;?ASSESSINGQUESTIONT?POSITIVEFEEDBACKS;??ASSESSINGQUESTIONS?POSITIVEFEEDBACKT;?QUESTIONT?STATEMENTS;?ASSESSINGQUESTIONT?STATEMENTS;?EXTRADOMAINT?EXTRADOMAINS;?QUESTIONS?STATEMENTT;?NEGATIVEFEEDBACKS?GROUNDINGT;?INCOMPLETETASKACTION?INCOMPLETETASKACTION;?POSITIVEFEEDBACKS?GROUNDINGT;??BUGGYTASKACTION?BUGGYTASKACTION 4 Models We learned three types of models using cross-validation with systematic sampling of training and testing sets.  4.1 First-Order Markov Model The simplest model we discuss is the first-order Markov model (MM), or bigram model (Figure 2). A MM that generates observation (state) sequence o1o2?ot is defined in the following way.",205,"['MM', 'ot']","['Markov', 'model', 'Markov model', 'model']","[[654, 656], [741, 743]]","[[578, 584], [476, 481], [640, 652], [476, 481]]",['Markov model'],"['MM', 'ot']","[[578, 590]]","['MM', 'MM']","[[654, 656], [654, 656]]"
205,205,"We searched for four conditions: depression, bipolar disorder, post traumatic stress disorder (PTSD) and seasonal affective disorder (SAD).",206,"['PTSD', 'SAD']","['disorder', 'post traumatic stress disorder', 'affective disorder']","[[95, 99], [134, 137]]","[[53, 61], [63, 93], [114, 132]]","['post traumatic stress disorder', 'affective disorder']","['PTSD', 'SAD']","[[63, 93], [114, 132]]","['PTSD', 'SAD']","[[95, 99], [134, 137]]"
206,206," ? If the key and response do not match, the category is incorrect (INC) ; if interactively assigned, a tall y appears in both the INC and XIC (interactive incorrect) columns .",207,"['INC', 'XIC']","['incorrect', 'y', 'in', 'interactive incorrect']","[[67, 70], [138, 141]]","[[56, 65], [11, 12], [56, 58], [143, 164]]",['interactive incorrect'],"['INC', 'XIC']","[[144, 165]]","['INC', 'INC', 'XIC']","[[68, 71], [68, 71], [139, 142]]"
207,207,(ARG0) and ? Greenspan? as the object (ARG1) of the noun predicate ?,208,"['ARG0', 'ARG1']",[],"[[1, 5], [39, 43]]",[],[],"['ARG0', 'ARG1']",[],"['ARG0', 'ARG1']","[[1, 5], [39, 43]]"
208,208,(2014c): ? Italian - Romanian (IT-RO); ?,209,[],['Italian - Romanian'],[],"[[11, 29]]",['Italian - Romanian'],[''],"[[11, 29]]",['IT-RO'],"[[31, 36]]"
209,209,"1 Introduction Despite the advances in natural language processing (NLP), Word Sense Disambiguation (WSD) is still considered one of the most challenging prob-",210,[')'],"['in', 'language processing', 'Sense Disambiguation', 'is']","[[71, 72]]","[[36, 38], [47, 66], [79, 99], [86, 88]]","['language processing', 'Sense Disambiguation']",[')'],"[[47, 66], [79, 99]]","['NLP', 'WSD']","[[68, 71], [101, 104]]"
210,210, ? Unstressed (US) average: Each feature is normalized by its mean value in the un-,211,[')'],[],"[[16, 17]]",[],[],[')'],[],['US'],"[[15, 17]]"
211,211,"and a search procedure. For example, we can build a n-gram word language model (LM)?itself a large weighted FSA.",212,"['LM', 'FSA']","['a', 'a', 'language model', 'a']","[[80, 82], [108, 111]]","[[0, 1], [0, 1], [64, 78], [0, 1]]",['language model'],"['LM', 'FSA']","[[64, 78]]",['FSA'],"[[108, 111]]"
212,212,"The key reason to compute tsim under the equiprobability assumption is that we need not compute the MWBM, but may find just the maximum cardinality bipartite matching (MCBM), since all potential links have the same weight. An O(e",213,"['MWBM', 'MCBM']",['maximum cardinality bipartite matching'],"[[100, 104], [168, 172]]","[[128, 166]]",['maximum cardinality bipartite matching'],"['MWBM', 'MCBM']","[[128, 166]]","['MWBM', 'MCBM']","[[100, 104], [168, 172]]"
213,213,"10http://rapid-i.com/ classification problems, we were unable to achieve results with a Support Vector Machine (SVM) learner (libSVMLearner) using the Radial Base",214,['SVM'],"['to', 'a Support Vector Machine']","[[112, 115]]","[[62, 64], [86, 110]]",['Support Vector Machine'],['SVM'],"[[88, 110]]","['10http://rapid-i.com/', 'SVM', 'libSVMLearner']","[[0, 21], [112, 115], [126, 139]]"
214,214," First, the matching score of the matching two nodes, NMS (Node Match Score) is calculated with their node scores, NS1 and NS2,",215,['NMS'],['Node Match Score'],"[[53, 56]]","[[58, 74]]",['Node Match Score'],['NMS'],"[[59, 75]]","['NMS', 'NS1', 'NS2']","[[54, 57], [115, 118], [123, 126]]"
215,215,"2007. CRFsuite: A fast implementation of Conditional Random Fields (CRFs), http://www.chokkan.org/software/crfsuite/.",216,['CRFsuite'],['Conditional Random Fields'],"[[6, 14]]","[[41, 66]]",['Conditional Random Fields'],['CRFsuite'],"[[41, 66]]","['CRFsuite', 'CRFs']","[[6, 14], [6, 10]]"
216,216,"rithms can also be used in discriminative settings (Bellare et al, 2009; Ganchev et al, 2010) specifically for semi-supervised learning (SSL.) ",217,[],"['in', 'al', 'al', 'learning']",[],"[[24, 26], [11, 13], [11, 13], [127, 135]]",['learning'],[''],"[[127, 135]]",['SSL.'],"[[137, 141]]"
217,217,"It makes sense now that you explained it, but I never used an else if in any of my other programs .04 POSITIVE FEEDBACK (P) Second part complete. .11 QUESTION (Q) Why couldn?t I have said if (i<5) .11 STATEMENT (S) i is my only index .07  REQUEST FOR FEEDBACK (RF) So I need to create a new method that sees how many elements are in my array? .16 RESPONSE (RSP) You mean not the length but the contents .14 UNCERTAIN FEEDBACK WITH ELABORATION (UE) I?m trying to remember how to copy arrays .008 UNCERTAIN FEEDBACK (U) Not quite yet .008  3.2 Task action annotation The tutoring sessions were task-oriented, focusing on a computer programming exercise.",218,['UE'],"['I', 'POSITIVE', 'FEEDBACK', 'P', 'QUESTION', 'I', 'S', 'REQUEST FOR FEEDBACK', 'I', 'RESPONSE', 'UNCERTAIN FEEDBACK WITH ELABORATION', 'I', 'UNCERTAIN FEEDBACK', 'U', 'on']","[[151, 153]]","[[0, 1], [102, 110], [111, 119], [102, 103], [150, 158], [0, 1], [104, 105], [239, 259], [0, 1], [347, 355], [407, 442], [0, 1], [407, 425], [151, 152], [127, 129]]","['POSITIVE', 'QUESTION', 'REQUEST FOR FEEDBACK', 'RESPONSE', 'UNCERTAIN FEEDBACK WITH ELABORATION']",['UE'],"[[102, 110], [150, 158], [239, 259], [347, 355], [407, 442]]","['i<5', 'STATEMENT', 'REQUEST', 'RF', 'RESPONSE', 'RSP', 'UNCERTAIN', 'UE', 'UNCERTAIN']","[[192, 195], [201, 210], [239, 246], [261, 263], [347, 355], [357, 360], [407, 416], [151, 153], [407, 416]]"
218,218,"nodes in their MRs mij . Then, after setting the context ci as the MR of the root node (MR(T ) ? ci),",219,['MR'],['root node'],"[[15, 17]]","[[77, 86]]",['root node'],['MR'],"[[77, 86]]","['MRs', 'MR']","[[15, 18], [15, 17]]"
219,219,until the current sentence (PENT) and the word entropy for the conversation subsequent to the current sentence (SENT). We hypothesize that informative,220,"['PENT', 'SENT']","['until the current sentence', 'the', 'the', 'subsequent to the current sentence']","[[28, 32], [112, 116]]","[[0, 26], [6, 9], [6, 9], [76, 110]]","['until the current sentence', 'subsequent to the current sentence']","['PENT', 'SENT']","[[0, 26], [76, 110]]","['PENT', 'SENT']","[[28, 32], [112, 116]]"
220,220,"  1. PARADISEC (Pacific and Regional Archive for Digital Sources in Endangered Cultures): audio, video,  text and image resources for Australian and Pacific Island languages (Thieberger, Barwick, Billington, & ",221,['PARADISEC'],"['Pacific and Regional Archive for Digital Sources in Endangered Cultures', 'and', 'for', 'and Pacific']","[[3, 12]]","[[14, 85], [22, 25], [43, 46], [143, 154]]","['Pacific and Regional Archive for Digital Sources in Endangered Cultures', 'and Pacific']",['PARADISEC'],"[[16, 87], [145, 156]]",['PARADISEC'],"[[5, 14]]"
221,221,"c, include latent variable models that simultaneously capture the semantics of words and sentences, such as latent semantic analysis (LSA) or latent Dirichlet alocation (LDA).",222,"['LSA', 'LDA']","['c', 'latent', 'latent semantic analysis', 'latent Dirichlet alocation']","[[134, 137], [170, 173]]","[[0, 1], [11, 17], [108, 132], [142, 168]]","['latent semantic analysis', 'latent Dirichlet alocation']","['LSA', 'LDA']","[[108, 132], [142, 168]]","['LSA', 'LDA']","[[134, 137], [170, 173]]"
222,222, Abstract Minimum Error Rate Training (MERT) is a method for training the parameters of a log-,223,[')'],"['Error Rate Training (', 'a', 'a']","[[42, 43]]","[[17, 38], [5, 6], [5, 6]]",['Error Rate Training ('],[')'],"[[18, 39]]",['MERT'],"[[39, 43]]"
223,223,A phonetic system represents sound segments as 3Phonemic and phonetic representations are given in the International Phonetic Alphabet (IPA). ,224,[],"['A', 'International Phonetic Alphabet']",[],"[[0, 1], [103, 134]]",['International Phonetic Alphabet'],[''],"[[103, 134]]",['IPA'],"[[136, 139]]"
224,224,"word w is defined as the largest connected subgraph that contains w. For each content  9 Other thesauri have been used for WSD, e.g., the German Hallig-Wartburg (see Schmidt \[1988, 1991\])  and the Longman Lexicon of Contemporary English (LLOCE) (Chen and Chang, this volume). ",225,"['WSD', 'LLOCE']","['is', 'Longman Lexicon of Contemporary English']","[[123, 126], [240, 245]]","[[7, 9], [199, 238]]",['Longman Lexicon of Contemporary English'],"['WSD', 'LLOCE']","[[199, 238]]","['WSD', 'LLOCE']","[[123, 126], [240, 245]]"
225,225,"the Switchboard corpus.1 The standard measure of error used in ASR is word error rate (WER), computed as 100(I + D + S)/R, where I,D and S are the number of inser-",226,"['ASR', 'WER']","['error', 'word error rate']","[[63, 66], [87, 90]]","[[49, 54], [70, 85]]",['word error rate'],"['ASR', 'WER']","[[70, 85]]","['ASR', 'WER']","[[63, 66], [87, 90]]"
226,226,"verbs, adject ives,  and others. Then a  separate  Keyword In Context  (KWIC) Index  was made for each part of speech.",227,['KWIC'],['Keyword In Context'],"[[72, 76]]","[[51, 69]]",['Keyword In Context'],['KWIC'],"[[51, 69]]",['KWIC'],"[[72, 76]]"
227,227,company was interested in knowledge discovery  approaches applicable to the data aggregated by its  Emergency Control System (ECS) in the form of  field service tickets.,228,['ECS'],['Emergency Control System'],"[[126, 129]]","[[100, 124]]",['Emergency Control System'],['ECS'],"[[100, 124]]",['ECS'],"[[126, 129]]"
228,228,Italian - Romanian (IT-RO); ? Portuguese - Romanian (PT-RO); ?,229,[],"['Italian', '- Romanian', 'Portuguese - Romanian']",[],"[[0, 7], [8, 18], [30, 51]]","['Italian', 'Portuguese - Romanian']",[''],"[[0, 7], [30, 51]]","['IT-RO', 'PT-RO']","[[20, 25], [53, 58]]"
229,229,V (verb) 6946 81.9 85.8 PR (preposition) 5302 60.0 79.0 CONJ (conjunction) 2998 76.1 80.7 ADV (adverb) 2855 72.3 83.3,230,"['V', 'PR', 'CONJ']","['verb', 'preposition', 'conjunction', 'adverb']","[[0, 1], [24, 26], [56, 60]]","[[3, 7], [28, 39], [62, 73], [95, 101]]","['preposition', 'conjunction', 'adverb']","['V', 'PR', 'CONJ']","[[28, 39], [62, 73], [95, 101]]","['PR', 'CONJ', 'ADV']","[[24, 26], [56, 60], [90, 93]]"
230,230,"lexicalized Baselines. In Proceedings of the ACL Workshop on Parsing German (PaGe), pages 40?46, Columbus, OH, USA.",231,"['ACL', 'PaGe', 'OH', 'USA']",['Parsing German'],"[[45, 48], [77, 81], [107, 109], [111, 114]]","[[61, 75]]",['Parsing German'],"['ACL', 'PaGe', 'OH', 'USA']","[[61, 75]]","['ACL', 'PaGe', 'OH', 'USA']","[[45, 48], [77, 81], [107, 109], [111, 114]]"
231,231,"It consists mainly of four incremental (cas-  caded) processes that work on the blackboard-like  current conceptual structure (CCR). At first sight, ",232,['CCR'],['current conceptual structure'],"[[127, 130]]","[[97, 125]]",['current conceptual structure'],['CCR'],"[[97, 125]]",['CCR'],"[[127, 130]]"
232,232,"when reconcilable with Bias 1. Whenever the sentence or query has a verb phrase (VP) spanning roughly half of it, annotators seem to chunk be-",233,['VP'],['a verb phrase'],"[[81, 83]]","[[66, 79]]",['verb phrase'],['VP'],"[[68, 79]]",['VP'],"[[81, 83]]"
233,233,Abbreviations NE = Named Entity CE = Correlated Entity EP = Entity Profile,234,"['NE', 'CE', 'EP']","['Named', 'Entity', 'Correlated Entity']","[[14, 16], [32, 34], [55, 57]]","[[19, 24], [25, 31], [37, 54]]",['Correlated Entity'],"['NE', 'CE', 'EP']","[[37, 54]]","['NE', 'CE', 'EP']","[[14, 16], [32, 34], [55, 57]]"
234,234,which can handle the non-projective trees present in the Irish data. In each case we report Labelled Attachment Score (LAS) and Unlabelled Attachment Score (UAS). ,235,"['LAS', 'UAS']","['Labelled Attachment Score', 'Unlabelled Attachment Score']","[[119, 122], [157, 160]]","[[92, 117], [128, 155]]","['Labelled Attachment Score', 'Unlabelled Attachment Score']","['LAS', 'UAS']","[[92, 117], [128, 155]]","['LAS', 'UAS']","[[119, 122], [157, 160]]"
235,235,"Table 1: A classification of grammar rules for the HPB model. PR = phrasal rule, HR = hierarchical rule, GR = glue rule.",236,"['HPB', 'PR', 'HR', 'GR']","['phrasal', 'rule', 'hierarchical rule', 'glue rule']","[[51, 54], [62, 64], [81, 83], [105, 107]]","[[67, 74], [37, 41], [86, 103], [110, 119]]","['phrasal', 'hierarchical rule', 'glue rule']","['HPB', 'PR', 'HR', 'GR']","[[67, 74], [86, 103], [110, 119]]","['HPB', 'PR', 'HR', 'GR']","[[51, 54], [62, 64], [81, 83], [105, 107]]"
236,236,senses. Semantic role labeling is achieved using maximum entropy (MaxEnt) model based semantic role classification and integer linear,237,['MaxEnt'],['maximum entropy'],"[[66, 72]]","[[49, 64]]",['maximum entropy'],['MaxEnt'],"[[49, 64]]",['MaxEnt'],"[[66, 72]]"
237,237,FS = false start  E = echo  ADD = added information  SELF = talking to oneself ,238,"['FS', 'E', 'ADD']","['false start', 'echo', 'added information']","[[0, 2], [18, 19], [28, 31]]","[[5, 16], [22, 26], [34, 51]]","['false start', 'added information']","['FS', 'E', 'ADD']","[[5, 16], [34, 51]]","['FS', 'ADD', 'SELF']","[[0, 2], [28, 31], [53, 57]]"
238,238,tasks or languages.  Amazon?s Mechanical Turk (MTurk) service facilitates inexpensive collection of large amounts of,239,[],['Mechanical Turk'],[],"[[30, 45]]",['Mechanical Turk'],[''],"[[30, 45]]",['MTurk'],"[[47, 52]]"
239,239," iii. Simple_Rank (S-Rank): It is computed  based on Rank(i)=tfi*Len(i), which aims ",240,[')'],['Rank'],"[[24, 25]]","[[12, 16]]",[],[')'],[],['S-Rank'],"[[19, 25]]"
240,240,The MRF provides the base frame to  combine various statistical information  with maximum entropy (ME) method. ,241,"['MRF', 'ME']",['maximum entropy'],"[[4, 7], [99, 101]]","[[82, 97]]",['maximum entropy'],"['MRF', 'ME']","[[82, 97]]","['MRF', 'ME']","[[4, 7], [99, 101]]"
241,241,"annotation ? the Penn Chinese Treebank (CTB)(Xia et al, 2000), and the People?s Daily News (PDN) corpus from Beijing University.",242,"['CTB', 'PDN']","['?', 'Chinese Treebank', 'People ? s Daily News']","[[40, 43], [92, 95]]","[[11, 12], [22, 38], [-1, 20]]","['Chinese Treebank', 'People ? s Daily News']","['CTB', 'PDN']","[[22, 38]]",['PDN'],"[[92, 95]]"
242,242,"Sangkeun Jung, Cheongjae Lee, Kyungduk Kim, Gary Geunbae Lee Department of Computer Science and Engineering Pohang University of Computer Science and Technology(POSTECH) San 31, Hyoja-Dong, Pohang, 790-784, Korea",243,['POSTECH'],"['of Computer Science and', 'Pohang University of Computer Science and Technology', 'Pohang']","[[161, 168]]","[[72, 95], [108, 160], [108, 114]]",['Pohang University of Computer Science and Technology'],['POSTECH'],"[[108, 160]]",[],[]
243,243,6. A rule to convert the Hindi word into its  base form (BF). ,244,[')'],['form'],"[[59, 60]]","[[51, 55]]",[],[')'],[],['BF'],"[[57, 59]]"
244,244,for acquiring high quality non-expert knowledge from on-demand workforce using Amazon Mechanical Turk (MTurk). We show how ,245,[],['Mechanical Turk'],[],"[[86, 101]]",['Mechanical Turk'],[''],"[[86, 101]]",['MTurk'],"[[103, 108]]"
245,245,"integral to membrane  membrane  The protein encoded by this gene is a receptor for interleukin 20 (IL20), a cytokine that may be involved in epidermal function.",246,[],"['interleukin 20', 'in']",[],"[[83, 97], [0, 2]]",['interleukin 20'],[''],"[[83, 97]]",['IL20'],"[[99, 103]]"
246,246,We evaluate the lexicons proposed in Section 3 both intrinsically (by comparing their lexicon entries against General Inquirer (GI) lexicon) and extrinsically (by using them in a phrase polarity anno-,247,['GI'],"['General Inquirer', 'a']","[[128, 130]]","[[110, 126], [5, 6]]",['General Inquirer'],['GI'],"[[110, 126]]",['GI'],"[[128, 130]]"
247,247,out of this phrase. The word with the parent out of  the phrase is called Head of Phrase (HP). The ,248,['HP'],"['of', 'of', 'Head of Phrase']","[[90, 92]]","[[4, 6], [4, 6], [74, 88]]",['Head of Phrase'],['HP'],"[[74, 88]]",['HP'],"[[90, 92]]"
248,248," 1 Introduction Noun phrase (NP) coreference resolution, the task of determining which NPs in a text or dialogue re-",249,[')'],"['phrase', 'a']","[[30, 31]]","[[20, 26], [23, 24]]",['phrase'],[')'],"[[21, 27]]","['NP', 'NPs']","[[29, 31], [87, 90]]"
249,249,"Generation of Crisp Descriptions Arguably the most fundamental task in the generation of referring expressions (GRE), content determination (CD) requires finding a set of properties that jointly identify the intended referent.",250,"['GRE', 'CD']","['of', 'in', 'generation of referring expressions', 'content determination', 'a', 'of']","[[112, 115], [141, 143]]","[[11, 13], [68, 70], [75, 110], [118, 139], [5, 6], [11, 13]]","['generation of referring expressions', 'content determination']","['GRE', 'CD']","[[75, 110], [118, 139]]","['GRE', 'CD']","[[112, 115], [141, 143]]"
250,250,"entities presence feature (DIC), numerical entities presence feature (NUM), question specific feature (SPE), and dependency validity feature (DEP). ",251,"['DIC', 'NUM', 'SPE', 'DEP']","['entities presence feature', 'numerical entities presence feature', 'question specific feature', 'dependency validity feature']","[[27, 30], [70, 73], [103, 106], [142, 145]]","[[0, 25], [33, 68], [76, 101], [113, 140]]","['numerical entities presence feature', 'question specific feature', 'dependency validity feature']","['DIC', 'NUM', 'SPE', 'DEP']","[[33, 68], [76, 101], [113, 140]]","['DIC', 'NUM', 'SPE', 'DEP']","[[27, 30], [70, 73], [103, 106], [142, 145]]"
251,251,"3.1 Semantic Types In the present task, we use a subset of semantic types from the Brandeis Shallow Ontology (BSO), which is a shallow hierarchy of types developed as a part",252,['BSO'],"['a', 'Brandeis Shallow Ontology', 'is a', 'a']","[[110, 113]]","[[7, 8], [83, 108], [122, 126], [7, 8]]",['Brandeis Shallow Ontology'],['BSO'],"[[83, 108]]",['BSO'],"[[110, 113]]"
252,252,"applied to the sentiment analysis problem. Models such as Na??ve Bayes (NB), Maximum Entropy (ME) and Support Vector Machines (SVM) can determine",253,"['NB', 'ME', 'SVM']","['to', 'Na ? ? ve Bayes', 'Maximum Entropy', 'Support Vector Machines']","[[72, 74], [94, 96], [127, 130]]","[[8, 10], [-1, 14], [77, 92], [102, 125]]","['Na ? ? ve Bayes', 'Maximum Entropy', 'Support Vector Machines']","['NB', 'ME', 'SVM']","[[77, 92], [102, 125]]","['NB', 'ME', 'SVM']","[[72, 74], [94, 96], [127, 130]]"
253,253, Rank Group Lexical Features 1 HM HM1 (head of M1) HM2 (head of M2),254,"['1', 'HMHM1']","['head of', 'head of M2']","[[28, 29], [-1, 4]]","[[38, 45], [55, 65]]",['head of M2'],"['1', 'HMHM1']","[[56, 66]]","['HM', 'HM1', 'HM2']","[[31, 33], [34, 37], [51, 54]]"
254,254,"Cross-lingual textual entailment (CLTE) (Mehdad et al., 2010) is an extension of textual entailment (TE) (Dagan and Glickman, 2004).",255,"['CLTE', 'TE']","['textual entailment', 'textual entailment']","[[34, 38], [36, 38]]","[[14, 32], [14, 32]]","['textual entailment', 'textual entailment']","['CLTE', 'TE']","[[14, 32], [14, 32]]","['CLTE', 'TE']","[[34, 38], [36, 38]]"
255,255,1977).  The parameters of the IDCLM model are computed using the variational Bayes EM (VB-EM) procedure by maximizing the marginal distribution of the training data that contains a set of n-gram events,256,['IDCLM'],"['variational Bayes EM', 'a']","[[30, 35]]","[[65, 85], [13, 14]]",['variational Bayes EM'],['IDCLM'],"[[65, 85]]","['IDCLM', 'VB-EM']","[[30, 35], [87, 92]]"
256,256," 2 Related Work Reference resolution (RR), which is the task of resolving referring expressions (REs) to what they are",257,[')'],"['resolution', 'expressions']","[[39, 40]]","[[25, 35], [83, 94]]","['resolution', 'expressions']",[')'],"[[26, 36], [84, 95]]","['RR', 'REs']","[[38, 40], [97, 100]]"
257,257,"or fictional) world. These discourse ntities,  called reference objects (RefOs), are stored  and processed ina net-like structure, called a ",258,['RefOs'],['reference objects'],"[[73, 78]]","[[54, 71]]",['reference objects'],['RefOs'],"[[54, 71]]",['RefOs'],"[[73, 78]]"
258,258,then X Y =~ Z  then Y X ::~ Z  Permutation Closure of language L (PermL)  PermL = { s \[ s' in L and s is a per- ,259,[],"['Permutation Closure of language L', 's', 's', 'L', 's', 'a']",[],"[[31, 64], [46, 47], [46, 47], [63, 64], [46, 47], [37, 38]]",['Permutation Closure of language L'],[''],"[[31, 64]]","['PermL', 'PermL']","[[66, 71], [66, 71]]"
259,259," I. Introduction  SABA (""Semantic Analyser , Backward Ap-  proach"") is an automatic parser of French ",260,[],"['Analyser ,', 'an']",[],"[[33, 43], [27, 29]]",['Analyse'],[''],"[[34, 41]]",['SABA'],"[[18, 22]]"
260,260,"Proceedings of  the First International Symposium on Compurers and Chinese  Inpuf/Output Systems, Acadernig Sinico, 983-998  in the FCL (FACOM Composition Language) System, information is punched on paper tape  with a Kanji keyboard.",261,['FCL'],"['on', 'FACOM Composition Language', 'on', 'a']","[[132, 135]]","[[35, 37], [137, 163], [35, 37], [32, 33]]",['FACOM Composition Language'],['FCL'],"[[137, 163]]",['FCL'],"[[132, 135]]"
261,261,"In order to answer this question, we propose a new model called the Recursive Neural Tensor Network (RNTN). The main idea is to use",262,[')'],"['a', 'Neural Tensor Network']","[[105, 106]]","[[12, 13], [78, 99]]",['Neural Tensor Network'],[')'],"[[78, 99]]",['RNTN'],"[[101, 105]]"
262,262,"In Proceedings of the 19th International Conference on Computational Linguistics (COLING), volume I, pages 267?273.",263,[')'],"['on', 'Linguistics']","[[88, 89]]","[[36, 38], [69, 80]]",['Linguistics'],[')'],"[[69, 80]]",['COLING'],"[[82, 88]]"
263,263,tating full-text passages that describe the functional relationships between bio-entities summarised in a Molecular Interaction Map (MIM). Our corpus,264,['MIM'],['a Molecular Interaction Map'],"[[133, 136]]","[[104, 131]]",['Molecular Interaction Map'],['MIM'],"[[106, 131]]",['MIM'],"[[133, 136]]"
264,264,"Abstract A number of issues arise when trying to scaleup natural language understanding (NLU) tools designed for relatively simple domains (e.g.,",265,['NLU'],['natural language understanding'],"[[89, 92]]","[[57, 87]]",['natural language understanding'],['NLU'],"[[57, 87]]",['NLU'],"[[89, 92]]"
265,265,"distance (EDIT), which is the Levenshtein distance between generated word string and human reference output, and string accuracy (S-A), which is the proportion of times the word string was identical to the",266,"['EDIT', 'S-A']","['distance', 'is', 'string', 'string accuracy', 'is', 'string']","[[10, 14], [130, 133]]","[[0, 8], [1, 3], [74, 80], [113, 128], [1, 3], [74, 80]]","['distance', 'string accuracy']","['EDIT', 'S-A']","[[0, 8], [113, 128]]","['EDIT', 'S-A']","[[10, 14], [130, 133]]"
266,266,"The second column represents three SMT systems, namely: the baseline system adapted to the domain (DA), the same system with a CSLM (DA+CSLM) and the project adapted sys-",267,"['SMT', 'DA', 'CSLM']","['domain', 'a']","[[35, 38], [99, 101], [127, 131]]","[[91, 97], [49, 50]]",['domain'],"['SMT', 'DA', 'CSLM']","[[91, 97]]","['SMT', 'DA', 'CSLM']","[[35, 38], [99, 101], [127, 131]]"
267,267,"(i)(a) If the verb is the last word  of the surface shape of the  sentence (SS), it always be-  longs to the focus.",268,['SS'],"['i', 'sentence']","[[76, 78]]","[[1, 2], [66, 74]]",['sentence'],['SS'],"[[66, 74]]",['SS'],"[[76, 78]]"
268,268," In Expertise column, C=Computer Scientist, BI=Bioinformatician, B=Biologist, L=Linguist ?",269,[],['Scientist'],[],"[[32, 41]]",['Scientist'],[''],"[[33, 42]]",['BI'],"[[44, 46]]"
269,269,"As is common practice for continuous features, we choose this pdf to be a Gaussian mixture model (GMM) since any continuous distribution can be approximated with ar-",270,"['pdf', 'GMM']",['a Gaussian mixture model'],"[[62, 65], [98, 101]]","[[72, 96]]",['Gaussian mixture model'],"['pdf', 'GMM']","[[74, 96]]",['GMM'],"[[98, 101]]"
270,270,"So, for example, the preposition in addition to (krom?) appears altogether in 309 instances in PDT,  within which there are 44 instances in the function of AltLex (automatically looked up). All ",271,"['PDT', 'AltLex']","['automatically', 'up']","[[95, 98], [156, 162]]","[[164, 177], [185, 187]]",['automatically'],"['PDT', 'AltLex']","[[164, 177]]","['PDT', 'AltLex']","[[95, 98], [156, 162]]"
271,271," Finally, we propose using the beam-search decoder to combine multiple discriminative models such as M3N and multiple generative models such as language models (LM) and perform multiple passes of disfluency detection.",272,"['M3N', 'LM']","['models', 'models', 'language models']","[[100, 103], [160, 162]]","[[85, 91], [85, 91], [143, 158]]",['language models'],"['M3N', 'LM']","[[144, 159]]","['M3N', 'LM']","[[101, 104], [161, 163]]"
272,272,"The first system, as its name suggests, is very  simple: using the WSD model, it chooses the  most frequent sense (MFS) of the lemma l with  POS p according to WN (that is, the lowest num-",273,['MFS'],['most frequent sense'],"[[115, 118]]","[[94, 113]]",['most frequent sense'],['MFS'],"[[94, 113]]","['WSD', 'MFS', 'POS', 'WN']","[[67, 70], [115, 118], [141, 144], [160, 162]]"
273,273, 1 Introduction Margin infused relaxed algorithm (MIRA) has been widely adopted for the parameter optimization in,274,[')'],['infused relaxed algorithm'],"[[53, 54]]","[[22, 47]]",['infused relaxed algorithm'],[')'],"[[23, 48]]",['MIRA'],"[[50, 54]]"
274,274," Our approach differs in important ways from the  use of hidden Markov models (HMMs) for class-  based language modeling (Jelinek et al, 1992).",275,[')'],['Markov models'],"[[82, 83]]","[[63, 76]]",['Markov models'],[')'],"[[64, 77]]",['HMMs'],"[[79, 83]]"
275,275,the semantics of the head noun of the reference  object. A noun phrase (NP) denoting a place  gives rise to a spatial PP.,276,"['NP', 'PP']","['noun', 'noun phrase', 'a', 'a']","[[72, 74], [118, 120]]","[[26, 30], [59, 70], [7, 8], [7, 8]]",['noun phrase'],"['NP', 'PP']","[[59, 70]]","['NP', 'PP']","[[72, 74], [118, 120]]"
276,276,contact(CeNT) motion(MOT)  emoeion(ENO) perception(PER)  possession(POSS) stat ive(STA)  ~eather(WEA) ingestion(ING) ,277,"['CeNT', 'MOT', 'ENO', 'PER', 'POSS', 'STA', 'WEA', 'ING']","['motion', 'emoeion', 'perception', 'possession', 'stat ive', 'ingestion']","[[8, 12], [21, 24], [35, 38], [51, 54], [68, 72], [83, 86], [97, 100], [112, 115]]","[[14, 20], [27, 34], [40, 50], [57, 67], [74, 82], [102, 111]]","['motion', 'emoeion', 'perception', 'possession', 'stat ive', 'ingestion']","['CeNT', 'MOT', 'ENO', 'PER', 'POSS', 'STA', 'WEA', 'ING']","[[14, 20], [27, 34], [40, 50], [57, 67], [74, 82], [102, 111]]",[],[]
277,277,"tropy modeling. Berger et al (1996) presents an incremental feature selection (IFS) algorithm, which computes the approximate gains",278,['IFS'],"['al', 'incremental feature selection']","[[79, 82]]","[[26, 28], [48, 77]]",['incremental feature selection'],['IFS'],"[[48, 77]]",['IFS'],"[[79, 82]]"
278,278,"pre-processed ATB (Table 10). Consequently, this particular Arabic MWE identification experiment is similar to joint parsing and named entity recognition (NER) (Finkel and Manning 2009).",279,"['ATB', 'MWE', 'NER']",['named entity recognition'],"[[14, 17], [67, 70], [155, 158]]","[[129, 153]]",['named entity recognition'],"['ATB', 'MWE', 'NER']","[[129, 153]]","['ATB', 'MWE', 'NER']","[[14, 17], [67, 70], [155, 158]]"
279,279,"ficient. The remainder of the data can be partially addressed with noun phrase (NP) detectors (Abney, 1991; Ramshaw and Marcus, 1995; Mu?noz et",280,['NP'],['noun phrase'],"[[80, 82]]","[[67, 78]]",['noun phrase'],['NP'],"[[67, 78]]",['NP'],"[[80, 82]]"
280,280,"Frame abbreviations:  INAN=inanimate NP, ANIM=animate NP, VBZ--inflected  main verb, IS=is, VBG=gerund, PP=prepositional phrase,  TO=to (prep.),",281,"['NP', 'VBZ']","['inflected main verb', 'phrase', 'prep']","[[37, 39], [58, 61]]","[[-1, 18], [121, 127], [107, 111]]","['inflected main verb', 'phrase']","['NP', 'VBZ']","[[121, 127]]","['INAN', 'NP', 'ANIM', 'NP', 'VBZ', 'IS', 'VBG', 'PP', 'TO']","[[22, 26], [37, 39], [41, 45], [37, 39], [58, 61], [85, 87], [92, 95], [104, 106], [130, 132]]"
281,281,2 where AF = adjusted frequency di = relative size of category i,282,[],['frequency'],[],"[[22, 31]]",['frequency'],[''],"[[22, 31]]",['AF'],"[[8, 10]]"
282,282,respective polarities. This new value will be called  Positive Association (PosA). The PosA value is ,283,['PosA'],['Positive Association'],"[[76, 80]]","[[54, 74]]",['Positive Association'],['PosA'],"[[54, 74]]",['PosA'],"[[76, 80]]"
283,283,"production strategies. In Proceedings of the 16th International Conference on Computational Linguistics (COLING?96), pages 249?254.",284,['COLING?96'],['Conference on Computational Linguistics'],"[[105, 114]]","[[64, 103]]",['Conference on Computational Linguistics'],['COLING?96'],"[[64, 103]]",['COLING?96'],"[[105, 114]]"
284,284,"paring to BL system (N.S.), the average number of alternative translations of each source phrase (T/S) and the average source phrase length in the output (A.L.) -1.80 on average TER.",285,"['BL', '.', 'T/S']","['alternative translations', 'length', 'on']","[[10, 12], [22, 23], [98, 101]]","[[50, 74], [133, 139], [71, 73]]","['alternative translations', 'length']","['BL', '.', 'T/S']","[[50, 74], [133, 139]]","['BL', 'N.S.', 'T/S', 'A.L.', 'TER']","[[10, 12], [21, 25], [98, 101], [155, 159], [178, 181]]"
285,285,"and Johnson, 2011), particularly from the DARPA EARS (Effective, Affordable, Reusable Speech-toText) MDE (MetaData Extraction) (DARPA Information Processing Technology Office, 2003) pro-",286,"['DARPA', 'EARS', 'MDE']",['MetaData Extraction'],"[[42, 47], [48, 52], [101, 104]]","[[106, 125]]",['MetaData Extraction'],"['DARPA', 'EARS', 'MDE']","[[106, 125]]","['DARPA', 'EARS', 'MDE']","[[42, 47], [48, 52], [101, 104]]"
286,286,"lion words. From TIPSTER,  we used the Associ-  ated Press (AP), Wall Street Journal (WSJ), and  San Jose Mercury News (SJM) data, yielding 123, ",287,"['AP', 'WSJ', 'SJM']","['Associ- ated Press', 'Wall Street Journal', 'San Jose Mercury News']","[[60, 62], [86, 89], [120, 123]]","[[-1, 17], [65, 84], [97, 118]]","['Associ- ated Press', 'Wall Street Journal', 'San Jose Mercury News']","['AP', 'WSJ', 'SJM']","[[65, 84], [97, 118]]","['TIPSTER', 'AP', 'WSJ', 'SJM']","[[17, 24], [60, 62], [86, 89], [120, 123]]"
287,287,"Chinese sentence into a sequence of words. This is  the task of Chinese word segmentation (CWS), an  important and challenging task in Chinese NLP.",288,"['CWS', 'NLP']","['Chinese', 'a', 'Chinese word segmentation', 'in Chinese']","[[91, 94], [143, 146]]","[[0, 7], [22, 23], [64, 89], [132, 142]]","['Chinese word segmentation', 'in Chinese']","['CWS', 'NLP']","[[64, 89], [132, 142]]","['CWS', 'NLP']","[[91, 94], [143, 146]]"
288,288,Video in sentences out.  In Association for Uncertainty in Artificial Intelligence (UAI). ,289,['UAI'],"['in', 'In', 'Uncertainty in Artificial Intelligence']","[[84, 87]]","[[6, 8], [25, 27], [44, 82]]",['Uncertainty in Artificial Intelligence'],['UAI'],"[[44, 82]]",['UAI'],"[[84, 87]]"
289,289,BOEING CO(BA) OTC  UTL USA  UTL CORP(UTLC)  BOEING'S ARGOSYSTEMS SUBSIDIARY TO MAKE TENDER OFFER FOR ALL UTL CORE SHARES ,290,['OTC'],"['BOEING', 'CO', 'UTL', 'UTL CORP', 'BOEING', 'UTL']","[[14, 17]]","[[0, 6], [7, 9], [19, 22], [28, 36], [0, 6], [19, 22]]","['BOEING', 'UTL CORP', 'BOEING']",['OTC'],"[[0, 6], [28, 36], [0, 6]]","['BOEING CO(BA', 'OTC', 'UTL', 'USA', 'UTL']","[[0, 12], [14, 17], [19, 22], [23, 26], [19, 22]]"
290,290, For comparison we re-implemented the probabilistic Visual Objects Algorithm (VOA) of Mitchell et al(2013).,291,['VOA'],"['Visual Objects Algorithm', 'al']","[[77, 80]]","[[51, 75], [55, 57]]",['Visual Objects Algorithm'],['VOA'],"[[52, 76]]",['VOA'],"[[78, 81]]"
291,291," 2 Platform Architecture  The Application Generation Platform (AGP), created during the European project GEMINI, is an ",292,"[')', ',']","['Platform', 'Generation Platform']","[[65, 66], [66, 67]]","[[2, 10], [41, 60]]",['Generation Platform'],"[')', '', '']","[[42, 61]]","['AGP', 'GEMINI']","[[63, 66], [105, 111]]"
292,292,"The query-based selection model utilizes Support Vector Regression (SVR) models to predict the mean average precision (MAP) of each query from the ambiguity measures, and to choose an ap-",293,"['SVR', 'MAP']","['Support Vector Regression', 'to', 'mean average precision', 'to', 'an']","[[68, 71], [119, 122]]","[[41, 66], [52, 54], [95, 117], [52, 54], [97, 99]]","['Support Vector Regression', 'mean average precision']","['SVR', 'MAP']","[[41, 66], [95, 117]]","['SVR', 'MAP']","[[68, 71], [119, 122]]"
293,293,will describe our method of automatically creating a training set based on the click-through links and how we build an SVM (Support Vector Machine) classifier with the integration of enriched informa-,294,['SVM'],"['a', 'Support Vector Machine']","[[119, 122]]","[[28, 29], [124, 146]]",['Support Vector Machine'],['SVM'],"[[124, 146]]",['SVM'],"[[119, 122]]"
294,294,"Mophological processing, syntactic parsing and  other useflfl tools have been proposed in the field  of natural language processing(NLP). Many ",295,['NLP'],"['processing', 'in', 'natural language processing']","[[132, 135]]","[[13, 23], [20, 22], [104, 131]]",['natural language processing'],['NLP'],"[[104, 131]]",[],[]
295,295,"Computational Linguistics Volume 23, Number 2  1993c). FUF (Functional Unification Formalism) is a programming language based on  functional unification (Kay 1979).",296,['FUF'],"['Functional Unification Formalism', 'a', 'on']","[[55, 58]]","[[60, 92], [6, 7], [9, 11]]",['Functional Unification Formalism'],['FUF'],"[[60, 92]]",['FUF'],"[[55, 58]]"
296,296,"translation with overall understanding?.  Rhetorical structure theory (RST) (Mann and  Thompson, 1988) provides us with a good per-",297,['RST'],"['Rhetorical structure theory', 'a']","[[71, 74]]","[[42, 69], [2, 3]]",['Rhetorical structure theory'],['RST'],"[[42, 69]]",['RST'],"[[71, 74]]"
297,297,Sentences from TST2-MUC4-0048 Sl : SALVADORAN PRESIDENT-ELECT ALFREDO CRISTIAII CONDEMNED THE TERRORIST KILLING OF ATTORNE Y GENERAL ROBERTO GARCIA ALVARADO AND ACCUSED THE FARABUNDO MARTI NATIONAL LIBERATION FRONT (FMLN ) OF THE CRIME .,298,['FMLN'],[],"[[216, 220]]",[],[],['FMLN'],[],"['TST2', 'FMLN']","[[15, 19], [216, 220]]"
298,298,"Finally, the intention  translates into a call to UC's expression mechanism,  UCExpress (UCexpressl in the trace), which eventu-  ally calls UCGen to produce the answer.",299,[],['UC'],[],"[[50, 52]]",[],[''],[],"[""UC's"", 'UCExpress', 'UCGen']","[[50, 54], [78, 87], [141, 146]]"
299,299,"For 1http://maltparser.org/ English?Chinese (EN?ZH) word alignment, we observe that 75.62% of the consecutive Chinese",300,[],"['? Chinese', '?']",[],"[[-1, 8], [35, 36]]",['? Chinese'],[''],[],['EN?ZH'],"[[45, 50]]"
300,300,"28  Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 39?47, October 25, 2014, Doha, Qatar.",301,['ANLP'],['Arabic Natural Langauge Processing'],"[[82, 86]]","[[46, 80]]",['Arabic Natural Langauge Processing'],['ANLP'],"[[46, 80]]",['ANLP'],"[[82, 86]]"
301,301,and  Communications Industry Association (CCIA) filed differing recommendations  with the OMB on Federal automatic data processing (ADP) procurement. CBEW ,302,"['CCIA', 'OMB', 'ADP']","['and Communications Industry Association', 'on', 'automatic data processing']","[[42, 46], [90, 93], [132, 135]]","[[-1, 38], [16, 18], [105, 130]]","['and Communications Industry Association', 'automatic data processing']","['CCIA', 'OMB', 'ADP']","[[105, 130]]","['CCIA', 'OMB', 'ADP', 'CBEW']","[[42, 46], [90, 93], [132, 135], [150, 154]]"
302,302,"for many NLP applications including machine translation. In fact, Google Translate (GT)3 translates Examples (1) and (3) as ?",303,"['NLP', 'GT']",['Google Translate'],"[[9, 12], [84, 86]]","[[66, 82]]",['Google Translate'],"['NLP', 'GT']","[[66, 82]]",['NLP'],"[[9, 12]]"
303,303,Economics neighborhood f bank  bank  Subject Code EC = Economics  have it person out ,304,['EC'],"['Economics', 'Economics']","[[50, 52]]","[[0, 9], [0, 9]]","['Economics', 'Economics']",['EC'],"[[0, 9], [0, 9]]",['EC'],"[[50, 52]]"
304,304," The meaning of complex phrases is represented as  a composed LCS (CLCS). This is constructed ""com- ",305,[],"['LCS', ')']",[],"[[61, 64], [70, 71]]",[],[''],[],"['LCS', 'CLCS']","[[62, 65], [67, 71]]"
305,305,which has been developed within the projects K1T-NASEV and its  successor KIT-FAST 2 will be described (for details see \[Hanen-  1 LP = Linear Precedence; FCR = Feature Co-oecmenee R striction  KIT-FAST (FAST = Functor-Argument Structure for Translation; KIT = ,306,"['K1T-NASEV', 'KIT-FAST', 'LP', 'FCR']","['for', 'Linear Precedence', 'Feature Co-oecmenee R', 'Functor-Argument Structure for Translation']","[[45, 54], [74, 82], [132, 134], [156, 159]]","[[104, 107], [137, 154], [162, 183], [212, 254]]","['Linear Precedence', 'Feature Co-oecmenee R', 'Functor-Argument Structure for Translation']","['K1T-NASEV', 'KIT-FAST', 'LP', 'FCR']","[[137, 154], [162, 183], [212, 254]]","['K1T-NASEV', 'KIT-FAST', 'LP', 'FCR', 'KIT-FAST', 'FAST', 'KIT']","[[45, 54], [74, 82], [132, 134], [156, 159], [74, 82], [78, 82], [74, 77]]"
306,306, 2 Universal Networking Language Universal Networking Language (UNL) is an interlingua that represents a sentence in a language inde-,307,[')'],"['Networking Language', 'Networking Language', 'an', 'a', 'in a']","[[66, 67]]","[[12, 31], [12, 31], [24, 26], [9, 10], [113, 117]]","['Networking Language', 'Networking Language']",[')'],"[[13, 32], [13, 32]]",['UNL'],"[[64, 67]]"
307,307," Ckakraborty, Tanmoy, 2010, Identification of NounNoun (N-N) Collocations as Multi-Word Expressions  in Bengali Corpus.",308,['N-N'],['NounNoun'],"[[55, 58]]","[[45, 53]]",['NounNoun'],['N-N'],"[[46, 54]]",['N-N'],"[[56, 59]]"
308,308,"4.2 Dataset and preprocessing To evaluate the proposed approach, we use SemEval-2013 datasets: TW (tweets obtained by merging learn and development data) and SMS, in",309,"['TW', 'SMS']",['tweets'],"[[95, 97], [158, 161]]","[[99, 105]]",['tweets'],"['TW', 'SMS']","[[99, 105]]","['SemEval-2013', 'TW', 'SMS']","[[72, 84], [95, 97], [158, 161]]"
309,309," The experiments were performed using the  Wall Street Journal (WSJ) corpus of the Uni-  versity of Pennsylvania (Marcus et al, 1993) ",310,[')'],"['Street Journal', 'et al']","[[66, 67]]","[[47, 61], [120, 125]]",['Street Journal'],[')'],"[[48, 62]]",['WSJ'],"[[64, 67]]"
310,310,INIT MED FIN TOTAL 201 (87.8%) 13 (5.7%) 15 (6.5%) 229 Table 1: Distribution of the Position (POS) of Discourse Adverbials,311,['POS'],['Position'],"[[94, 97]]","[[84, 92]]",['Position'],['POS'],"[[84, 92]]",['POS'],"[[94, 97]]"
311,311,rada@cs.unt.edu Abstract Amazon Mechanical Turk (MTurk) is a marketplace for so-called ?,312,[],"['Mechanical Turk', 'a']",[],"[[32, 47], [1, 2]]",['Mechanical Turk'],[''],"[[32, 47]]",['MTurk'],"[[49, 54]]"
312,312,tions and so on.  3.2 The Greedy Prepend Algorithm (GPA) To learn a decision list from a given set of training,313,['GPA'],"['Greedy Prepend Algorithm', 'a', 'a']","[[52, 55]]","[[26, 50], [6, 7], [6, 7]]",['Greedy Prepend Algorithm'],['GPA'],"[[26, 50]]",['GPA'],"[[52, 55]]"
313,313,"legislatures, councils, ""other government bodies , I 1  and the private sector  should withhold action implementing major proposals for EFTS until the  National Commission on Electronic Fund transfers (NCEFT) has completed its  studies.",314,"['EFTS', 'NCEFT']",['National Commission on Electronic Fund transfers'],"[[136, 140], [202, 207]]","[[152, 200]]",['National Commission on Electronic Fund transfers'],"['EFTS', 'NCEFT']","[[152, 200]]","['EFTS', 'NCEFT']","[[136, 140], [202, 207]]"
314,314, 2. Na?ve Bayesian approach with full vocabulary (NBF). It,315,[')'],['? ve Bayesian'],"[[52, 53]]","[[-1, 12]]",['? ve Bayesian'],[')'],[],['NBF'],"[[50, 53]]"
315,315,"correction. ? P3E3N4S2, F W I Controlled Automotive Service Language (CASL) (Means and Godden 1996; Means, Chapman, and Liu 2000) is a controlled language for writing service manuals and bul-",316,"['P3E3N4S2', 'CASL']","['Controlled Automotive Service Language', 'a']","[[14, 22], [70, 74]]","[[30, 68], [61, 62]]",['Controlled Automotive Service Language'],"['P3E3N4S2', 'CASL']","[[30, 68]]","['P3E3N4S2', 'CASL']","[[14, 22], [70, 74]]"
316,316,"extend Eigenwords, spectral monolingual word embeddings based on canonical correlation analysis (CCA), to crosslingual settings with sentence-alignment.",317,['CCA'],['on canonical correlation analysis'],"[[97, 100]]","[[62, 95]]",['on canonical correlation analysis'],['CCA'],"[[62, 95]]",['CCA'],"[[97, 100]]"
317,317,The initial translation outputs from Google Translate (GT) and the results of the targeted paraphrasing translation process (TP) were evaluated according to widely used critera of fluency and adequacy.,318,"['GT', 'TP']","['translation', 'Google Translate', 'translation process']","[[55, 57], [125, 127]]","[[12, 23], [37, 53], [104, 123]]","['Google Translate', 'translation process']","['GT', 'TP']","[[37, 53], [104, 123]]","['GT', 'TP']","[[55, 57], [125, 127]]"
318,318,"simultaneous (SML) with another proposition: ""Fred washed the car  while John chased Mary"", Figure 50 A sequenttal rn iering of proposi-  t ions is also found, characterized by a sequence (SEQ) relation. The ",319,"['SML', 'SEQ']",['sequence'],"[[14, 17], [189, 192]]","[[179, 187]]",['sequence'],"['SML', 'SEQ']","[[179, 187]]","['SML', 'SEQ']","[[14, 17], [189, 192]]"
319,319,wards Task 2.  4.1 Wikipedia system (WIKI) In the WIKI data a sentence is marked as uncertain,320,['WIKI'],"['Wikipedia', 'a']","[[37, 41]]","[[19, 28], [1, 2]]",['Wikipedia'],['WIKI'],"[[19, 28]]","['WIKI', 'WIKI']","[[37, 41], [37, 41]]"
320,320," 4. Coreference (COR) As mentioned in our discussion of transitional phrases, a strong argument",321,[')'],[],"[[19, 20]]",[],[],[')'],[],['COR'],"[[17, 20]]"
321,321,"Bayesian Networks (Samuelsson, 1993), Neural  Networks (Marques and Lopes, 1996) and  Conditional Random Fields (CRF) (Lafferty et  al.,",322,['CRF'],"['and', 'and Conditional Random Fields']","[[113, 116]]","[[64, 67], [-1, 28]]",['and Conditional Random Fields'],['CRF'],[],['CRF'],"[[113, 116]]"
322,322,Evaluation Metrics: We evaluate the performance of question retrieval using the following metrics: Mean Average Precision (MAP) and Precision@N (P@N).,323,['MAP'],"['Mean Average Precision', 'Precision @ N', 'P @ N']","[[123, 126]]","[[99, 121], [-1, 12], [-1, 4]]","['Mean Average Precision', 'Precision @ N']",['MAP'],"[[99, 121]]","['MAP', 'P@N']","[[123, 126], [145, 148]]"
323,323,quen cies Figure 6: Distribution of Ratio of Frequencies(RF) values over the nouns in the corpus,324,['RF'],"['cies', 'of Ratio of Frequencies']","[[57, 59]]","[[5, 9], [33, 56]]",['Ratio of Frequencies'],['RF'],"[[36, 56]]",[],[]
324,324,"system utterances with respect o dialog context.  Utterances can be either appropriate (AP), inappro-  priate (IP), or ambiguous (AM).",325,"['AP', 'IP', 'AM']","['appropriate', 'inappro- priate', 'ambiguous']","[[88, 90], [111, 113], [130, 132]]","[[75, 86], [-1, 14], [119, 128]]","['appropriate', 'inappro- priate', 'ambiguous']","['AP', 'IP', 'AM']","[[75, 86], [119, 128]]","['AP', 'IP', 'AM']","[[88, 90], [111, 113], [130, 132]]"
325,325, 2.2 Tree substitution grammars Tree substitution grammars (TSGs) allow for complementary analysis.,326,[')'],"['substitution grammars', 'substitution grammars']","[[63, 64]]","[[9, 30], [9, 30]]","['substitution grammars', 'substitution grammars']",[')'],"[[10, 31], [10, 31]]",['TSGs'],"[[60, 64]]"
326,326, 2 Background and Related Work Amazon?s Mechanical Turk (MTurk) is an online marketplace for work that gives employers,327,[],"['Turk', 'an']",[],"[[50, 54], [13, 15]]",[],[''],[],['MTurk'],"[[57, 62]]"
327,327,"the points plus 10% of the surrounding area. For this, The Generic Map Tools (GMT)10 were used, in this case via HTTP.11",328,['GMT'],['Generic Map Tools'],"[[78, 81]]","[[59, 76]]",['Generic Map Tools'],['GMT'],"[[59, 76]]",[],[]
328,328,entry description to a lexeme. A part-of-speech of the lexeme is set to a common noun (NN ) where the minimum word probability of NN is assigned,329,['NN'],['noun'],"[[87, 89]]","[[81, 85]]",[],['NN'],[],"['NN', 'NN']","[[87, 89], [87, 89]]"
329,329,"ary, we assign a default value 3.0.  3.2 Named Entities (NE)  Named Entities are important semantic information ",330,['NE'],"['a', 'Named Entities', 'Named Entities']","[[57, 59]]","[[0, 1], [41, 55], [41, 55]]","['Named Entities', 'Named Entities']",['NE'],"[[41, 55], [41, 55]]",['NE'],"[[57, 59]]"
330,330,"2.1 Processing definitions  Our algorithms are used in an overall system  called ""onomasiological search system"" (OSS),  whose aim is to allow the user to find terms by ",331,['OSS'],"['system', 'onomasiological search system']","[[114, 117]]","[[66, 72], [82, 111]]",['onomasiological search system'],['OSS'],"[[82, 111]]",['OSS'],"[[114, 117]]"
331,331,"In MT Summit XIII: the Thirteenth Machine Translation Summit [organized by the] AsiaPacific Association for Machine Translation (AAMT), pages 513-520.",332,['MT'],"['Machine Translation', 'AsiaPacific Association for Machine Translation']","[[3, 5]]","[[34, 53], [80, 127]]",['AsiaPacific Association for Machine Translation'],['MT'],"[[80, 127]]",['AAMT'],"[[129, 133]]"
332,332,"guished from mentions in text or mentions in other sources. The Terence Annotation Format (TAF) provides a unified framework to annotate events, par-",333,['TAF'],"['or', 'Terence Annotation Format', 'a']","[[91, 94]]","[[30, 32], [64, 89], [77, 78]]",['Terence Annotation Format'],['TAF'],"[[64, 89]]",['TAF'],"[[91, 94]]"
333,333,"Subjacency sub-  sumes, as well as other principles, Ross's lO  Complex Noun Phrase Constraint (CNPC), which  prohibits movements out o f~-NpNPS ~ structures, ",334,['CNPC'],"['as', 'as', 'Complex Noun Phrase Constraint']","[[96, 100]]","[[24, 26], [24, 26], [64, 94]]",['Complex Noun Phrase Constraint'],['CNPC'],"[[64, 94]]",['CNPC'],"[[96, 100]]"
334,334,We report both the aggregate curves precision/recall curves and Precision@N (P@N) in our experiments.,335,[],"['Precision @ N', 'P @ N']",[],"[[-1, 12], [-1, 4]]",['Precision @ N'],[''],[],['P@N'],"[[77, 80]]"
335,335,On the source-language side of the  corpus we will automatically generate lists of  frequent multiword expressions (MWEs) and  grammatical constructions using the methodology ,336,"['MWEs', ')']",['multiword expressions'],"[[116, 120], [120, 121]]","[[93, 114]]",['multiword expressions'],"['MWEs', ')']","[[93, 114]]",['MWEs'],"[[116, 120]]"
336,336,al. were entered into Graph Spider using the  metapattern language (MPL) designed by the  Graph Spider authors.,337,['MPL'],['metapattern language'],"[[68, 71]]","[[46, 66]]",['metapattern language'],['MPL'],"[[46, 66]]",['MPL'],"[[68, 71]]"
337,337,"In interaction with the user, the system should play the role of an Information Search Assistant (ISA). ",338,['ISA'],"['In', 'Information Search Assistant']","[[98, 101]]","[[0, 2], [68, 96]]",['Information Search Assistant'],['ISA'],"[[68, 96]]",['ISA'],"[[98, 101]]"
338,338,"ducted experiments on the same dataset for sentence identification using interaction patterns generated by another pattern generating algorithm (PGA) (Huang et al.,",339,['PGA'],['pattern generating algorithm'],"[[145, 148]]","[[115, 143]]",['pattern generating algorithm'],['PGA'],"[[115, 143]]",['PGA'],"[[145, 148]]"
339,339,"{zhaosq,xlan,tliu,lisheng}@ir.hit.edu.cn Abstract Paraphrase generation (PG) is important in plenty of NLP applications.",340,"['PG', 'NLP']",['Paraphrase generation'],"[[73, 75], [103, 106]]","[[50, 71]]",['Paraphrase generation'],"['PG', 'NLP']","[[50, 71]]","['PG', 'NLP']","[[73, 75], [103, 106]]"
340,340,"1. Introduction Word segmentation is an important task in natural language processing (NLP) for languages without word delimiters (e.g., Chinese).",341,['NLP'],"['an', 'in natural language processing']","[[87, 90]]","[[37, 39], [55, 85]]",['in natural language processing'],['NLP'],"[[55, 85]]",['NLP'],"[[87, 90]]"
341,341,"of derivations. Each such derivation is realized in  PROVERB by a proof communicative act (PEA),  following the viewpoint hat language utterances are ",342,['PEA'],['a proof communicative act'],"[[91, 94]]","[[64, 89]]",['proof communicative act'],['PEA'],"[[66, 89]]","['PROVERB', 'PEA']","[[53, 60], [91, 94]]"
342,342," Introduction The Penn Chinese Treebank (CTB) is an ongoing project, with its objective being to",343,[')'],"['Treebank', 'an']","[[43, 44]]","[[30, 38], [35, 37]]",['Treebank'],[')'],"[[31, 39]]",['CTB'],"[[41, 44]]"
343,343,News stories typically describe real-world events.  Topic detection and tracking (TDT) aims to detect stories that discuss identical or directly related,344,['TDT'],['Topic detection and tracking'],"[[82, 85]]","[[52, 80]]",['Topic detection and tracking'],['TDT'],"[[52, 80]]",['TDT'],"[[82, 85]]"
344,344,"For Arabic, morphological segmentation is performed by MADA 3.2 (Habash et al, 2009), using the Penn Arabic Treebank (PATB) segmentation scheme as recommended by El Kholy and Habash",345,"['MADA', 'PATB']","['Arabic', 'Penn Arabic Treebank']","[[55, 59], [118, 122]]","[[4, 10], [96, 116]]",['Penn Arabic Treebank'],"['MADA', 'PATB']","[[96, 116]]","['MADA', 'PATB']","[[55, 59], [118, 122]]"
345,345,"In ear l ier  papers devoted to interpersonal  interaction iFrank,1981; Levinson,1981\] much atten-  tion is paid to studying the role of speecb act (SA)  i n  d ia logue  s t ructure .",346,['SA'],"['speecb act', 's']","[[150, 152]]","[[138, 148], [19, 20]]",['speecb act'],['SA'],"[[138, 148]]",['SA'],"[[150, 152]]"
346,346,"we can use these annotations to measure an average precision across the precision-recall curve, and an aggregate mean average precision (MAP) across all relations.",347,['MAP'],"['an average precision', 'an', 'mean average precision']","[[137, 140]]","[[40, 60], [4, 6], [113, 135]]",['mean average precision'],['MAP'],"[[113, 135]]",['MAP'],"[[137, 140]]"
347,347," ? BLEU (bilingual evalutation understudy) score: This score measures the precision of unigrams, bigrams, trigrams, and 4-grams with respect to a",348,[],['evalutation understudy )'],[],"[[-1, 23]]",['evalutation understudy )'],[''],[],['BLEU'],"[[3, 7]]"
348,348,2007 task into four sub-tasks: (1) target word frame disambiguation (TWFD); (2) FE boundary detection (FEBD); (3) GF label classification (GFLC) and (4) FE label classification (FELC).,349,"['TWFD', 'FE', 'FEBD', 'GF', 'FELC']","['target word frame disambiguation', 'boundary detection']","[[69, 73], [80, 82], [103, 107], [114, 116], [178, 182]]","[[35, 67], [83, 101]]","['target word frame disambiguation', 'boundary detection']","['TWFD', 'FE', 'FEBD', 'GF', 'FELC']","[[35, 67], [83, 101]]","['TWFD', 'FE', 'FEBD', 'GF', 'GFLC', 'FE', 'FELC']","[[69, 73], [80, 82], [103, 107], [114, 116], [139, 143], [80, 82], [178, 182]]"
349,349, Table 2 shows part of a decision list for the target noun chicken that was learned from a subset of the BNC (British National Corpus) [17]. Note that the,350,['BNC'],"['a', 'a', 'British National Corpus']","[[104, 107]]","[[1, 2], [1, 2], [109, 132]]",['British National Corpus'],['BNC'],"[[110, 133]]",['BNC'],"[[105, 108]]"
350,350,"The table shows percentage of phrases that we have to retain. ES=Spanish, EN=English, FR=French, CS=Czech, DE=German. ",351,[],[],[],[],[],[''],[],"['ES', 'EN', 'FR', 'CS', 'DE']","[[62, 64], [74, 76], [86, 88], [97, 99], [107, 109]]"
351,351,josefr@coli.uni-sb.de Abstract Active Learning (AL) has been proposed as a technique to reduce the amount of annotated,352,['AL'],"['Active Learning', 'a']","[[48, 50]]","[[31, 46], [27, 28]]",['Active Learning'],['AL'],"[[31, 46]]",['AL'],"[[48, 50]]"
352,352," 2.1 Weighted regular tree grammars A weighted regular tree grammar (WRTG) is a 4tuple G = (S,L,R, s`), where S and L are two",353,[')'],"['regular tree', 'regular tree grammar', 'a']","[[72, 73]]","[[13, 25], [13, 33], [18, 19]]",['regular tree grammar'],[')'],"[[14, 34]]",['WRTG'],"[[69, 73]]"
353,353,"(i) identify the scope of coordinations regardless of phrase types, and (ii) detect noun phrase (NP) coordinations and identify their scopes.",354,['NP'],"['phrase', 'noun phrase']","[[97, 99]]","[[54, 60], [84, 95]]",['noun phrase'],['NP'],"[[84, 95]]",['NP'],"[[97, 99]]"
354,354," 1 Introduction Among many natural language processing (NLP) tasks, such as text classification, question answer-",355,[')'],['language processing ('],"[[58, 59]]","[[34, 55]]",['language processing ('],[')'],"[[35, 56]]",['NLP'],"[[56, 59]]"
355,355,"(01) AT (Singular Article)  (03) BED (were)  (05) BEG (being)  (07) BER (are, 're) ",356,"['AT', 'BED', 'BEG']",['Singular Article'],"[[5, 7], [33, 36], [50, 53]]","[[9, 25]]",['Singular Article'],"['AT', 'BED', 'BEG']","[[9, 25]]","['AT', 'BED', 'BEG', 'BER']","[[5, 7], [33, 36], [50, 53], [68, 71]]"
356,356,"In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI?77), page 67=76. ",357,['IJCAI?77'],"['In', 'International Joint Conference on Artificial Intelligence']","[[81, 89]]","[[0, 2], [22, 79]]",['International Joint Conference on Artificial Intelligence'],['IJCAI?77'],"[[22, 79]]",['IJCAI?77'],"[[81, 89]]"
357,357,In Proc. of the Human Language Technologies (HLT): The Annual Conf.,358,['HLT'],['Human Language Technologies'],"[[45, 48]]","[[16, 43]]",['Human Language Technologies'],['HLT'],"[[16, 43]]",['HLT'],"[[45, 48]]"
358,358,"We experimentally evaluated the test collection for single document summarization contained in the RST Discourse Treebank (RST-DTB) (Carlson et al.,",359,[],['RST Discourse Treebank'],[],"[[99, 121]]",['RST Discourse Treebank'],[''],"[[99, 121]]",['RST-DTB'],"[[123, 130]]"
359,359,implementation of SVM.  Lexical Classifier (LC): This method calculates the number of positive words and negative words,360,"['SVM', 'LC']",['Lexical Classifier'],"[[18, 21], [44, 46]]","[[24, 42]]",['Lexical Classifier'],"['SVM', 'LC']","[[24, 42]]","['SVM', 'LC']","[[18, 21], [44, 46]]"
360,360, (Undecided) Meronym(MER)  (a) IF x=ANT ,361,"['MER', 'IF']",['Meronym'],"[[20, 23], [30, 32]]","[[12, 19]]",['Meronym'],"['MER', 'IF']","[[13, 20]]",['ANT'],"[[36, 39]]"
361,361,organizations in knowledge mining approaches to  master this information for quality assurance or  Customer Relationship Management (CRM) purposes.,362,['CRM'],['Customer Relationship Management'],"[[133, 136]]","[[99, 131]]",['Customer Relationship Management'],['CRM'],"[[99, 131]]",['CRM'],"[[133, 136]]"
362,362,12 Interac Figure 2: Upper chart: Turn-wise Interaction Quality (IQ) annotation from 3 raters. The final label is the median of,363,['IQ'],['Interaction Quality'],"[[65, 67]]","[[44, 63]]",['Interaction Quality'],['IQ'],"[[44, 63]]",['IQ'],"[[65, 67]]"
363,363,We annotate the relation node in the path with the exact relation word (as a lexical constraint) and the POS (postag constraint). We create a re-,364,['POS'],"['in', 'a', 'constraint', 'postag constraint', 'a']","[[105, 108]]","[[30, 32], [3, 4], [85, 95], [110, 127], [3, 4]]",['postag constraint'],['POS'],"[[110, 127]]",['POS'],"[[105, 108]]"
364,364,(#classes) with respect o each part of speech.  Table 1 Outline of Bunruigoihy3 (BGH)  POS noun I verb adj other total ,365,"['BGH', 'POS']",['Bunruigoihy3'],"[[81, 84], [87, 90]]","[[67, 79]]",['Bunruigoihy3'],"['BGH', 'POS']","[[67, 79]]","['BGH', 'POS']","[[81, 84], [87, 90]]"
365,365, Conditional Random Field  A conditional random field (CRF)[5] can be seen  as an undirected graph model in which the nodes ,366,['CRF'],"['conditional random field', 'an']","[[54, 57]]","[[28, 52], [13, 15]]",['conditional random field'],['CRF'],"[[1, 25]]",[],[]
366,366,VIOLATED EXPECTATION (Ho) NONVOLITIONAL-RESULT (M&T) EXPLANATION (Ho) ( CAUSAL  ADDITIVE ) - RESULT (A&L) ( SEMANTIC  PRAGMATIC ) - EXPLANATION (A&L),367,['M&T)'],"['-', '(', 'EXPLANATION']","[[48, 52]]","[[39, 40], [21, 22], [53, 64]]",['EXPLANATION'],['M&T)'],"[[53, 64]]","['NONVOLITIONAL-RESULT', 'M&T', 'EXPLANATION', 'A&L', 'A&L']","[[26, 46], [48, 51], [53, 64], [102, 105], [102, 105]]"
367,367, 5 Conclusion Our approach is akin to so-called semantic role labelling (SRL) approaches [CM05] and to several rewriting approaches developed to modify parsing output in RTE systems [Ass07].,368,[')'],"['role labelling', 'in']","[[75, 76]]","[[56, 70], [31, 33]]",['role labelling'],[')'],"[[57, 71]]","['SRL', 'CM05', 'RTE']","[[73, 76], [90, 94], [170, 173]]"
368,368,   (5) Flattened CPT (FCPT): the CPT with the  single in and out arcs of non-terminal nodes (ex-,369,[')'],"['CPT', 'CPT']","[[2, 3]]","[[14, 17], [14, 17]]",[],[')'],[],"['CPT', 'FCPT', 'CPT']","[[17, 20], [22, 26], [17, 20]]"
369,369,"two requirements. Since it has to be transformed  into context?free grammar (CFG) for recognition,  features must have a finite number of values, as ",370,['CFG'],"['context ? free grammar', 'a']","[[77, 80]]","[[-1, 21], [28, 29]]",['context ? free grammar'],['CFG'],[],['CFG'],"[[77, 80]]"
370,370,"capture various relationships related to the predicate, we assign function label ? ADT (adjunct)? for",371,['ADT'],['adjunct'],"[[83, 86]]","[[88, 95]]",['adjunct'],['ADT'],"[[88, 95]]",['ADT'],"[[83, 86]]"
371,371,SN  where CN = common oun  PN = proper name  SN = Sa-inflection oun (nominal verb) ,372,['SN'],"['common', 'oun', 'oun']","[[0, 2]]","[[15, 21], [22, 25], [22, 25]]",['common'],['SN'],"[[15, 21]]","['SN', 'CN', 'PN', 'SN']","[[0, 2], [10, 12], [27, 29], [0, 2]]"
372,372," They solve this by formulating the problem as a quadratic assignment problem (QAP). But, even",373,['QAP'],"['problem', 'a quadratic assignment problem']","[[78, 81]]","[[35, 42], [46, 76]]",['quadratic assignment problem'],['QAP'],"[[49, 77]]",['QAP'],"[[79, 82]]"
373,373,"on its n?1 previous tokens, i.e. we directly model the following conditional probability (in practice, we choose n = 3, Tri-gram (TRI) ): p(w",374,['TRI'],['Tri-gram'],"[[130, 133]]","[[120, 128]]",['Tri-gram'],['TRI'],"[[120, 128]]",['TRI'],"[[130, 133]]"
374,374,"on adjunction (Joshi, 1987):  ? Null adjunction (NA): disallow any adjunc-  tion on the given node.",375,['NA'],"['on adjunction', 'Null adjunction', 'tion on']","[[49, 51]]","[[0, 13], [32, 47], [76, 83]]","['on adjunction', 'Null adjunction', 'tion on']",['NA'],"[[0, 13], [32, 47], [76, 83]]",['NA'],"[[49, 51]]"
375,375,It takes an examplebased approach to recognize IV words and follows description length gain (DLG) to infer OOV words in terms of their text compression effect.,376,"['IV', 'DLG', 'OOV']","['description length gain', 'in']","[[47, 49], [93, 96], [107, 110]]","[[68, 91], [89, 91]]",['description length gain'],"['IV', 'DLG', 'OOV']","[[68, 91]]","['DLG', 'OOV']","[[93, 96], [107, 110]]"
376,376,8. Strong forms of pronouns not preceded by a preposition (unless they carry IC) t Table 1: Annotation guidelines; IC = Intonation Center. ,377,['IC'],"['a', 't', 'Intonation Center']","[[77, 79]]","[[44, 45], [4, 5], [120, 137]]",['Intonation Center'],['IC'],"[[120, 137]]","['IC', 'IC']","[[77, 79], [77, 79]]"
377,377," 1 Introduction Topical Text Categorization (TC), the task of classifying documents by pre-defined topics, is most",378,[')'],['Text Categorization'],"[[46, 47]]","[[23, 42]]",['Text Categorization'],[')'],"[[24, 43]]",['TC'],"[[45, 47]]"
378,378,"As an example, the following arrow property says that within an interrogative phrase (Pint), an interrogative chunk (IntC) with an interrogative pronoun inside (pint) ar-",379,"['Pint', 'IntC']","['interrogative phrase', 'interrogative chunk', 'interrogative']","[[86, 90], [117, 121]]","[[64, 84], [96, 115], [64, 77]]","['interrogative phrase', 'interrogative chunk']","['Pint', 'IntC']","[[64, 84], [96, 115]]",['IntC'],"[[117, 121]]"
379,379,Controlled English at Douglas SMART Controlled English ASD Simplified Technical English (ASD-STE) AECMA Simplified English (AECMA-SE),380,[],"['English', 'English', 'ASD Simplified Technical English', 'AECMA Simplified English']",[],"[[11, 18], [11, 18], [55, 87], [98, 122]]","['ASD Simplified Technical English', 'AECMA Simplified English']",[''],"[[55, 87], [98, 122]]","['SMART', 'ASD', 'ASD-STE', 'AECMA-SE']","[[30, 35], [55, 58], [89, 96], [124, 132]]"
380,380,16: end while 17: return builtPPs 3.3 Extended GNPPA (E-GNPPA) The GNPPA described in section 3.1 assumes that,381,[],"['GNPPA', 'GNPPA']",[],"[[47, 52], [47, 52]]",[],[''],[],"['E-GNPPA', 'GNPPA']","[[54, 61], [47, 52]]"
381,381,"  3.3 Optimality Theory  Optimality Theory (OT) is a theory of language  and grammar, developed by Alan Prince and Paul ",382,[')'],"['Theory', 'Theory', 'a']","[[44, 45]]","[[15, 21], [15, 21], [9, 10]]","['Theory', 'Theory']",[')'],"[[17, 23], [17, 23]]",['OT'],"[[44, 46]]"
382,382,"1001   Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 844?853, October 25-29, 2014, Doha, Qatar.",383,['EMNLP'],['Empirical Methods in Natural Language Processing'],"[[95, 100]]","[[45, 93]]",['Empirical Methods in Natural Language Processing'],['EMNLP'],"[[45, 93]]",['EMNLP'],"[[95, 100]]"
383,383,"2 tMi The two parameter classes for generating modifying nonterminals that are children of base NPs (NPB nodes), PM,NPB and PMw,NPB, have the following back-off structures. ",384,"['tMi', 'NPs', 'PM']","['base', 'NPB']","[[2, 5], [96, 99], [113, 115]]","[[91, 95], [101, 104]]",[],"['tMi', 'NPs', 'PM']",[],"['NPs', 'NPB', 'PM', 'NPB', 'PMw', 'NPB']","[[96, 99], [101, 104], [113, 115], [101, 104], [124, 127], [101, 104]]"
384,384,being developed as an Apache incubator project.  UIMA?s Common Analysis System (CAS) is used to describe typed objects (annotations) associated,385,"['UIMA?', 'CAS']","['an', 's Common Analysis System', 'is']","[[49, 54], [80, 83]]","[[19, 21], [54, 78], [69, 71]]",['s Common Analysis System'],"['UIMA?', 'CAS']","[[54, 78]]",['CAS'],"[[80, 83]]"
385,385,Sane: ..PERJANTAINA (pltkanl iper jantalna)  PER3ANTAI FRIDAY Noun $8 Eaa  Sane: PITK&KSI.. (p i tk ika iper Janta iks i )   PITK& LI3NG Ad ject ive  $8 Trane l  ,386,"['PERJANTAINA', 'PITK&KSI']","['pltkanl iper jantalna', 'p i tk', 'iper', 'i']","[[8, 19], [81, 89]]","[[21, 42], [93, 99], [29, 33], [29, 30]]",['pltkanl iper jantalna'],"['PERJANTAINA', 'PITK&KSI']","[[21, 42]]","['PERJANTAINA', 'PITK']","[[8, 19], [81, 85]]"
386,386,"115  Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 566?576, October 25-29, 2014, Doha, Qatar.",387,['EMNLP'],['Empirical Methods in Natural Language Processing'],"[[93, 98]]","[[43, 91]]",['Empirical Methods in Natural Language Processing'],['EMNLP'],"[[43, 91]]",['EMNLP'],"[[93, 98]]"
387,387,"831 . . . demonstrated that HOIL-1L interacting protein (HOIP), a ubiquitin ligase that can catalyze the assembly of linear polyubiquitin chains, is recruited to DC40 in a TRAF2-dependent manner following engagement of CD40 . . .",388,[')'],"['interacting', 'a', 'in a']","[[61, 62]]","[[36, 47], [18, 19], [167, 171]]",['interacting'],[')'],"[[36, 47]]","['HOIP', 'DC40', 'CD40']","[[57, 61], [162, 166], [219, 223]]"
388,388,"tasks. While having the same model structure as Hidden Markov Models (HMMs), CRFs are trained discriminatively and can use large numbers of corre-",389,"['HMMs', 'CRFs']",['Hidden Markov Models'],"[[70, 74], [77, 81]]","[[48, 68]]",['Hidden Markov Models'],"['HMMs', 'CRFs']","[[48, 68]]","['HMMs', 'CRFs']","[[70, 74], [77, 81]]"
389,389,derstanding our approach.  2.1.1 The Conversat ional  Roles Model  (COR)   In the field of information retrieval (IR) the interactive ,390,"['COR', 'IR']","['Conversat ional Roles Model', 'information retrieval']","[[68, 71], [114, 116]]","[[-1, 26], [91, 112]]","['Conversat ional Roles Model', 'information retrieval']","['COR', 'IR']","[[91, 112]]","['COR', 'IR']","[[68, 71], [114, 116]]"
390,390,evt EVENT lfr LIVING THING sub SUBSTANCE fod FOOD lme LINEAR MEASURE tme TIME Table 1: The 39 CoreLex basic types (BTs) and their WordNet anchor nodes Basic type WordNet anchor Examples,391,"['lfr', 'lme', 'BTs']","['CoreLex basic types', 'type']","[[10, 13], [50, 53], [115, 118]]","[[94, 113], [108, 112]]",['CoreLex basic types'],"['lfr', 'lme', 'BTs']","[[94, 113]]","['LIVING', 'SUBSTANCE', 'FOOD', 'BTs']","[[14, 20], [31, 40], [45, 49], [115, 118]]"
391,391,The first observation is that the task is quite difficult as evidenced by extremely poor performance  of the bag of words approach (BOW). The correct ,392,['BOW'],"['of', 'bag of words']","[[132, 135]]","[[102, 104], [109, 121]]",['bag of words'],['BOW'],"[[109, 121]]",['BOW'],"[[132, 135]]"
392,392,Table 3 describes the used data sets.  Assault Weapons (AW) 4,393,['AW'],['Assault Weapons'],"[[56, 58]]","[[39, 54]]",['Assault Weapons'],['AW'],"[[39, 54]]",['AW'],"[[56, 58]]"
393,393," Definition 1 A character string ABC is called an overlap ambiguity string (OAS) if it can be segmented into two words either as AB/C or A/BC (not both), depending on context.",394,['A'],"['string', 'overlap ambiguity string', 'it']","[[13, 14]]","[[25, 31], [49, 73], [5, 7]]",['overlap ambiguity string'],['A'],"[[50, 74]]","['ABC', 'OAS', 'AB/C', 'BC']","[[33, 36], [76, 79], [129, 133], [34, 36]]"
394,394, Irish students do not receive any instruction in  Modern Foreign Languages (MFL) up until this  point (Irish is not considered a MFL).,395,[')'],"['Foreign Languages', 'a']","[[79, 80]]","[[57, 74], [30, 31]]",['Foreign Languages'],[')'],"[[58, 75]]","['MFL', 'MFL']","[[77, 80], [77, 80]]"
395,395,resulting grammar. We cast the minimization as an integer linear program (ILP). Let V be the set of,396,['ILP'],['integer linear program'],"[[74, 77]]","[[50, 72]]",['integer linear program'],['ILP'],"[[50, 72]]",['ILP'],"[[74, 77]]"
396,396,L J  = lea:-ncd j o u r n a l s   PJ - 1 journals  NR = newt;pc?pcr reportasc  F = fictlon ,397,"['J', 'NR']","['u', 'n', 'newt']","[[2, 3], [51, 53]]","[[20, 21], [12, 13], [56, 60]]",[],"['J', 'NR']",[],['NR'],"[[51, 53]]"
397,397,"icoglu and Bergler, 2009). The second group uses a  machine learning (ML)-based approach which exploits various specific features and learning algo-",398,['ML'],"['a machine learning', 'learning']","[[70, 72]]","[[-1, 17], [60, 68]]",['machine learning'],['ML'],"[[52, 68]]",[],[]
398,398,"1 The  SCAN System  SCAN was developed for the TREC-96 SDR task,  a known item information retrieval (IR) task from  approximately 47hours of the NIST/DARPA HUB4 ",399,"['SDR', 'IR']","['for', 'a', 'information retrieval']","[[55, 58], [102, 104]]","[[39, 42], [26, 27], [79, 100]]",['information retrieval'],"['SDR', 'IR']","[[79, 100]]","['SCAN', 'TREC-96', 'SDR', 'IR', 'NIST']","[[7, 11], [47, 54], [55, 58], [102, 104], [146, 150]]"
399,399,"Department of Linguistics, ? Center for the Preservation of Ancient Religious Texts (CPART) Brigham Young University",400,['CPART'],"['of', 'Center for the Preservation of Ancient Religious Texts']","[[85, 90]]","[[11, 13], [29, 83]]",['Center for the Preservation of Ancient Religious Texts'],['CPART'],"[[29, 83]]",['CPART'],"[[85, 90]]"
400,400,"145  Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1092?1103, October 25-29, 2014, Doha, Qatar.",401,['EMNLP'],['Empirical Methods in Natural Language Processing'],"[[93, 98]]","[[43, 91]]",['Empirical Methods in Natural Language Processing'],['EMNLP'],"[[43, 91]]",['EMNLP'],"[[93, 98]]"
401,401,"Specifically, we investigate dialectal language in publicly available Twitter data, focusing on AfricanAmerican English (AAE), a dialect of Standard American English (SAE) spoken by millions of peo-",402,"['AAE', 'SAE']","['AfricanAmerican', 'English', 'a', 'Standard American English']","[[121, 124], [167, 170]]","[[96, 111], [112, 119], [8, 9], [140, 165]]","['AfricanAmerican', 'Standard American English']","['AAE', 'SAE']","[[96, 111], [140, 165]]","['AAE', 'SAE']","[[121, 124], [167, 170]]"
402,402,"? ?  Table 4: Results for the best baseline (B5) and the learning to rank method (LTR), using all entity pairs in the dataset, including those without any relevant sentences.",403,['LTR'],"['learning to rank method', 'in']","[[82, 85]]","[[57, 80], [40, 42]]",['learning to rank method'],['LTR'],"[[57, 80]]","['B5', 'LTR']","[[45, 47], [82, 85]]"
403,403,active (ACT) and passive (PASS) 3. causative (CAUS) 4.,404,"['ACT', 'PASS', 'CAUS']","['passive', 'causative']","[[8, 11], [26, 30], [46, 50]]","[[17, 24], [35, 44]]","['passive', 'causative']","['ACT', 'PASS', 'CAUS']","[[17, 24], [35, 44]]","['ACT', 'PASS', 'CAUS']","[[8, 11], [26, 30], [46, 50]]"
404,404,"problems. Informally, a CRF bears resemblance to a Hidden Markov Model (HMM) in which, for each input position in a sequence, there is an observed",405,"['CRF', 'HMM']","['a', 'a Hidden Markov Model', 'a']","[[24, 27], [72, 75]]","[[16, 17], [49, 70], [16, 17]]",['Hidden Markov Model'],"['CRF', 'HMM']","[[51, 70]]","['CRF', 'HMM']","[[24, 27], [72, 75]]"
405,405,Gambling neighborhood f bank  bank  Subject Code GB = Gambling  person use money piece ,406,['GB'],"['Gambling', 'Gambling person use']","[[49, 51]]","[[0, 8], [-1, 18]]",['Gambling person use'],['GB'],[],['GB'],"[[49, 51]]"
406,406,"He poured wine from the barrel into the bottle The semantic description of (20) appeals to an intermediate locus IME(LOC), which is not specified here.",407,[')'],['locus'],"[[78, 79]]","[[107, 112]]",[],[')'],[],[],[]
407,407,"UC 3 NLP, 1 BioNLP ML (Weka SVM) Table 2: Participation. UU = UofU, UZ = UZH, CU=ConcordU, UT = UTurku, UZ = UZH, US =",408,"['UC', 'NLP', 'BioNLP', 'ML', 'SVM', 'UU', 'UZ', 'UT', 'US']","['UofU', 'UZH', 'UTurku', 'UZH']","[[0, 2], [5, 8], [12, 18], [19, 21], [28, 31], [57, 59], [68, 70], [91, 93], [114, 116]]","[[62, 66], [73, 76], [96, 102], [73, 76]]",['UTurku'],"['UC', 'NLP', 'BioNLP', 'ML', 'SVM', 'UU', 'UZ', 'UT', 'US']","[[96, 102]]","['UC 3', 'NLP', 'BioNLP', 'ML', 'UU', 'UZ', 'UZH', 'CU', 'UT', 'UZ', 'UZH', 'US']","[[0, 4], [5, 8], [12, 18], [19, 21], [57, 59], [68, 70], [73, 76], [78, 80], [91, 93], [68, 70], [73, 76], [114, 116]]"
408,408,"ratio of the number of completely corrected generated MIUs over the number of all MIUs, and character accuracy (Ch-Acc), but the sentence accuracy (S-Acc) will also be reported in evaluation",409,"['Ch-Acc', 'S-Acc']","['character', 'accuracy', 'sentence accuracy']","[[112, 118], [148, 153]]","[[92, 101], [102, 110], [129, 146]]","['character', 'sentence accuracy']","['Ch-Acc', 'S-Acc']","[[92, 101], [129, 146]]","['MIUs', 'MIUs', 'Ch-Acc', 'S-Acc']","[[54, 58], [54, 58], [112, 118], [148, 153]]"
409,409,"They are Na?ve  Bayes (NB), Support Vector Machine (SVM),  Maximum Entropy (MaxEnt) (Kamal Nigam et al  1999) and standard chain CRFs (Fei et al 2003).",410,"['NB', 'SVM', 'MaxEnt', 'CRFs']","['Na ? ve Bayes', 'Support Vector Machine', 'Maximum Entropy']","[[23, 25], [52, 55], [76, 82], [129, 133]]","[[-1, 12], [28, 50], [59, 74]]","['Na ? ve Bayes', 'Support Vector Machine', 'Maximum Entropy']","['NB', 'SVM', 'MaxEnt', 'CRFs']","[[28, 50], [59, 74]]","['NB', 'SVM', 'MaxEnt', 'CRFs']","[[23, 25], [52, 55], [76, 82], [129, 133]]"
410,410,The similarity of decisions can be evaluated by calculating the proportion of identical decisions (PID)when comparing the test results with those of the gold stan-,411,['PID'],"['of decisions', 'proportion of identical decisions', 'of']","[[99, 102]]","[[15, 27], [64, 97], [15, 17]]","['decisions', 'proportion of identical decisions']",['PID'],"[[18, 27], [64, 97]]",[],[]
411,411, ? HybFSum (Hybrid Flat Summarizer): To investigate the performance of hierarchical topic,412,['('],['Flat Summarizer )'],"[[10, 11]]","[[-1, 16]]",['Flat Summarizer )'],['('],[],[],[]
412,412,been proposed in \[Uszkoreit 87\]: p.145 in his German  grammar. It makes the adverbial phrase (AdvP) a sister  node of the verb and its arguments: ,413,['AdvP'],"['adverbial phrase', 'a', 'verb']","[[96, 100]]","[[78, 94], [52, 53], [80, 84]]",['adverbial phrase'],['AdvP'],"[[78, 94]]",['AdvP'],"[[96, 100]]"
413,413,"(Zhao et al, 2014), The Meaning Factory (Bjerva et al, 2014), UNAL-NLP (Jimenez et al, 2014), and Illinois-LH (Lai and Hockenmaier, 2014). ",414,['UNAL-NLP'],"['and', 'Lai and Hockenmaier']","[[62, 70]]","[[94, 97], [111, 130]]",['Lai and Hockenmaier'],['UNAL-NLP'],"[[111, 130]]","['UNAL-NLP', 'LH']","[[62, 70], [107, 109]]"
414,414,"sentence, Multiple Linear Regression is used to  build a quantitative model relating the content  tags of the source language (SL) sentence to the  response, which is assumed to be the sum of the ",415,['SL'],"['a', 'source language']","[[127, 129]]","[[23, 24], [110, 125]]",['source language'],['SL'],"[[110, 125]]",['SL'],"[[127, 129]]"
415,415,"Commentary We distinguish three types of events in the domain: identification (ID) events trigger the system to name the street the car is on, turn events fire",416,[')'],['on'],"[[81, 82]]","[[75, 77]]",[],[')'],[],['ID'],"[[79, 81]]"
416,416,"For biomedical terms other than genes/gene products, the Unified Medical Language System (UMLS) meta-thesaurus (Lindberg et al, 1993) is a large",417,"['UMLS', ')']","['Unified Medical Language System', 'al', 'a']","[[90, 94], [94, 95]]","[[57, 88], [12, 14], [12, 13]]",['Unified Medical Language System'],"['UMLS', ')']","[[57, 88]]",['UMLS'],"[[90, 94]]"
417,417,snippets with a frequency higher than three. Then we calculate the inverse sentence frequency (ISF) for these phrases using the entire ICSI meeting corpus.,418,"['ISF', 'ICSI']","['frequency', 'inverse sentence frequency']","[[95, 98], [135, 139]]","[[16, 25], [67, 93]]",['inverse sentence frequency'],"['ISF', 'ICSI']","[[67, 93]]","['ISF', 'ICSI']","[[95, 98], [135, 139]]"
418,418," 1 Introduction In recognizing textual entailment (RTE), automated systems assess whether a human reader",419,[')'],"['entailment', 'a']","[[53, 54]]","[[38, 48], [35, 36]]",['entailment'],[')'],"[[39, 49]]",['RTE'],"[[51, 54]]"
419,419,"A decade ago, students interested in natural language processing arrived at universities having been exposed to the idea of machine translation (MT) primarily through science fiction.",420,['MT'],"['in', 'machine translation']","[[145, 147]]","[[23, 25], [124, 143]]",['machine translation'],['MT'],"[[124, 143]]",['MT'],"[[145, 147]]"
420,420,"man annotators identified in the texts. TP (true positives) is |A?G|, FP (false positives) is |A\G|, FN (false negatives) is |G\A|, and precision (P ),",421,"['TP', 'FP', 'FN']","['true', 'false positives', 'false negatives']","[[40, 42], [70, 72], [101, 103]]","[[44, 48], [74, 89], [105, 120]]","['false positives', 'false negatives']","['TP', 'FP', 'FN']","[[74, 89], [105, 120]]","['TP', 'FP', 'FN']","[[40, 42], [70, 72], [101, 103]]"
421,421,"We report results for the ATAS versions (ATAS-TC, ATAS-CRF) and for the baselines (Z-CRF, C-value, FRTC) as well as for using supervised (S-SEL) and unsupervised feature selection (U-SEL) in system setting (S) and gold boundary setting (G).",422,"['ATAS', 'S-SEL', 'U-SEL']","['supervised', 'unsupervised feature selection']","[[26, 30], [138, 143], [181, 186]]","[[126, 136], [149, 179]]",['unsupervised feature selection'],"['ATAS', 'S-SEL', 'U-SEL']","[[149, 179]]","['ATAS', 'ATAS-TC', 'ATAS-CRF', 'Z-CRF', 'FRTC', 'S-SEL', 'U-SEL']","[[26, 30], [41, 48], [50, 58], [83, 88], [99, 103], [138, 143], [181, 186]]"
422,422,amjbara@umich.edu Abstract The ACL Anthology Network (AAN)1 is a comprehensive manually curated networked,423,['AAN'],"['ACL Anthology Network', 'a']","[[54, 57]]","[[31, 52], [0, 1]]",['ACL Anthology Network'],['AAN'],"[[31, 52]]",['ACL'],"[[31, 34]]"
423,423,"where Q(w,w?) is proportional to the integral term in Equation (IX). The term PC(w) corresponds",424,"['Q', ')', 'IX)', 'PC']",['in'],"[[6, 7], [12, 13], [64, 67], [78, 80]]","[[37, 39]]",[],"['Q', ')', 'IX)', 'PC']",[],['IX'],"[[64, 66]]"
424,424,"Their by-country breakdown is as follows: 3.99M (61%) from Saudi Arabia (SA), 880K (13%) from Egypt (EG), 707K (11%) from Kuwait (KW), 302K (5%) from United Arab Emi-",425,"['SA', 'EG', 'KW']","['Saudi Arabia', 'Egypt', 'Kuwait']","[[73, 75], [101, 103], [130, 132]]","[[59, 71], [94, 99], [122, 128]]","['Saudi Arabia', 'Kuwait']","['SA', 'EG', 'KW']","[[59, 71], [122, 128]]","['SA', 'EG', 'KW']","[[73, 75], [101, 103], [130, 132]]"
425,425,"section 8.1). Then, the grammar underlying the parser is provided with a specific attachment heuristic that uses corequirement (CR) information from the lexicon. ",426,['CR'],['corequirement'],"[[128, 130]]","[[113, 126]]",['corequirement'],['CR'],"[[113, 126]]",['CR'],"[[128, 130]]"
426,426," In line 4, G91 provides an Acknowledge type of evidence, and Moves On to the next task item: identifying the Target Location - Grid (TL-GR) of the CFF. The Acknowledge and Move On, referring to the CGU",427,['CFF'],['Target Location - Grid'],"[[147, 150]]","[[109, 131]]",['Target Location - Grid'],['CFF'],"[[110, 132]]","['TL-GR', 'CFF', 'CGU']","[[134, 139], [148, 151], [199, 202]]"
427,427, With basic CG there are just two rules for combining categories: the forward (FA) and backward (BA) functional application rules.,428,"['CG', 'FA', 'BA']","['for', 'forward', 'backward']","[[11, 13], [78, 80], [96, 98]]","[[39, 42], [69, 76], [86, 94]]","['forward', 'backward']","['CG', 'FA', 'BA']","[[70, 77], [87, 95]]","['CG', 'FA', 'BA']","[[12, 14], [79, 81], [97, 99]]"
428,428,"To overcome this problem, Shen et al (2008) proposed a dependency language model (DLM) to exploit longdistance word relations for SMT.",429,['DLM'],['a dependency language model'],"[[82, 85]]","[[53, 80]]",['dependency language model'],['DLM'],"[[55, 80]]","['DLM', 'SMT']","[[82, 85], [130, 133]]"
429,429,"Abstract In this paper, we explore the possibility of leveraging Residual Networks (ResNet), a powerful structure in constructing extremely",430,['ResNet'],"['Residual Networks', 'a']","[[84, 90]]","[[65, 82], [5, 6]]",['Residual Networks'],['ResNet'],"[[65, 82]]",['ResNet'],"[[84, 90]]"
430,430,the end we build two NGCMs: NGCMP  (NGCM according to preceding context) and  NGCMS (NGCM according to succeeding  context).,431,"['NGCMP', 'NGCMS']","['NGCM', 'according to preceding context', 'NGCM according to succeeding context']","[[28, 33], [78, 83]]","[[21, 25], [41, 71], [-1, 35]]","['according to preceding context', 'NGCM according to succeeding context']","['NGCMP', 'NGCMS']","[[41, 71]]","['NGCMs', 'NGCM', 'NGCMS', 'NGCM']","[[21, 26], [21, 25], [78, 83], [21, 25]]"
431,431,"Ures uniformly (Dadam et al, 1986). Our LDB  rmat and Lexical Query l_anguage (LQL) sup-  port the hierarchical model for dictionary data; ",432,"['LDB', 'LQL']","['al', 'Lexical Query l_anguage']","[[40, 43], [79, 82]]","[[25, 27], [54, 77]]",['Lexical Query l_anguage'],"['LDB', 'LQL']","[[54, 77]]","['LDB', 'LQL']","[[40, 43], [79, 82]]"
432,432,"The Office. Television series, the National Broadcasting Company (NBC). ",433,['NBC'],['National Broadcasting Company'],"[[66, 69]]","[[35, 64]]",['National Broadcasting Company'],['NBC'],"[[35, 64]]",['NBC'],"[[66, 69]]"
433,433, 1 Introduction Question Answering (QA) is a challenging task that draws upon many aspects of NLP.,434,[')'],['Answering'],"[[37, 38]]","[[24, 33]]",['Answering'],[')'],"[[25, 34]]","['QA', 'NLP']","[[36, 38], [94, 97]]"
434,434,"opment and sentence generation. Report, German National Center for Information Technology (GMD),  Institute for integrated publication and information systems (IPSI), Darmstadt, Germany, January 1997. ",435,"['GMD', 'IPSI']","['and', 'German National Center for Information Technology', 'Institute for integrated publication and information systems']","[[91, 94], [160, 164]]","[[7, 10], [40, 89], [98, 158]]","['German National Center for Information Technology', 'Institute for integrated publication and information systems']","['GMD', 'IPSI']","[[40, 89], [98, 158]]","['GMD', 'IPSI']","[[91, 94], [160, 164]]"
435,435,"knowledge, mnong others in l:'ei~onal or DBMT systems.  Such Discovery Assistants (DA) slmuld certainly be  highly cooperative, namely show sensible interactivity ",436,"['DBMT', 'DA']",['Discovery Assistants'],"[[41, 45], [83, 85]]","[[61, 81]]",['Discovery Assistants'],"['DBMT', 'DA']","[[61, 81]]","['DBMT', 'DA']","[[41, 45], [83, 85]]"
436,436,"pact of syllabification on the L2P problem in English. Their Syllabification by Analogy (SbA) algorithm is a data-driven, lazy learning approach.",437,"['L2P', 'SbA']","['on', 'Syllabification by Analogy', 'a']","[[31, 34], [89, 92]]","[[21, 23], [61, 87], [1, 2]]",['Syllabification by Analogy'],"['L2P', 'SbA']","[[61, 87]]","['L2P', 'SbA']","[[31, 34], [89, 92]]"
437,437,1 Introduction Resolving the ambiguity of person names in web search results is a challenging problem becoming an area of interest for Natural Language Processing (NLP) and Information Retrieval (IR) communities. ,438,"['NLP', 'IR']","['in', 'a', 'an', 'for Natural Language Processing', 'Information Retrieval']","[[164, 167], [196, 198]]","[[21, 23], [29, 30], [111, 113], [131, 162], [173, 194]]","['for Natural Language Processing', 'Information Retrieval']","['NLP', 'IR']","[[131, 162], [173, 194]]","['NLP', 'IR']","[[164, 167], [196, 198]]"
438,438,"In Proceedings  from the 16th International Conference on  Computational Linguistics (COLING-96), pages  592-597.",439,['COLING-96'],['on Computational Linguistics'],"[[86, 95]]","[[-1, 27]]",['on Computational Linguistics'],['COLING-96'],[],['COLING-96'],"[[86, 95]]"
439,439,e .g .  M C ~  --7 SUM + PRED* + IOBJ + WBJ + PREP P  *PRED = predicator - not predicate  1-1  detailed analysis of first occurring element of ,440,"['SUM', 'PRED', 'IOBJ', 'WBJ', 'PREPP']","['e', 'predicator']","[[19, 22], [25, 29], [33, 37], [40, 43], [-1, 4]]","[[0, 1], [62, 72]]",['predicator'],"['SUM', 'PRED', 'IOBJ', 'WBJ', 'PREPP']","[[62, 72]]","['PRED', 'IOBJ', 'WBJ', 'PRED']","[[25, 29], [33, 37], [40, 43], [25, 29]]"
440,440,"We think, based on the explicit sentences, several Support Vector Machine (SVM) classifiers can be established to do this task.",441,['SVM'],"['Support Vector Machine', 'to']","[[75, 78]]","[[51, 73], [62, 64]]",['Support Vector Machine'],['SVM'],"[[51, 73]]",['SVM'],"[[75, 78]]"
441,441,"average values. Figure 6 shows the average pitch of the phrase do you have in task interruption (INT) and poker-playing (PKR) of each player, with the actual values displayed in the columns below.",442,"['INT', 'PKR']","['in', 'interruption', 'in']","[[97, 100], [121, 124]]","[[75, 77], [83, 95], [75, 77]]",['interruption'],"['INT', 'PKR']","[[83, 95]]","['INT', 'PKR']","[[97, 100], [121, 124]]"
442,442,"enizes, tags, lemmatizes and parses the input sentences, outputting syntactic trees and then adding grammatical relations (GR) as described by (Buttery and Korhonen, 2005).",443,['GR'],['grammatical relations'],"[[123, 125]]","[[100, 121]]",['grammatical relations'],['GR'],"[[100, 121]]",['GR'],"[[123, 125]]"
443,443, We discuss the available functions of the  prototype Chinese Sketch Engine (CSE) as well  as the robustness of language-independent ,444,[')'],['Sketch Engine'],"[[79, 80]]","[[61, 74]]",['Sketch Engine'],[')'],"[[62, 75]]",['CSE'],"[[77, 80]]"
444,444,"tionary. In (Zingarelli, 2008), we found 33 different types of prepositional phrases (PPs), which we grouped into 21 classes (for instance, all of the 48",445,['PPs'],['prepositional phrases'],"[[86, 89]]","[[63, 84]]",['prepositional phrases'],['PPs'],"[[63, 84]]",['PPs'],"[[86, 89]]"
445,445,"for Statistical Machine Translation Shixiang Lu, Zhenbiao Chen, Bo Xu Interactive Digital Media Technology Research Center (IDMTech) Institute of Automation, Chinese Academy of Sciences, Beijing, China",446,['IDMTech'],['Interactive Digital Media Technology Research'],"[[124, 131]]","[[70, 115]]",['Interactive Digital Media Technology Research'],['IDMTech'],"[[70, 115]]",['IDMTech'],"[[124, 131]]"
446,446,"overall scores considering all metrics. To these systems we added minimum Bayes risk (MBR) decoding (Kumar and Byrne, 2004).",447,['MBR'],['minimum Bayes risk'],"[[86, 89]]","[[66, 84]]",['minimum Bayes risk'],['MBR'],"[[66, 84]]",['MBR'],"[[86, 89]]"
447,447,"(see also Sima?an, 1999, 2003). We haven?t implemented the max rule product (MRP) where posteriors are multiplied instead of added (Petrov and",448,['MRP'],['max rule product'],"[[77, 80]]","[[59, 75]]",['max rule product'],['MRP'],"[[59, 75]]",['MRP'],"[[77, 80]]"
448,448,of the intuition behind the inclusion of Tree Adjoining Lan-  gages (TAL) in the class of languages generated by a variant  of HG's called Modified Head Grammars (MHG's). In the ,449,"['TAL', 'HG', ""'s""]","['Tree Adjoining Lan- gages', 'in', 'a', 'Modified Head Grammars']","[[69, 72], [127, 129], [129, 131]]","[[-1, 24], [7, 9], [57, 58], [139, 161]]","['Tree Adjoining Lan- gages', 'Modified Head Grammars']","['TAL', 'HG', ""'s""]","[[139, 161]]","['TAL', ""HG's"", ""MHG's""]","[[69, 72], [127, 131], [163, 168]]"
449,449,"If a goal is not accomplished before worst-time  timeout value,  ACCUMVALUE = ACCUM.VALUE - \[response-  complexity(punishment) * sub-goal(worst-ease timeout punis- ",450,[],[],[],[],[],[''],[],['ACCUMVALUE'],"[[65, 75]]"
450,450,"Each of these sets is further divided by three domains: newswire (NWire), newspaper (NPaper), and broadcast news (BNews). ",451,['BNews'],['broadcast news'],"[[114, 119]]","[[98, 112]]",['broadcast news'],['BNews'],"[[98, 112]]","['NWire', 'BNews']","[[66, 71], [114, 119]]"
451,451,"The set of ncs in ? are selected from all the possibilities in the hyponym hierarchy according to the minimum description length (MDL) principle (Rissanen 1978) as used by Li and Abe (1995, 1998).",452,['MDL'],"['in', 'in', 'minimum description length']","[[130, 133]]","[[15, 17], [15, 17], [102, 128]]",['minimum description length'],['MDL'],"[[102, 128]]",['MDL'],"[[130, 133]]"
452,452,"However, we are interesting in the potential power of our model by incorporating lexical reordering (LR) models and comparing it with syntax-based models.",453,['LR'],"['in', 'lexical reordering']","[[101, 103]]","[[16, 18], [81, 99]]",['lexical reordering'],['LR'],"[[81, 99]]",['LR'],"[[101, 103]]"
453,453," In the next sections, we briefly introduce the kernel trick and describe the subtree (ST) kernel devised in Vishwanathan and Smola (2002), the subset tree (SST) kernel defined in Collins and Duffy (2002), and the partial tree (PT) kernel proposed in",454,"['ST', 'PT']","['subtree', 'tree', 'partial tree']","[[86, 88], [227, 229]]","[[77, 84], [80, 84], [213, 225]]","['subtree', 'partial tree']","['ST', 'PT']","[[78, 85], [214, 226]]","['ST', 'SST', 'PT']","[[87, 89], [157, 160], [228, 230]]"
454,454,"*****- TRANSFOREATIONS * l f**   SCAN CALLED AT 1 I  ANTEST CALLED FOR 12?F ALAT 3 (AACC) ,SO= 13. RES= 0, TOP= 1:s ",455,"['FOR', 'AACC']","['CALLED AT', 'ANTEST CALLED', 'ALAT']","[[12, 15], [84, 88]]","[[38, 47], [53, 66], [76, 80]]","['CALLED AT', 'ANTEST CALLED']","['FOR', 'AACC']","[[38, 47], [53, 66]]","['*- TRANSFOREATIONS', 'FOR', 'AACC']","[[4, 22], [12, 15], [84, 88]]"
455,455, ? Shallow Syntactic Similarity (SP) SP-Op-?.,456,[')'],['Syntactic Similarity'],"[[34, 35]]","[[10, 30]]",['Syntactic Similarity'],[')'],"[[11, 31]]","['SP', 'SP']","[[33, 35], [33, 35]]"
456,456,"using only a single, probable alignment."" The single most probable assignment Ama~  is the maximum a posteriori (MAP) assignment:  Amax = ar~maxPr(U,A, VIO ) (22) -- AE~4 ",457,['MAP'],"['a', 'maximum a posteriori']","[[113, 116]]","[[11, 12], [91, 111]]",['maximum a posteriori'],['MAP'],"[[91, 111]]","['MAP', 'Amax', 'VIO']","[[113, 116], [131, 135], [152, 155]]"
457,457,"Sentence). The dependency labels are NK (Noun Kernel), SB (Subject), AO (Object Accusative), HD (Head), MO (Modifier), AC (Adpositional Case Marker), CJ (Conjunct), and OC (Clausal Object).",458,"['NK', 'SB', 'AO', 'HD', 'MO', 'AC', 'CJ', 'OC']","['Noun Kernel', 'Subject', 'Object Accusative', 'Head', 'Modifier', 'Adpositional Case Marker', 'Conjunct', 'Clausal Object']","[[37, 39], [55, 57], [69, 71], [93, 95], [104, 106], [119, 121], [150, 152], [169, 171]]","[[41, 52], [59, 66], [73, 90], [97, 101], [108, 116], [123, 147], [154, 162], [173, 187]]","['Noun Kernel', 'Subject', 'Object Accusative', 'Modifier', 'Adpositional Case Marker', 'Conjunct', 'Clausal Object']","['NK', 'SB', 'AO', 'HD', 'MO', 'AC', 'CJ', 'OC']","[[41, 52], [59, 66], [73, 90], [108, 116], [123, 147], [154, 162], [173, 187]]","['NK', 'SB', 'AO', 'HD', 'MO', 'AC', 'CJ', 'OC']","[[37, 39], [55, 57], [69, 71], [93, 95], [104, 106], [119, 121], [150, 152], [169, 171]]"
458,458," Semantic relatedness of two given terms (text fragments, phrases or words) can be obtained by calculating the correlation between two high dimensional vectors of a Distributional Semantic Model (DSM), which is based on the assumption that semantic meaning of a text can be inferred from its usage in context",459,['DSM'],"['Semantic', 'a Distributional Semantic Model', 'on', 'a']","[[195, 198]]","[[0, 8], [162, 193], [119, 121], [3, 4]]",['Distributional Semantic Model'],['DSM'],"[[165, 194]]",['DSM'],"[[196, 199]]"
459,459,"An integrated, conditional model of information extraction and coreference with application to citation graph construction. In 20th Conference on Uncertainty in Artificial Intelligence (UAI). ",460,['UAI'],"['In', 'Uncertainty in Artificial Intelligence']","[[186, 189]]","[[124, 126], [146, 184]]",['Uncertainty in Artificial Intelligence'],['UAI'],"[[146, 184]]",['UAI'],"[[186, 189]]"
460,460,"4 Experiments In this section, we evaluate performance of different methods on the Relation Schema Induction (RSI) task.",461,['RSI'],"['In', 'on', 'Relation Schema Induction']","[[110, 113]]","[[14, 16], [27, 29], [83, 108]]",['Relation Schema Induction'],['RSI'],"[[83, 108]]",['RSI'],"[[110, 113]]"
461,461,We developed and tested our system on 30 full  length UK archaeological reports archived by the  Arts and Humanities Data Service (AHDS)4. ,462,"['UK', 'AHDS']","['and', 'Arts and Humanities Data Service']","[[54, 56], [131, 135]]","[[13, 16], [97, 129]]",['Arts and Humanities Data Service'],"['UK', 'AHDS']","[[97, 129]]",['UK'],"[[54, 56]]"
462,462,"formance. They are the One-error Loss (O-Loss) function, the Symmetric Loss (S-Loss) function, and the Hierarchical Loss (H-Loss) function:",463,[],"['One-error', 'Loss', 'Symmetric Loss', 'Hierarchical Loss']",[],"[[23, 32], [33, 37], [61, 75], [103, 120]]","['One-error', 'Symmetric Loss', 'Hierarchical Loss']",[''],"[[23, 32], [61, 75], [103, 120]]","['O-Loss', 'S-Loss', 'H-Loss']","[[39, 45], [77, 83], [122, 128]]"
463,463,"Instead of simple web page counts and complex  web page collection, we propose a novel model,  a Web Search with Double Checking (WSDC), to  analyze snippets.",464,['WSDC'],['Web Search with Double Checking'],"[[130, 134]]","[[97, 128]]",['Web Search with Double Checking'],['WSDC'],"[[97, 128]]",['WSDC'],"[[130, 134]]"
464,464,"hedge words Table 3: Participants and summary of system descriptions. Abbreviations: BI=Bioinformatician, NLP=Natural Language Processing researcher, SDE=Software Development Engineer, CoreNLP=Stanford CoreNLP, Porter=Porter",465,[],"['of', 'Language Processing', 'Development Engineer', 'CoreNLP']",[],"[[46, 48], [118, 137], [163, 183], [185, 192]]","['Language Processing', 'Development Engineer', 'CoreNLP']",[''],"[[118, 137], [163, 183], [185, 192]]","['BI', 'NLP', 'SDE', 'Porter']","[[85, 87], [106, 109], [150, 153], [211, 217]]"
465,465," 4 Dimensionality Reduction In this section, the Sparse Projection (SP) algorithm is described (see also Algorithm 1). SP is the core",466,[')'],['Projection'],"[[69, 70]]","[[55, 65]]",['Projection'],[')'],"[[56, 66]]","['SP', 'SP']","[[68, 70], [68, 70]]"
466,466,"2.2 Hierarchical Agglomerative Clustering After discovering sense clusters of paths, we employ hierarchical agglomerative clustering (HAC) to discover semantic relations from these sense clusters.",467,['HAC'],['hierarchical agglomerative clustering'],"[[134, 137]]","[[95, 132]]",['hierarchical agglomerative clustering'],['HAC'],"[[4, 41]]",['HAC'],"[[134, 137]]"
467,467,"extremely limited in this domain. Thus, language 1KEY: COM=completive aspect, DEM=demonstrative, DIR=directional",468,[],['aspect'],[],"[[70, 76]]",['aspect'],[''],"[[70, 76]]","['COM', 'DEM', 'DIR']","[[55, 58], [78, 81], [97, 100]]"
468,468, 2 Background: MaxEnt Models Maximum Entropy (MaxEnt) models are widely used in Natural Language Processing (Berger et,469,[')'],['Entropy'],"[[51, 52]]","[[36, 43]]",['Entropy'],[')'],"[[37, 44]]","['MaxEnt', 'MaxEnt']","[[15, 21], [15, 21]]"
469,469,"is set to 0.95 and threshold_f is set to 1;  Step 3. Use TCT (triple context template) matching  model to extract 2-char, 3-char and 4-char ",470,['TCT'],['triple context template'],"[[57, 60]]","[[62, 85]]",['triple context template'],['TCT'],"[[62, 85]]",['TCT'],"[[57, 60]]"
470,470,"trigger in the Trigger Rule Factbase.  Consistency Checkers ( CC' s): Report  inconsistencies within and between factbases and, ",471,"[""CC'""]","['Consistency Checkers', 's']","[[62, 65]]","[[39, 59], [34, 35]]",['Consistency Checkers'],"[""CC'""]","[[39, 59]]",['CC'],"[[62, 64]]"
471,471,"task: Argumentative Zoning (Teufel and Moens, 2002). Argumentative Zoning (AZ) is the task of applying one of seven discourse level tags (Fig-",472,['AZ'],"['Argumentative Zoning', 'Argumentative Zoning']","[[75, 77]]","[[6, 26], [6, 26]]","['Argumentative Zoning', 'Argumentative Zoning']",['AZ'],"[[6, 26], [6, 26]]",['AZ'],"[[75, 77]]"
472,472,ture of I end set to 1.  Unique Occurrences and Zone (UNIQ): This group of features indicates whether the word ,473,['I'],['Unique Occurrences and Zone'],"[[8, 9]]","[[25, 52]]",['Unique Occurrences and Zone'],['I'],"[[25, 52]]",['UNIQ'],"[[54, 58]]"
473,473,examples in (5). This change in beliefs about the past is treated as an error identification signal (EIS). ,474,['EIS'],['error identification signal'],"[[101, 104]]","[[72, 99]]",['error identification signal'],['EIS'],"[[72, 99]]",['EIS'],"[[101, 104]]"
474,474,"non-terminal symbols to characterize linguistic objects allow us to use much richer statistical means such as ME (maximum entropy model), etc.",475,['ME'],['maximum entropy model'],"[[110, 112]]","[[114, 135]]",['maximum entropy model'],['ME'],"[[114, 135]]",['ME'],"[[110, 112]]"
475,475,An example of a comma rule is the following: SX=S X ; ? SX=S X (18),476,[],"['X', 'X']",[],"[[46, 47], [46, 47]]",[],[''],[],"['SX', 'SX']","[[45, 47], [45, 47]]"
476,476,recognition. In Proceedings of the 26th Conference on Artificial Intelligence (AAAI). ,477,['AAAI'],"['In', 'Artificial Intelligence']","[[79, 83]]","[[13, 15], [54, 77]]",['Artificial Intelligence'],['AAAI'],"[[54, 77]]",['AAAI'],"[[79, 83]]"
477,477,nication after speech and email.4 Millions of users of instant messaging (IM) services and short message service (SMS) generate electronic content in a dialect that does not adhere to conventional gram-,478,"['IM', 'SMS']","['instant messaging', 'short message service', 'in a']","[[74, 76], [114, 117]]","[[55, 72], [91, 112], [147, 151]]","['instant messaging', 'short message service']","['IM', 'SMS']","[[55, 72], [91, 112]]","['IM', 'SMS']","[[74, 76], [114, 117]]"
478,478,"speech recognition (ASR), dialog management (DM), database access (DB Access), data storage (DB) and oral response generation (RG). In ad-",479,"['ASR', 'DM', 'DB', 'RG']","['speech', 'dialog management', 'database access', 'data storage', 'oral response generation']","[[20, 23], [45, 47], [67, 69], [127, 129]]","[[0, 6], [26, 43], [50, 65], [79, 91], [101, 125]]","['speech', 'dialog management', 'database access', 'data storage', 'oral response generation']","['ASR', 'DM', 'DB', 'RG']","[[0, 6], [26, 43], [50, 65], [79, 91], [101, 125]]","['ASR', 'DM', 'DB', 'RG']","[[20, 23], [45, 47], [67, 69], [127, 129]]"
479,479,"classifier.  6.1   Language Model (LM)  As language model has already been used in question classification [7], it is taken as ",480,['LM'],['Language Model'],"[[35, 37]]","[[19, 33]]",['Language Model'],['LM'],"[[19, 33]]",['LM'],"[[35, 37]]"
480,480,argument facet inducer. We introduce a new task of ARGUMENT FACET SIMILARITY (AFS). We discuss,481,['AFS'],['ARGUMENT FACET SIMILARITY'],"[[78, 81]]","[[51, 76]]",['ARGUMENT FACET SIMILARITY'],['AFS'],"[[51, 76]]",['AFS'],"[[78, 81]]"
481,481,Question reformulation ? Information Extraction (IE) ?,482,['IE'],['Information Extraction'],"[[49, 51]]","[[25, 47]]",['Information Extraction'],['IE'],"[[25, 47]]",['IE'],"[[49, 51]]"
482,482,results training on Multi-Domain Sentiment Dataset and testing on citation dataset (CITD). The horizontal line,483,['CITD'],"['on', 'on citation dataset']","[[84, 88]]","[[17, 19], [63, 82]]",['on citation dataset'],['CITD'],"[[63, 82]]",['CITD'],"[[84, 88]]"
483,483," In this paper, we propose to disambiguate NEs using a Personalized PageRank (PPR)-based random walk algorithm.",484,[')'],"['a', 'PageRank']","[[80, 81]]","[[9, 10], [67, 75]]",['PageRank'],[')'],"[[68, 76]]",['NEs'],"[[43, 46]]"
484,484,coverage of the course material.  The quality estimation task (QET) (CallisonBurch et al 2012) aims to develop quality indica-,485,['QET'],"['quality estimation task', 'quality']","[[63, 66]]","[[38, 61], [38, 45]]",['quality estimation task'],['QET'],"[[38, 61]]",['QET'],"[[63, 66]]"
485,485,"4.2 Evaluation of Different Representation Learning Methods Experiment Setup and Dataset We conduct sentiment classification of items in two traditional sentiment lexicons, HL (Hu and Liu, 2004) and MPQA (Wilson et al., 2005), to evaluate the effective of the",486,"['HL', 'MPQA']","['and', 'Hu and Liu', 'and']","[[173, 175], [199, 203]]","[[77, 80], [177, 187], [77, 80]]",[],"['HL', 'MPQA']",[],"['HL', 'MPQA']","[[173, 175], [199, 203]]"
486,486,"match number, SM (Short Match) is the continuous match number which is no more than 4, and LM (Long Match) is the continuous match number which is more than 4.",487,"['SM', 'LM']","['Short', 'Match', 'Long Match']","[[14, 16], [91, 93]]","[[18, 23], [24, 29], [95, 105]]",['Long Match'],"['SM', 'LM']","[[95, 105]]","['SM', 'LM']","[[14, 16], [91, 93]]"
487,487,"are written in the original language.  Direct orthographical mapping (DOM), which performs the transliteration between two lan-",488,['DOM'],"['in', 'Direct orthographical mapping']","[[70, 73]]","[[12, 14], [39, 68]]",['Direct orthographical mapping'],['DOM'],"[[39, 68]]",['DOM'],"[[70, 73]]"
488,488,"for each mention, four pieces of information: 1. the mention type: person (PER), organization (ORG), location (LOC), geopolitical en-",489,"['PER', 'ORG', 'LOC']","['person', 'organization', 'location']","[[75, 78], [95, 98], [111, 114]]","[[67, 73], [81, 93], [101, 109]]","['person', 'organization', 'location']","['PER', 'ORG', 'LOC']","[[67, 73], [81, 93], [101, 109]]","['PER', 'ORG', 'LOC']","[[75, 78], [95, 98], [111, 114]]"
489,489,degree of semantic equivalence between a pair of texts. Natural Language Processing (NLP) applications such as Question Answering (Lin and,490,['NLP'],"['a', 'Natural Language Processing']","[[85, 88]]","[[13, 14], [56, 83]]",['Natural Language Processing'],['NLP'],"[[56, 83]]",['NLP'],"[[85, 88]]"
490,490,from comparable in-domain corpora. We used the AFP (Agence France Presse) and APW (Associated Press Worldstream Service) news texts since there,491,"['AFP', 'APW']","['Agence France Presse', 'Associated Press Worldstream Service']","[[47, 50], [78, 81]]","[[52, 72], [83, 119]]","['Agence France Presse', 'Associated Press Worldstream Service']","['AFP', 'APW']","[[52, 72], [83, 119]]","['AFP', 'APW']","[[47, 50], [78, 81]]"
491,491,"additional computation costs, and can be applied to  several different learners, such as Naive Bayes  (NB), Maximum Entropy (ME), and Support  Vector Machines (SVMs) models.",492,"['NB', 'ME', 'SVMs']","['to', 'Naive', 'Maximum Entropy', 'Support Vector Machines']","[[103, 105], [125, 127], [160, 164]]","[[49, 51], [89, 94], [108, 123], [-1, 22]]","['Maximum Entropy', 'Support Vector Machines']","['NB', 'ME', 'SVMs']","[[108, 123]]","['NB', 'ME', 'SVMs']","[[103, 105], [125, 127], [160, 164]]"
492,492,"train statistical models that rely on annotated data.8 In this paper, we test automatic annotation using Conditional Random Fields (CRFs) (Lafferty et al, 2001) which have achieved high performance for in-",493,['CRFs'],"['on', 'Conditional Random Fields', 'al']","[[132, 136]]","[[35, 37], [105, 130], [15, 17]]",['Conditional Random Fields'],['CRFs'],"[[105, 130]]",['CRFs'],"[[132, 136]]"
493,493,"measured on separate grammatical and ungrammatical data: Gr = Grammatical, AG = Agreement, RW = Real-Word, EW = Extra Word, MW = Missing Word",494,"['AG', 'RW', 'EW', 'MW']","['Gr', 'Grammatical', 'Agreement', 'Real-Word', 'Extra', 'Word']","[[75, 77], [91, 93], [107, 109], [124, 126]]","[[57, 59], [62, 73], [80, 89], [96, 105], [112, 117], [101, 105]]","['Grammatical', 'Agreement', 'Real-Word']","['AG', 'RW', 'EW', 'MW']","[[21, 32], [80, 89], [96, 105]]","['Gr', 'AG', 'RW', 'EW', 'MW']","[[57, 59], [75, 77], [91, 93], [107, 109], [124, 126]]"
494,494,"Schu?tze reduces the dimensionality of this feature space using Singular Value Decomposition (SVD), which is also employed by related techniques such as Latent Semantic Indexing (Deerwester et",495,['SVD'],['Singular Value Decomposition'],"[[94, 97]]","[[64, 92]]",['Singular Value Decomposition'],['SVD'],"[[64, 92]]",['SVD'],"[[94, 97]]"
495,495,"is a.t least cubic in t, ime, this fl)llows trivially  fronl the inequality  A a+B a <A a+:C4 ~B+aAB=+B a =(A+B)  a  for A,B positive - length of strings) ",496,['A'],"['t', 'ime']","[[77, 78]]","[[5, 6], [25, 28]]",[],['A'],[],[],[]
496,496,"present specialized knowledge, since both the writer and readers are experts. Medical texts include the abstracts of all medical articles written in Basque in the Gaceta M?edica de Bilbao (GMB) ? Medical",497,[],"['Gaceta M ? edica de Bilbao', '?']",[],"[[-1, 25], [171, 172]]",['Gaceta M ? edica de Bilbao'],[''],[],['GMB'],"[[189, 192]]"
497,497,"2014). We note the linguistic rules included in the Lease, Johnson & Charniak (2006) tree adjoining grammar (TAG) noisy-channel model ? lexical,",498,['TAG'],"['in', 'tree adjoining grammar']","[[109, 112]]","[[20, 22], [85, 107]]",['tree adjoining grammar'],['TAG'],"[[85, 107]]",['TAG'],"[[109, 112]]"
